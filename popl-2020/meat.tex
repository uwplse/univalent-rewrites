\section{A Configurable Proof Term Transformation}
\label{sec:key2}

At the heart of \toolname is a configurable proof term transformation for transporting
proofs across equivalences. This is based on the proof term transformation from 
\textsc{Devoid}~\cite{Ringer2019}, which solved this problem for particular class of equivalences.
The goal of \toolname is to implement something like \textsc{Devoid}, but over
a much broader set of changes, and with better workflow integration.
We were able to generalize the \textsc{Devoid} algorithm to do this:

\begin{quote}
\textbf{Insight 2}:
The proof term transformation from the \textsc{Devoid} proof reuse tool can be generalized (Section~\ref{sec:generic})
to build such a generic proof reuse tool (Section~\ref{sec:implementation}),
and the result is configurable both by the developer and by the user (Section~\ref{sec:configurable}).
\end{quote}

\subsection{The Proof Term Transformation}
\label{sec:generic}

\begin{figure}
\small
\begin{grammar}
<i> $\in \mathbbm{N}$, <v> $\in$ Vars, <s> $\in$ \{ Prop, Set, Type<i> \}

<t> ::= <v> | <s> | $\Pi$ (<v> : <t>) . <t> | $\lambda$ (<v> : <t>) . <t> | <t> <t> | \\
Ind (<v> : <t>)\{<t>,\ldots,<t>\} | Constr (<i>, <t>) | Elim(<t>, <t>)\{<t>,\ldots,<t>\} | \\
DepConstr(<i>, <t>) | DepElim(<t>, <t>)\{<t>,\ldots,<t>\} | IdEta (<t>) | RewEta(<i>, <t>, <t>, <t>)
\end{grammar}
\caption{Syntax for CIC$_\omega$ extended with the \toolname configuration.}
\label{fig:syntax}
\end{figure}

This generalized proof term transformation forms the core of \toolname, configured in the \textbf{Configure}
step and implemented in the \textbf{Transform} step.
The transformation operates over terms in an extended CIC$_{\omega}$ with primitive eliminators (Figure~\ref{fig:syntax}).
This extended CIC$_{\omega}$ contains everything in CIC$_{\omega}$; the typing rules are standard.
In addition, it contains terms that correspond to the configuration for the transformation, briefly:

\begin{enumerate}
\item \lstinline{DepConstr} and \lstinline{DepElim} to configure the transformation to an equivalence, and
\item \lstinline{IdEta} and \lstinline{RewEta} to configure the transformation to reason about equalities.
\end{enumerate}
Together, these instantiate the proof term transformation to a particular equivalence.
Each of these is defined in terms of other terms in CIC$_{\omega}$ for any given equivalence.
Representing them explicitly simplifies reasoning about both the proof term transformation and its implementation.

\begin{figure}
\begin{mathpar}
\mprset{flushleft}
\small
\hfill\fbox{$\Gamma$ $\vdash$ $t$ $\Uparrow$ $t'$}\\

\inferrule[Dep-Elim]
  { \Gamma \vdash p_{a} \Uparrow p_b \\ \Gamma \vdash \vec{f_{a}}\phantom{l} \Uparrow \vec{f_{b}} }
  { \Gamma \vdash \mathrm{DepElim}(a,\ p_{a}) \vec{f_{a}} \Uparrow \mathrm{DepElim}(b,\ p_b) \vec{f_{b}} }

\inferrule[Dep-Constr]
{ \Gamma \vdash \vec{t}_{a} \Uparrow \vec{t}_{b} } %\\ TODO must we explicitly lift A to B if we want to handle parameters/indices?
{ \Gamma \vdash \mathrm{DepConstr}(j,\ A)\ \vec{t}_{a} \Uparrow \mathrm{DepConstr}(j,\ B)\ \vec{t}_{b}  }

\inferrule[Id-Eta]
  { \\ }
  { \Gamma \vdash \mathrm{IdEta}(A) \Uparrow \mathrm{IdEta}(B) }

\inferrule[Rew-Eta]
  { \Gamma \vdash c_A \Uparrow c_B \\ \Gamma \vdash q_A \Uparrow q_B \\ \Gamma \vdash e_A \Uparrow e_B }
  { \Gamma \vdash \mathrm{RewEta}(j,\ A,\ q_A,\ t_A) \Uparrow \mathrm{RewEta}(j,\ B,\ q_B,\ t_B) }

\inferrule[Equivalence]
  { \\ }
  { \Gamma \vdash A\ \Uparrow B }

\inferrule[Constr]
{ \Gamma \vdash T \Uparrow T' \\ \Gamma \vdash \vec{t} \Uparrow \vec{t'} }
{ \Gamma \vdash \mathrm{Constr}(j,\ T)\ \vec{t} \Uparrow \mathrm{Constr}(j,\ T')\ \vec{t'} }

\inferrule[Ind]
  { \Gamma \vdash T \Uparrow T' \\ \Gamma \vdash \vec{C} \Uparrow \vec{C'}  }
  { \Gamma \vdash \mathrm{Ind} (\mathit{Ty} : T) \vec{C} \Uparrow \mathrm{Ind} (\mathit{Ty} : T') \vec{C'} }

\inferrule[Elim] % TODO wait why do we have c here when it clearly refers to the term we eliminate over? um
  { \Gamma \vdash c \Uparrow c' \\ \Gamma \vdash Q \Uparrow Q' \\ \Gamma \vdash \vec{f} \Uparrow \vec{f'}}
  { \Gamma \vdash \mathrm{Elim}(c, Q) \vec{f} \Uparrow \mathrm{Elim}(c', Q') \vec{f'}  }

%% Application
\inferrule[App]
 { \Gamma \vdash f \Uparrow f' \\ \Gamma \vdash t \Uparrow t'}
 { \Gamma \vdash f t \Uparrow f' t' }

% Lamda
\inferrule[Lam]
  { \Gamma \vdash T \Uparrow T' \\ \Gamma,\ t : T \vdash b \Uparrow b' }
  {\Gamma \vdash \lambda (t : T).b \Uparrow \lambda (t : T').b'}

% Product
\inferrule[Prod]
  { \Gamma \vdash T \Uparrow T' \\ \Gamma,\ t : T \vdash b \Uparrow b' }
  {\Gamma \vdash \Pi (t : T).b \Uparrow \Pi (t : T').b'}
\end{mathpar}
\caption{Proof term transformation.}
\label{fig:final}
\end{figure}

Figure~\ref{fig:final} shows the proof term transformation.
Like the transformation from \textsc{Devoid}, this transformation is parameterized over
two equivalent types \A and \B (\textsc{Equivalence}) and assumes fully expanded terms.
It uses the same conventions $\vec{i}$ and $\{t_1, \ldots, t_n\}$ to denote lists of terms.

The goal of the proof term transformation is to preserve that equivalence in some way, while no longer referring to the old specification.
That is, for equivalent types \A and \B, the transformation takes as input functions and proofs
that refer to \A and returns functions and proofs that refer to \B.
Furthermore, the transformed functions behave the same way as the input functions,
and the transformed proofs talk about the same things as the input proofs.

For example, Figure~\ref{fig:appswap1} shows the input and output reduced to CIC$_{\omega}$
for our refactored list append function \codeauto{\lstinline{++}} from Section~\ref{sec:overview},
corresponding to the change in \lstinline{list} from Figure~\ref{fig:listswap}.
Both versions of append behave identically up to the equivalence from Figure~\ref{fig:equivalence}, since:

\begin{lstlisting}
$\forall$ T (l1 l2 : Old.list T),
  (@\codeauto{f}@) T (l1 ++ l2) =
  ((@\codeauto{f}@) T l1) (@\codeauto{++}@) ((@\codeauto{f}@) T l2).
\end{lstlisting}
by induction and rewriting, and similarly in the opposite direction.
Our transformed proof \codeauto{\lstinline{rev_app_distr}} then proves the same thing the same way
as the original proof up to the same equivalence---and up to the corresponding changes in \codeauto{\lstinline{++}}
and \lstinline{rev}.

\begin{figure}
\begin{minipage}{0.48\textwidth}
\begin{lstlisting}
$\lambda$ (T : Type) (l m : list T) .
 Elim (l, $\lambda$(l: list T).list T $\rightarrow$ list T))
 {
   (@\codediff{($\lambda$ m . m)}@),
   ($\lambda$ t _ IHl m.
      Constr((@\codediff{1}@), list T) t (IHl m))
 } m.
\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}{0.48\textwidth}
\begin{lstlisting}
$\lambda$ (T : Type) (l m : list T) .
 Elim (l, $\lambda$(l: list T).list T $\rightarrow$ list T))
 {
   ($\lambda$ t _ IHl m.
      Constr((@\codediff{0}@), list T) t (IHl m)),
   (@\codediff{($\lambda$ m . m)}@)
 } m.
\end{lstlisting}
\end{minipage}
\caption{The list append function before (left) and after (right) refactoring.}
\label{fig:appswap1}
\end{figure}

More formally, the output of the proof term transformation ought to be equal to the input of the program transformation
\textit{up to transport} along the equivalence between \A and \B that the configuration instantiates it to.
This is the same as the correctness criterion for the program transformation from \textsc{Devoid} that this is based on,
with the transformation generalized to handle other equivalences beyond the class that \textsc{Devoid} supports.
The key steps in this transformation that make this possible are porting functions and proofs along the configuration corresponding
to a particular equivalence (\textsc{Dep-Constr}, \textsc{Dep-Elim}, \textsc{Id-Eta}, and \textsc{Rew-Eta}).
From there, rest of the transformation is straightforward.

Note that this correctness criterion is metatheoretical:
stating and proving that two terms are in equal up to transport is in general not possible in a language like Coq
without additional axioms, though it is in some cases realizable with an external tool~\cite{tabareau2017equivalences}.
\toolname does not yet generate these proofs as we were focused on building a usable tool with axiomatic freedom and few dependencies.
Coq ensures that all terms that plugins produce are well-typed; for now, as with \textsc{Devoid}, the proof engineer must vet the transformed
specifications herself.

\subsection{The Configuration}
\label{sec:configurable}

The behavior of the proof term transformation at a particular equivalence hinges on correct configuration.
The configuration ensures that the transformation accomplishes two goals: % TODO is ``ensures'' too strong if we don't prove it?

\begin{enumerate}
\item it preserves the equivalence between \A and \B, and
\item it produces well-typed terms.
\end{enumerate}
These two goals each correspond to a pair of configuration parts, respectively:

\begin{enumerate}
\item \lstinline{DepConstr} and \lstinline{DepElim} define how to transform constructors and eliminators, thereby preserving the equivalence (Section~\ref{sec:equivalence}), and 
\item \lstinline{IdEta} and \lstinline{RewEta} define how to transform identity and equalities, thereby producing well-typed terms (Section~\ref{sec:equality}).
\end{enumerate}
The four parts of this configuration must be in relation to one another in a certain way in order for the proof
term transformation to work correctly (Section~\ref{sec:art}).

\subsubsection{Equivalence}
\label{sec:equivalence}

The two configuration parts responsible for ensuring that the program transformation 
are \lstinline{DepConstr} (\textit{dependent constructors}) and \lstinline{DepElim} (\textit{dependent eliminators}).
These describe how to construct and eliminate \A and \B, wrapping the two types with a common inductive structure.
There are the same number of dependent constructors and inductive hypotheses in dependent eliminators for both \A and \B,
even if \A and \B are inductive types with different numbers of constructors.
The idea is to port functions and proofs over \A to functions and proofs over \B by viewing \B as if it is an \A.
This way, the rest of the transformation can replace constructions of \A with constructions of \B and
inductive proofs about \A with inductive proofs about \B, but otherwise just recursively lift
the other subterms without changing the order or number of arguments.

\begin{figure}
\begin{minipage}{0.48\textwidth}
\begin{lstlisting}
DepConstr(0, list T) : list T :=
  Constr((@\codediff{0}@), list T).
DepConstr(1, list T) t l : list T :=
  Constr ((@\codediff{1}@), list T) t l.

DepElim(l, P) { p$_{\mathtt{nil}}$, p$_{\mathtt{cons}}$ } : P l :=
  Elim(l, P) { (@\codediff{p$_{\mathtt{nil}}$}@), (@\codediff{p$_{\mathtt{cons}}$}@) }.
\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}{0.48\textwidth}
\begin{lstlisting}
DepConstr(0, list T) : list T :=
  Constr((@\codediff{1}@), list T).
DepConstr(1, list T) t l : list T :=
  Constr((@\codediff{0}@), list T) t l.

DepElim(l, P) { p$_{\mathtt{nil}}$, p$_{\mathtt{cons}}$ } : P l :=
  Elim(l, P) { (@\codediff{p$_{\mathtt{cons}}$}@), (@\codediff{p$_{\mathtt{nil}}$}@) }.
\end{lstlisting}
\end{minipage}
\caption{The dependent constructors and eliminators for old (left) and refactored (right) \lstinline{list}.}
\label{fig:listconfig}
\end{figure}

For the \lstinline{list} refactoring from Figure~\ref{fig:listswap},
the configuration that \toolname discovers uses the the dependent constructors
and eliminators in Figure~\ref{fig:listconfig}. The dependent constructors for \lstinline{Old.list}
are just the normal constructors \lstinline{nil} and \lstinline{cons} with the order unchanged,
while the dependent constructors for \lstinline{New.list} swap \lstinline{nil} and \lstinline{cons}
back to the original order.
Similarly, the dependent eliminator for \lstinline{Old.list} is just the normal eliminator for \lstinline{Old.list},
while the dependent eliminator for \lstinline{New.list} swaps the \lstinline{nil} and \lstinline{cons} cases.

\begin{figure}
\begin{minipage}{0.48\textwidth}
\begin{lstlisting}
$\lambda$ (T : Type) (l m : list T) .
 Elim
   (l, $\lambda$(l: list T).list T $\rightarrow$ list T))
 {
   ($\lambda$ m . m)
   ($\lambda$ t _ IHl m.
      Constr(1, list T) t (IHl m))
 } m.
\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}{0.48\textwidth}
\begin{lstlisting}
$\lambda$ (T : Type) (l m : list T) .
 (@\codediff{DepElim}@)
   (l, $\lambda$(l: list T).list T $\rightarrow$ list T))
 {
   ($\lambda$ m . m)
   ($\lambda$ t _ IHl m.
      (@\codediff{DepConstr}@)(1, list T) t (IHl m))
 } m.
\end{lstlisting}
\end{minipage}
\caption{The original list append function (left) and the same function rewritten to use \lstinline{DepConstr} (right).}
\label{fig:appswap2}
\end{figure}

To refactor the append function \lstinline{++} from the left of Figure~\ref{fig:appswap1}, \toolname
identifies implicit applications of \lstinline{DepConstr} and \lstinline{DepElim} and expands them (Figure~\ref{fig:appswap2}).
The transformation then just recursively substitutes in the refactored \lstinline{list} type
for the original \lstinline{list} type, which moves \lstinline{DepConstr} and \lstinline{DepElim}
to construct and eliminate over the refactored type.
Finally, this reduces to the term on the right of Figure~\ref{fig:appswap2}.
Transforming proofs works the same way.

When our types are not both inductive types, the constructors and eliminators can be \textit{dependent}.
One example of this arises from integrating the refactoring between lists and $\Sigma$\lstinline{(n : nat).vector T n} that
\textsc{Devoid} supports into the \toolname framework.
We can configure the \toolname transformation to perform this same refactoring
by configuring the dependent constructors to \textit{pack} the index into an existential, for example:

\begin{lstlisting}
DepConstr(0, $\Sigma$(n : nat).vector T n) : $\Sigma$(n : nat).vector T n :=
  $\exists$ (Constr(0, nat)) (Constr(0, vector T)).
\end{lstlisting}
and by configuring the eliminator to eliminate over the projections:

\begin{lstlisting}
DepElim(s, P) { f$_0$ f$_1$ } : P ($\exists$ ($\pi_l$ s) ($\pi_r$ s)) :=
  Elim($\pi_r$ s, $\lambda$ (n : nat) (v : vector T n) . P ($\exists$ n v)) {
    f$_0$
    ($\lambda$ (t : T) (n : nat) (v : vector T n) . f$_1$ t ($\exists$ n v))
  }. 
\end{lstlisting}

In both of these examples, the only interesting work moves into the configuration:
the configuration for the swap example takes care of swapping constructors and cases,
and the configuration for the \textsc{Devoid} example implements the constructor and eliminator rules from the \textsc{Devoid} transformation.
That way, that the rest of the \toolname transformation does not need to add, drop, or reorder arguments at any point.
In essence, all of the difficult work moves into the configuration, but once it is done, it is done.
Furthermore, for both of the examples above, the \textsc{Configure} component of \toolname is able to discover \lstinline{DepConstr}
and \lstinline{DepElim} from just the types \A and \B, taking care of even the difficult work.

Of course, both when designing a search procedure for an automatic configuration and when
configuring \toolname manually, choosing correct and useful \lstinline{DepConstr} and \lstinline{DepElim} is important,
and it is not always straightforward.
Section~\ref{sec:search} shows more example configurations, including
how to configure the repair that maps \{\lstinline{l : list T | length l = n}\} to \lstinline{vector T n},
and including cases when \A and \B themselves have different number of constructors.

\subsubsection{Equality}
\label{sec:equality}

The other two rules corresponding to the configuration deal with transporting equalities.
Since our language does not assume univalence, we do not have that equivalence is equivalent to equality.
The result of this, as noted in \citet{tabareau2019marriage},
is that we must do additional work to transform equalities.
Otherwise, if we tranform a term \lstinline{t : T} to some \lstinline{t' : T'}, we do not necessarily
have that our transformation maps \lstinline{T} to \lstinline{T'}.
The two rules that correspond to this in the program transformation are \lstinline{Id-Eta} and \lstinline{Rew-Eta},
which use configuration parts \lstinline{IdEta} (\textit{eta-expanded identity}) and \lstinline{RewEta} (\textit{eta-expanded rewrites}), respectively.

At a high level, \lstinline{IdEta} describes how to expand the identity function in a way that preserves equalities
coherently with the definitions of \lstinline{DepConstr} and \lstinline{DepElim}.
This is what allows us to forego the assumption from \textsc{Devoid} that our language has primitive projections.
Each \lstinline{RewEta}---one per inductive hypothesis in \lstinline{DepElim}---describes and proves the refolding behavior
of \lstinline{DepElim} on the corresponding inductive hypothesis.
These together describe the essence of identity and equality as they relate to \lstinline{DepConstr}
and \lstinline{DepElim}.

We see this with natural numbers \lstinline{nat} and binary numbers \lstinline{binnat}
in Section~\ref{sec:search}.
There, we at some point try to repair this theorem over \lstinline{nat} from the Coq standard library:

\begin{lstlisting}
(* TODO update this text and example now that we've changed 6, or move 6 up *)
Lemma plus_Sn_m :
  forall (n m : nat), S n + m = S (n + m).
Proof.
  intros n m; induction n; simpl; auto.
Qed.
\end{lstlisting}
to instead refer to binary numbers.
The term underneath this is just reflexivity:

\begin{lstlisting}
(fun n m : nat => eq_refl) : forall n m : nat, S n + m = S (n + m)
\end{lstlisting}
Naively transforming reflexivity (definitional equality) to reflexivity results in a type error,
since the transported depenedent constructor corresponding to \lstinline{S}---
a function that takes the successor of any binary natural number---
does not preserve definitional equality.

The trick to transforming this correctly is to view the definitional equality above as a contracted propositional equality:

\begin{lstlisting}
(fun n m : nat =>
  eq_rect
    (fun m => S n + m)
    (fun (p : nat -> nat) => S n + m = p m)
    eq_refl
    (fun m => S (n + m))
    eq_refl)
: forall n m : nat, S n + m = S (n + m)
\end{lstlisting}
We can then transform that propositional equality to a propositional equality over binary numbers (after transforming \lstinline{+} to operate
over binary numbers):

\begin{lstlisting}
(fun n m : Bin.nat =>
  eq_rect
    (fun m => Bin.S n + m)
    (fun (p : Bin.nat -> Bin.nat) => S n + m = p m)
    eq_refl
    (fun m => Bin.S (n + m))
    (refold_elim_S (fun _ => Bin.nat -> Bin.nat) (fun b3 : Bin.nat => b3) (fun _ add (b3 : Bin.nat) => Bin.S (add b3)) n)
: forall n m : Bin.nat, S n + m = S (n + m)
\end{lstlisting}
which gives us a proof of the theorem we want.

The key to this working is \lstinline{refold_elim_S}, which essentially states that
we can always refold the successor case of inductive proofs about \lstinline{Bin.nat}
that go through the dependent eliminator over \lstinline{Bin.nat}:

\begin{lstlisting}
refold_elim_S :
  forall (P : Bin.nat -> Type) (PO : P Bin.O) (PS : forall n, P n -> P (Bin.S n)) (n : Bin.nat),
    DepElim P PO PS (Bin.S n) = PS n (DepElim P PO PS n).
\end{lstlisting}
% TODO everywhere here need to be consistent about DepConstr, DepElim, syntax, etc.
The equivalent over \lstinline{nat} would follow by reflexivity, so its application is implicit.
We can derive a rewrite rule from this:

\begin{lstlisting}
(fun P PO PS n (Q : P (Bin.S n) -> Type) (H : Q (DepElim P PO PS (Bin.S n))) : Q (PS n (DepElim P PO PS n)) :=
  eq_rect
    (DepElim P PO PS (Bin.S n))
    (fun (H : P (Bin.S n)) => Q H)
    H
    (PS n (DepElim P PO PS n))
    (refold_elim_S P PO PS n)
: forall P PO PS n (Q : P (Bin.S n) -> Type), Q (DepElim P PO PS (Bin.S n)) -> Q (PS n (DepElim P PO PS n)).
\end{lstlisting}
This rewrite rule turns out to be \lstinline{RewEta} for \lstinline{Bin.nat}, one of the two configuration parts that 
handles contracted equalities:
\lstinline{Rew-Eta} uses \lstinline{RewEta} to transform expanded propositional equalities, while
\lstinline{Id-Eta} uses \lstinline{IdEta} to transform the expanded identity function.
In this example, \lstinline{IdEta} is just the identity function.
In our repair, \lstinline{IdEta} expands the existential:

\begin{lstlisting}
fun (n : pos_nat) => $\exists$ ($\pi_l$ n) ($\pi_r$ n)
\end{lstlisting}
so that, unlike \textsc{Devoid}, we do not need our algorithm to assume primitive projections.

\lstinline{RewEta} in the above example is not reflexivity precisely becuse our two inductive types
\lstinline{nat} and \lstinline{Bin.nat} do not have the same inductive structure---they are not \textit{ornaments}. % TODO cite
When our types are ornaments, like with our simple refactor above, every \lstinline{RewEta} just rewrites by reflexivity.
More in Section~\ref{sec:search}.

\subsubsection{Equivalence \& Equality}
\label{sec:art}

The configuration (\lstinline{DepConstr}, \lstinline{DepElim}, \lstinline{IdEta}, \lstinline{RewEta}) instantiates
the proof term transformation to a particular equivalence between \A and \B.
We noted in Section~\ref{sec:key1} that choosing an equivalence is a bit of an art:
there can be infinitely many equivalences that correpond to a 
given change in specification, only some of which are useful.
Beyond that, even once we have chosen an equivalence, we could define many possible configurations that correspond
to the equivalence, some of which will produce functions and proofs that are more useful or efficient than others.

Thankfully, once the art is done, we can at least ensure that it is \textit{correct art}.
The correctness criteria for the configuration relate \lstinline{DepConstr}, \lstinline{DepElim}, \lstinline{IdEta}, and \lstinline{RewEta}
in a way that preserves both equivalence (Section~\ref{sec:equivalence}) and equality (Section~\ref{sec:equality}).
To preserve equivalence, we need that each \lstinline{DepConstr(j, A)} is equal to each \lstinline{DepConstr(j, B)} up to transport,
and similarly that \lstinline{DepElim} over \A is equal to \lstinline{DepElim} over \B up to transport:

\begin{lstlisting}
TODO
\end{lstlisting}
The intuition for this is based on insights from \textsc{Devoid},
and is proven on an example in the univalent parametricity framework.\footnote{\url{https://github.com/CoqHott/univalent_parametricity/commit/7dc14e69942e6b3302fadaf5356f9a7e724b0f3c}}
That these induce a type equivalence follows from that.

To preserve equality, we need to relate the dependent constructors and eliminators to
\lstinline{IdEta} and \lstinline{RewEta}:

\begin{lstlisting}
TODO
\end{lstlisting}
The intuition is that these rules is that we need proofs about equality to lift to proofs about equality,
and again we can only ever construct or eliminate at some point, so it is enough
to use these facts just in the dependent constructors and eliminators.

These can be difficult to prove---the former requires either a special framework % TODO cite UP
or a univalent type theory.
Thankfully, the user does not need to prove these in order to use \toolname.
Rather, these simply need to hold in order for the proof term transformation to work correctly.

All of this comes together to transport functions and proofs across the equivalence between \A and \B
using a program transformation.
TODO show some examples.
Section~\ref{sec:search} shows some particular instantions of this configuration and their applicability to real programs and proofs.

\paragraph{Orphaned}

For any type \A or \B,
There is just one \lstinline{IdEta}, but there are as many \lstinline{RewEta} as there are
inductive hypotheses of \lstinline{DepElim}.
This is because we can minimize the equality problem to preserving definitional equalities
in the eliminator---we'll see this more in Section~\ref{sec:search}.

these induce proofs of section \& retraction I think.
so note with ornaments the section and retraction proofs are just induction and rewriting since \lstinline{RewEta} is
rewriting by reflexivity.

\paragraph{Orphaned}
The intuition behind \lstinline{DepConstr} and \lstinline{DepElim} is that,
since CIC$_{\omega}$ is a constructive logic, the only way to construct an \A (respectively \B) is to use its constructors.
Similarly, the only way to match over an \A (respectively \B) is to apply its eliminator. 
The \lstinline{Dep-Constr} rule thus rewrites constructions of \A to constructions of \B,
while the \lstinline{Dep-Elim} rule rewrites applications of eliminators of \A to applications of eliminators of \B.
The result will construct \B in place of \A, and it will eliminate \B in place of \A.
Thanks to this, \toolname can remove all references to the old type \A,
and produce a refactored or repaired term that refers only to the new type \B.

Together, these dependent constructors and eliminators induce a type equivalence between \A and \B,
formed by one function that eliminates \A and constructs \B, and another function that eliminates \B and constructs \A:

\begin{lstlisting}
f : A -> B := DepElim(a, $\lambda$(a : A).B){ $\lambda$ ... DepConstr(0, B) ..., ... }
g : B -> A := DepElim(b, $\lambda$(b : B).A){ $\lambda$ ... DepConstr(0, A) ..., ... }
\end{lstlisting}
Each search procedure that \textbf{Configure} implements discovers the configuration
along with these two functions, and (optionally for the proof engineer) produces a proof in Coq that these functions form an equivalence.
The transformation in \textbf{Transform} then ports functions and proofs across this equivalence.


\subsection{The Tool}
\label{sec:implementation}

% TODO may move this into 6, or 8, or something. not sure yet.

The configurable proof term transformation helped us build a flexible proof refactoring and reuse tool.
However, it alone was not enough to build a tool that reaches real users.
This section describes a sample of the implementation challenges that we encountered and how we solved them.
Section~\ref{sec:discussion} elaborates on the remaining challenges and our plans to address them in the future.

\paragraph{From CIC$_{\omega}$ to Coq}

Like \textsc{Devoid}, we also had to handle language differences to scale from CIC$_{\omega}$ to Coq.
We use the same \lstinline{Preprocess} command that \textsc{Devoid} uses to turn pattern matching and fixpoints into applications of eliminators.
We generalize the work from \textsc{Devoid} to handle Coq's non-primitive projections into our \lstinline{IdEta} rule.
We move the work of refolding constants into the configuration for each search procedure, so that it does not
cloud the proof term transformation itself.

\paragraph{Matching Against Preconditions}

It is easy to \textit{describe} the proof term transformation, but it is much more difficult to implement it.
This is because the proof term transformation only describes what transformation rules are applicable when,
but it does not describe how to actually check that the precondition holds.
In many cases, this check is not purely syntactic---we really want to know if a term \textit{unifies}
with an application of \lstinline{DepConstr}, for example, not whether it applies the term exactly.
This is especially pronounced with \lstinline{IdEta} and \lstinline{RewEta},
which typically show up contracted in real code.
This problem is exactly why \citet{tabareau2019marriage} speculated that converting definitional to propositional equalities
like we do with \lstinline{RewEta} may, in general, be intractable.

In practice, we find that unification is often not enough to identify an implicit application of one of the configuration terms.
Each of our search procedures for automatic configuration in turn implements special rewrite rules that tell \toolname
how to identify and expand these implicit applications before applying the transformation.
There is not yet a way for proof engineers themselves to supply these custom rewrite rules,
so sometimes in order to use \toolname with manual configuration, proof engineers must manually expand
input terms to explicitly apply parts of the configuration like \lstinline{RewEta}.
This can be challenging, so we plan to give proof engineers the opportunity to write
these custom rewrite rules themselves in the future.

\paragraph{Termination \& Intent}

Another challenge with implementing the proof term transformation is deciding whether to run a rule that matches at all.
That is, when the correctness criteria for a configuration hold and a subterm matches a rule, this suggests that \toolname \textit{can}
run the transformation rule, but it does not necessarily mean that it \textit{should}.
In some cases, repeatedly running a matching transformation rule would result in nontermination.
For example, if our type \B is a refinement of our type \A, then we can always run \textsc{Equivalence}
over and over again, forever.
\textsc{Devoid} ruled out this case by simply prohibiting the case where \B refers to \A, but we found it sometimes
useful in practice to support that case.
To support this, we include some simple termination checks in our code.

More generally, even when termination is guaranteed, whether to run a matching transformation rule
depends on the intent of the user.
For example, our industrial proof engineer sometimes wished to port only some occurrences of \A,
especially when \A was a tuple like \lstinline{(nat * bool)} that could feasibly appear elsewhere in the term
but have a different meaning.
We helped the proof engineer do this by interacting with \toolname using a particular workflow.
We plan to support this automatically using type-directed search in the future.

\paragraph{Reaching Real Users}
Many of our design decisions in implementing \toolname were informed by our partnership with
an industrial user.
For example, we found that our industrial user rarely had the patience to wait more than ten seconds
for \toolname to port a function or proof.
In response, we implemented very aggressive caching (with an option to disable the cache), even caching intermediate subterms that
we encounter in the course of running our program transformation.
We also added the option to set certain terms or even entire modules as opaque to \toolname, to prevent
unecessary $\delta$-reduction of constants.
We included many other optimizations, including lazy $\eta$-expansion of terms like \textsc{Devoid}.

User experiences also informed features that we exposed to users.
For example, all of our search procedures for configurations generate proofs that the discovered
equivalence actually is an equivalence, using functionality that expands on the same functionality from \textsc{Devoid}.
We also implemented special search procedures to generate custom eliminators to make it easier to reason about
types that we found common for certain search procedures.
For example, \toolname generates a custom eliminator automatically to reason about \{\lstinline{l : list T & length l = n}\}
and other similar types by breaking it into parts and reasoning seperately about the two projections.
These features along with our tactic decompiler helped with integration into proof engineering workflows.

%First we need that \lstinline{DepElim} over $A$ into \lstinline{DepConstr} over $B$ and \lstinline{DepElim} over $B$ into
%\lstinline{DepConstr} over $A$ form an equivalence between $A$ and $B$. When that's true, I think it should hold that \lstinline{DepElim} over $A$
%and \lstinline{DepElim} over $B$ are in univalent relation with one another. If not, then that's an extra condition.
%Finally, we need the transformation to preserve definitional equalities. Not sure about the general case, but for vectors and lists,
%we need:

%\begin{lstlisting}
%  $\forall$ A l (f : $\forall$ (l : sigT (Vector.t A)), l = l),
%    vect_dep_elim A (fun l => l = l) (f nil) (fun t s _ => f (cons t s)) l = f (id_eta l).
%\end{lstlisting}
%and:

%\begin{lstlisting}
%Definition elim_id (A : Type) (s : {H : nat & t A H}) :=
%  vect_dep_elim
%    A
%    (fun _ => {H : nat & t A H})
%    nil
%    (fun (h : A) _ IH =>
%      cons h IH)
%    s.

% $\forall$ A h s,
%    exists (H : cons h (elim_id A s) = elim_id A (cons h s)),
%      H = eq_refl.
%\end{lstlisting}
%More generally, for each constructor index $j$, define:

%\begin{lstlisting}
%  eqc (j, B) (f : $\forall$ b : B, b = b) :=
%    fun ... (* TODO get the hypos from the type of the eliminator *) =>
%      f (DepConstr (j, B)) (* TODO args *)%%

  %elim_id := (* TODO *)
%\end{lstlisting}
%Then we need:

%\begin{enumerate}
%\item $\forall b f, \mathrm{DepElim}(b,\ p_{b}) \{\mathrm{eqc} (1, B) f, \ldots, \mathrm{eqc} (n, B) f\} = f (\mathrm{IdEta}(A) a) $
%\item Something relating the constructors and \lstinline{elim_id} to reflexivity
%\end{enumerate}
%and similarly for $A$.

%Really the point of these conditions is that from them, with some restrictions on input terms, we can get
%that lifting terms gives us the same type that we'd get from lifting the type. But there are still
%some restrictions (see the few that fail).

%It's probably not always possible to define these three things for every equivalence.
%Could generalize by rewriting. But this lets us avoid the rewriting problem from Nicolas' paper.

% TODO how does this get us something like primitive projections? Just makes IdEta definitionally equal to regular Id?

% TODO so we can probably just frame search in terms of DepConstr and DepElim and then generate proofs about this on an ad-hoc basis
% and get away with not including the specific details of our instantiations. We can give examples instead, give intuition, and say we generate
% the proofs in Coq

%For the second one we need not just an eliminator rule but also an identity rule.
%DEVOID assumed primitive projections which let them get away without thinking of this,
%but then had this weirdly ad-hoc ``repacking'' thing in their implementation.
%It turns out this is just a more general identity rule, which basically says what
%the identity function should lift to so that the transformation preserves definitional equalities.
%Actually deciding when to run this rule is one of the biggest challenges in practice,
%so we'll talk about that more in the implementation section.


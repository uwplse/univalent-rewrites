\section{A Configurable Proof Term Transformation}
\label{sec:key2}

At the heart of \toolname is a configurable proof term transformation for transporting
proofs across equivalences. This is based on the proof term transformation from 
\textsc{Devoid}~\cite{Ringer2019}, which solved this problem for particular class of equivalences.
The goal of \toolname is to implement something like \textsc{Devoid}, but over
a much broader set of changes, and with better workflow integration.
We were able to generalize the \textsc{Devoid} algorithm to do this.

\begin{quote}
\textbf{Insight 2}:
The proof term transformation from the \textsc{Devoid}~\cite{Ringer2019} proof reuse tool can be generalized (Section~\ref{sec:generic})
to build such a proof repair tool (Section~\ref{sec:implementation}), and the result can handle 
many different kinds of changes (Section~\ref{sec:configurable}).
\end{quote}

\begin{figure}
\small
\begin{grammar}
<i> $\in \mathbbm{N}$, <v> $\in$ Vars, <s> $\in$ \{ Prop, Set, Type<i> \}

<t> ::= <v> | <s> | $\Pi$ (<v> : <t>) . <t> | $\lambda$ (<v> : <t>) . <t> | <t> <t> | \\
Ind (<v> : <t>)\{<t>,\ldots,<t>\} | Constr (<i>, <t>) | Elim(<t>, <t>)\{<t>,\ldots,<t>\}
\end{grammar}
\caption{Syntax for CIC$_\omega$.} % TODO cite existing work, both DEVOID and the place it is from
\label{fig:syntax}
\end{figure}

\paragraph{Conventions}
All terms that we introduce in this section are in CIC$_{\omega}$ with primitive eliminators,
the syntax for which is in Figure~\ref{fig:syntax}.
The typing rules are standard.
Throughout, we use $\vec{i}$ and $\{t_1, \ldots, t_n\}$ to denote lists of terms.

\subsection{The Configuration}
\label{sec:configurable}

This configuration is the key to building a proof term transformation that can support many different classes of changes.
Before introducing the proof term transformation, we will describe the configuration, which in effect specifies the behavior
of the transformation.

The configuration instantiates the proof term transformation to two equivialent types \A and \B, so that the proof term transformation
can transform terms defined over \A to terms defined over \B instead.
%The behavior of the proof term transformation at a particular equivalence hinges on correct configuration.
At a high level, the configuration helps the transformation achieve two goals: % TODO is ``ensures'' too strong if we don't prove it?

\begin{enumerate}
\item preserve the equivalence between \A and \B, and
\item produce well-typed terms.
\end{enumerate}
This configuration is a pair of pairs:

\begin{lstlisting}
((DepConstr, DepElim), (Eta, Iota))
\end{lstlisting}
each of which corresponds to one of the two goals, namely:

\begin{enumerate}
\item \lstinline{DepConstr} and \lstinline{DepElim} define how to transform constructors and eliminators, thereby preserving the equivalence (Section~\ref{sec:equivalence}), and 
\item \lstinline{Eta} and \lstinline{Iota} define how to transform $\eta$-expansion and $\iota$-reduction of these constructors and eliminators, thereby producing well-typed terms (Section~\ref{sec:equality}).
\end{enumerate}
Each of these is defined in terms of other terms in CIC$_{\omega}$ for any given equivalence.

\textbf{Configure} passes this configuration to \textbf{Transform}.
The four parts of this configuration must be in relation to one another in a certain way in order for the proof
term transformation to work correctly (Section~\ref{sec:art}).

\subsubsection{Equivalence}
\label{sec:equivalence}

The two configuration parts responsible for ensuring that the program transformation preserves equivalence
are \lstinline{DepConstr} (\textit{dependent constructors}) and \lstinline{DepElim} (\textit{dependent eliminators}).
These describe how to construct and eliminate \A and \B, wrapping the two types with a common inductive structure.
There must be the same number of dependent constructors and inductive hypotheses in dependent eliminators for both \A and \B,
even if \A and \B are inductive types with different numbers of constructors.
The idea is to port functions and proofs over \A to functions and proofs over \B by viewing \B as if it is an \A.
This way, the rest of the transformation can replace constructions of \A with constructions of \B and
inductive proofs about \A with inductive proofs about \B, but otherwise just recursively lift
the other subterms without changing the order or number of arguments.

\begin{figure}
\begin{minipage}{0.48\textwidth}
\begin{lstlisting}
DepConstr(0, list T) : list T :=
  Constr((@\codediff{0}@), list T).
DepConstr(1, list T) t l : list T :=
  Constr ((@\codediff{1}@), list T) t l.

DepElim(l, P) { p$_{\mathtt{nil}}$, p$_{\mathtt{cons}}$ } : P l :=
  Elim(l, P) { (@\codediff{p$_{\mathtt{nil}}$}@), (@\codediff{p$_{\mathtt{cons}}$}@) }.
\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}{0.48\textwidth}
\begin{lstlisting}
DepConstr(0, list T) : list T :=
  Constr((@\codediff{1}@), list T).
DepConstr(1, list T) t l : list T :=
  Constr((@\codediff{0}@), list T) t l.

DepElim(l, P) { p$_{\mathtt{nil}}$, p$_{\mathtt{cons}}$ } : P l :=
  Elim(l, P) { (@\codediff{p$_{\mathtt{cons}}$}@), (@\codediff{p$_{\mathtt{nil}}$}@) }.
\end{lstlisting}
\end{minipage}
\caption{The dependent constructors and eliminators for old (left) and new (right) \lstinline{list}.}
\label{fig:listconfig}
\end{figure}

For the \lstinline{list} change from Figure~\ref{fig:listswap},
the configuration that \toolname discovers uses the the dependent constructors
and eliminators in Figure~\ref{fig:listconfig}. The dependent constructors for \lstinline{Old.list}
are just the normal constructors \lstinline{nil} and \lstinline{cons} with the order unchanged,
while the dependent constructors for \lstinline{New.list} swap \lstinline{nil} and \lstinline{cons}
back to the original order.
Similarly, the dependent eliminator for \lstinline{Old.list} is just the normal eliminator for \lstinline{Old.list},
while the dependent eliminator for \lstinline{New.list} swaps the \lstinline{nil} and \lstinline{cons} cases.

When our types are not both inductive types, the constructors and eliminators can be \textit{dependent}.
One example of this arises from integrating the change from lists and $\Sigma$\lstinline{(n : nat).vector T n} that
\textsc{Devoid} supports into the \toolname framework.
We can configure the \toolname transformation to perform this same repair
by configuring the dependent constructors to \textit{pack} the index into an existential, for example:

\begin{lstlisting}
DepConstr(0, $\Sigma$(n : nat).vector T n) : $\Sigma$(n : nat).vector T n :=
  $\exists$ (Constr(0, nat)) (Constr(0, vector T)).
\end{lstlisting}
and by configuring the eliminator to eliminate over the projections:

\begin{lstlisting}
DepElim(s, P) { f$_0$ f$_1$ } : P ($\exists$ ($\pi_l$ s) ($\pi_r$ s)) :=
  Elim($\pi_r$ s, $\lambda$ (n : nat) (v : vector T n) . P ($\exists$ n v)) {
    f$_0$
    ($\lambda$ (t : T) (n : nat) (v : vector T n) . f$_1$ t ($\exists$ n v))
  }. 
\end{lstlisting}

In both of these examples, the only interesting work moves into the configuration:
the configuration for the swap example takes care of swapping constructors and cases,
and the configuration for the \textsc{Devoid} example implements the constructor and eliminator rules from the \textsc{Devoid} transformation.
That way, that the rest of the \toolname transformation does not need to add, drop, or reorder arguments at any point.
In essence, all of the difficult work moves into the configuration, but once it is done, it is done.
Furthermore, for both of the examples above, the \textsc{Configure} component of \toolname is able to discover \lstinline{DepConstr}
and \lstinline{DepElim} from just the types \A and \B, taking care of even the difficult work.

\subsubsection{Equality}
\label{sec:equality}

The other configuration parts \lstinline{Eta} and \lstinline{Iota} deal with transporting equalities.
A naive proof term transformation in a non-univalent language, as noted in \citet{tabareau2019marriage},
may fail to generate well-typed terms if it does not consider the problem of transporting equalities.
Otherwise, if the transformation transforms a term \lstinline{t : T} to some \lstinline{t' : T'}, it does not necessarily
hold that it transforms \lstinline{T} to \lstinline{T'}.

The two rules that correspond to this in the program transformation are \lstinline{Eta} and \lstinline{Iota},
which use configuration parts with the same name.
These together describe identity and equality as they relate to \lstinline{DepConstr} and \lstinline{DepElim}.
More formally, they define $\eta$-expansion and $\iota$-reduction over \lstinline{DepConstr} and \lstinline{DepElim},
which may be propositional rather than definitional, and so must be represented explicitly in the transformation.

\lstinline{Eta} describes how to $\eta$-expand the body of the identity function in a way that preserves equalities
coherently with the definitions of \lstinline{DepConstr} and \lstinline{DepElim}.
Note that this refers to $\eta$ over a given type, like $\eta$-expansion for $\Sigma$ types, and not to $\eta$-expansion of functions.
For example, for the change from list to \lstinline{$\Sigma$(n : nat).vector T n}, we have:

\begin{lstlisting}
Eta ($\Sigma$(n : nat).vector T n) :=
  $\lambda$ (s : $\Sigma$(n : nat).vector T n).$\exists$ (\$pi_l$ s) (\$pi_r$ s).
\end{lstlisting}
which corresponds to the strategic packing in the \textsc{Devoid} implementation to deal with
non-primitive projections not handled by the transformation. Thanks to this, we can forego the assumption from the \textsc{Devoid} transformation
that our language has primitive projections (definitional $\eta$ for $\Sigma$ types).

\begin{figure}
\begin{minipage}{0.48\textwidth}
   \lstinputlisting[firstline=1, lastline=8]{nattobin.tex}
\end{minipage}
\hfill
\begin{minipage}{0.48\textwidth}
   \lstinputlisting[firstline=10, lastline=17]{nattobin.tex}
\end{minipage}
\caption{Unary (left) and binary (right) natural numbers.}
\label{fig:nattobin}
\end{figure}

Each \lstinline{Iota}---one per constructor---describes and proves the $\iota$-reduction behavior
of \lstinline{DepElim} on the corresponding case. For example, with unary natural numbers defined in the standard way,
and using the standard eliminator over the natural numbers, the $\iota$ rules are definitional, since:

\begin{lstlisting}
nat.refold_elim_S:
  $\forall$ P p$_\texttt{0}$ p$_\texttt{S}$ n,
    DepElim((@\codediff{DepConstr(1, nat) n}@), P) { p$_\texttt{0}$ p$_\texttt{S}$ } = (@\codediff{p$_\texttt{S}$}@) n (DepElim(n, P) { p$_\texttt{0}$ p$_\texttt{S}$ }).
\end{lstlisting}
goes through by reflexivity.
However, this is no longer true for binary numbers \lstinline{N} as defined in the Coq standard library (Figure~\ref{fig:nattobin}).
So while we can in fact define \lstinline{DepConstr} and \lstinline{DepElim} to induce an equivalence
between them (see Section~\ref{sec:bin}), we run into trouble reasoning about applications of \lstinline{DepElim},
since the corresponding $\iota$ rule:

\begin{lstlisting}
N.refold_elim_S:
  $\forall$ P p$_\texttt{0}$ p$_\texttt{S}$ n,
    DepElim((@\codediff{DepConstr(1, N) n}@), P) { p$_\texttt{0}$ p$_\texttt{S}$ } = (@\codediff{p$_\texttt{S}$}@) n (DepElim(n, P) { p$_\texttt{0}$ p$_\texttt{S}$ }).
\end{lstlisting}
no longer holds by reflexivity.

The result of this is that proofs about \lstinline{nat} that hold by reflexivity
do not necessarily hold by reflexivity over \lstinline{N}. For example, in Coq,
while \lstinline{S (n + m) = S n + m} holds by reflexivity over \lstinline{nat},
when we define \lstinline{+} with our new dependent eliminator over \lstinline{N},
this no longer holds by reflexivity.
To transform proofs about \lstinline{nat} to proofs about \lstinline{N}, we must transform \textit{definitional} $\iota$-reduction over \lstinline{nat}
to explicit \textit{propositional} $\iota$-reduction over \lstinline{N}.
For our choice of equivalence in Section~\ref{sec:bin} between \lstinline{nat} and \lstinline{N}, the \lstinline{Iota} rules are trivial
for the base case and are exactly the proofs of theorems above for the succesor case.

Taken together over both \A and \B, \lstinline{Iota} describes how the inductive structures of \A and \B differ from one another.
The structures of \lstinline{DepElim} over \A and \B are always the same, so if \A and \B have the same 
inductive structure (if they are \textit{ornaments}~\cite{mcbride}),
then if $\iota$-reduction is definitional over \lstinline{DepElim} on \A, it will also be definitional on \B.
Otherwise, if \A and \B have different inductive structures, as with \lstinline{nat} and \lstinline{N},
then definitional $\iota$ over one would lift to propositional $\iota$ over the other.
The \lstinline{Iota} rule of the transformation encodes this fact.

For the case of \lstinline{nat} and \lstinline{N},
the need for explicit $\iota$ was noted as far back as \citet{magaud2000changing}.
What \textsc{Iota} does in the proof term transformation is encode this more generally for any change in inductive type.

\subsubsection{Equivalence \& Equality}
\label{sec:art}

Of course, both when designing a search procedure for an automatic configuration and when
configuring \toolname manually, choosing correct and useful configuration is important,
and it is not always straightforward. This section specifies what it means for these
to be correct and gives some intuition to why.
Section~\ref{sec:search} shows some useful example configurations.

The configuration ((\lstinline{DepConstr}, \lstinline{DepElim}), (\lstinline{Eta}, \lstinline{Iota})) instantiates
the proof term transformation to a particular equivalence between \A and \B.
Choosing an equivalence is a bit of an art:
there can be infinitely many equivalences that correpond to a 
given change in specification, only some of which are useful.
Beyond that, even once we have chosen an equivalence, we could define many possible configurations that correspond
to the equivalence, some of which will produce functions and proofs that are more useful or efficient than others.

Thankfully, once the art is done, we at least understand what it means for it to be \textit{correct art}.
The correctness criteria for the configuration relate \lstinline{DepConstr}, \lstinline{DepElim}, \lstinline{Eta}, and \lstinline{Iota}
in a way that preserves equivalence (Section~\ref{sec:equivalence}) coherently with equality (Section~\ref{sec:equality}).

To preserve equivalence, we need that \lstinline{DepElim} and \lstinline{DepConstr} together induce an equivalence between \A and \B,
formed by one function that eliminates \A and constructs \B, and another function that eliminates \B and constructs \A:

\begin{lstlisting}
f : A -> B := DepElim(a, $\lambda$(a : A).B){ $\lambda$ ... DepConstr(0, B) ..., ... }
g : B -> A := DepElim(b, $\lambda$(b : B).A){ $\lambda$ ... DepConstr(0, A) ..., ... }
\end{lstlisting}
Each search procedure that \textbf{Configure} implements discovers these functions and produces a proof in Coq that these functions form an equivalence.
In addition, we need that:

\begin{enumerate} % TODO make more formal, and check if we need to say it induces particular equivalence
\item $\forall$ \lstinline{j}, \lstinline{DepConstr(j, A)} is equal to \lstinline{DepConstr(j, B)} up to transport along that equivalence, and
\item $\forall$ \lstinline{(a : A) (b : B) (P : A -> Type) (Q : B -> Type)}, if \lstinline{a} is equal to \lstinline{b} and \lstinline{P} is equal to \lstinline{Q} up to transport along that equivalence,
then \lstinline{DepElim(a, P)} is equal to \lstinline{DepElim(b, Q)} up to transport along that equivalence.
\end{enumerate}
The intuition for this is based on insights from \textsc{Devoid},
and is proven on an example from \textsc{Devoid} in the univalent parametricity framework.\footnote{\url{https://github.com/CoqHott/univalent_parametricity/commit/7dc14e69942e6b3302fadaf5356f9a7e724b0f3c}}
Essentially, that these are equal up to transport along the equivalence means that replacing dependent constructors (respectively eliminators) of \A
with dependent constructions (respectively eliminators) of \B will preserve equality up to transport for those particular subterms.
Furthermore, since CIC$_{\omega}$ is a constructive logic, the \textit{only} way to construct an \A (respectively \B) is to use its constructors,
and the \textit{only} way to match over an \A (respectively \B) is to apply its eliminator.
Finally, since these form an equivalence, all ways of constructing or eliminating \A and \B are covered by these dependent constructors and eliminators.
So, as long as we are able to identify and expand all implicit applications of \lstinline{DepConstr} and \lstinline{DepElim},
\textsc{Dep-Constr} and \textsc{Dep-Elim} preserve correctness of the transformation and cover all constructions and eliminations of \A and \B.

To ensure coherence with equality, we need \lstinline{Eta} and \lstinline{Iota} to correctly prove the $\eta$ and $\iota$ rules
over \lstinline{DepConstr} and \lstinline{DepElim}.
For \lstinline{Eta}, we need it to have the same definitional behavior as the
eliminator, in other words:

\begin{lstlisting}
DepElim(a, P) { f$_0$, ..., f$_n$ } : P (Eta(A) a)
\end{lstlisting}
and similarly for \B. % TODO do we need anything for DepConstr?

Each \lstinline{Iota} needs to prove and rewrite along the simplification or refolding behavior that corresponds to a case of the dependent eliminator, in other words: % TODO do we need eta here?

\begin{lstlisting}
Iota(A) :
  $\forall$ P $\vec{f}$ $\vec{x}$ (Q : P (DepConstr(j, A) $\vec{x}$) $\rightarrow$ Type),
    Q (DepElim((@\codediff{DepConstr(j, A) $\vec{x}$}@), P) $\vec{f}$ $\rightarrow$ 
    Q ((@\codediff{$\vec{f}$[j]}@) ... (DepElim(IH$_0$, P) $\vec{f}$) ... (DepElim(IH$_n$, P) $\vec{f}$) ...)
\end{lstlisting}
where each \lstinline{IH}$_i$ is each recursive occurrence of \A in the eliminator case,
and similarly for \B.
Together, these induce proofs of \lstinline{section} and \lstinline{retraction} (used in conjunction with
induction and rewriting).
The intuition here is that it should be enough to preserve the reduction behavior
of the eliminators and constructors, since again those are the only ways we can construct or eliminate our types.

It can be difficult to prove the correctness criteria for the configuration---proving equality of the dependent eliminators
up to transport, for example, requires either a special framework~\cite{tabareau2017equivalences}
or a univalent type theory~\cite{univalent2013homotopy}.
Thankfully, the user does not need to prove the correctness criteria for a configuration in order to use \toolname.
Rather, the correctness criteria simply need to hold in order for the proof term transformation to work correctly.

\subsection{The Proof Term Transformation}
\label{sec:generic}

\begin{figure}
\begin{mathpar}
\mprset{flushleft}
\small
\hfill\fbox{$\Gamma$ $\vdash$ $t$ $\Uparrow$ $t'$}\\

\inferrule[Dep-Elim]
  { \Gamma \vdash a \Uparrow b \\ \Gamma \vdash p_{a} \Uparrow p_b \\ \Gamma \vdash \vec{f_{a}}\phantom{l} \Uparrow \vec{f_{b}} }
  { \Gamma \vdash \mathrm{DepElim}(a,\ p_{a}) \vec{f_{a}} \Uparrow \mathrm{DepElim}(b,\ p_b) \vec{f_{b}} }

\inferrule[Dep-Constr]
{ \Gamma \vdash \vec{t}_{a} \Uparrow \vec{t}_{b} } %\\ TODO must we explicitly lift A to B if we want to handle parameters/indices?
{ \Gamma \vdash \mathrm{DepConstr}(j,\ A)\ \vec{t}_{a} \Uparrow \mathrm{DepConstr}(j,\ B)\ \vec{t}_{b}  }

\inferrule[Eta]
  { \\ }
  { \Gamma \vdash \mathrm{Eta}(A) \Uparrow \mathrm{Eta}(B) }

\inferrule[Iota]
  { \Gamma \vdash c_A \Uparrow c_B \\ \Gamma \vdash q_A \Uparrow q_B \\ \Gamma \vdash e_A \Uparrow e_B }
  { \Gamma \vdash \mathrm{Iota}(j,\ A,\ q_A,\ t_A) \Uparrow \mathrm{Iota}(j,\ B,\ q_B,\ t_B) }

\inferrule[Equivalence]
  { \\ }
  { \Gamma \vdash A\ \Uparrow B }

\inferrule[Constr]
{ \Gamma \vdash T \Uparrow T' \\ \Gamma \vdash \vec{t} \Uparrow \vec{t'} }
{ \Gamma \vdash \mathrm{Constr}(j,\ T)\ \vec{t} \Uparrow \mathrm{Constr}(j,\ T')\ \vec{t'} }

\inferrule[Ind]
  { \Gamma \vdash T \Uparrow T' \\ \Gamma \vdash \vec{C} \Uparrow \vec{C'}  }
  { \Gamma \vdash \mathrm{Ind} (\mathit{Ty} : T) \vec{C} \Uparrow \mathrm{Ind} (\mathit{Ty} : T') \vec{C'} }

\inferrule[Elim] % TODO wait why do we have c here when it clearly refers to the term we eliminate over? um
  { \Gamma \vdash c \Uparrow c' \\ \Gamma \vdash Q \Uparrow Q' \\ \Gamma \vdash \vec{f} \Uparrow \vec{f'}}
  { \Gamma \vdash \mathrm{Elim}(c, Q) \vec{f} \Uparrow \mathrm{Elim}(c', Q') \vec{f'}  }

%% Application
\inferrule[App]
 { \Gamma \vdash f \Uparrow f' \\ \Gamma \vdash t \Uparrow t'}
 { \Gamma \vdash f t \Uparrow f' t' }

% Lamda
\inferrule[Lam]
  { \Gamma \vdash T \Uparrow T' \\ \Gamma,\ t : T \vdash b \Uparrow b' }
  {\Gamma \vdash \lambda (t : T).b \Uparrow \lambda (t : T').b'}

% Product
\inferrule[Prod]
  { \Gamma \vdash T \Uparrow T' \\ \Gamma,\ t : T \vdash b \Uparrow b' }
  {\Gamma \vdash \Pi (t : T).b \Uparrow \Pi (t : T').b'}
\end{mathpar}
\caption{Proof term transformation.}
\label{fig:final}
\end{figure}

Figure~\ref{fig:final} shows the proof term transformation that forms the core of \toolname.
Like the transformation from \textsc{Devoid}, this transformation is parameterized over
two equivalent types \A and \B (\textsc{Equivalence}) and assumes fully expanded terms.
In addition, it is parameterized over the configuration (\lstinline{DepConstr}, \lstinline{DepElim}, \lstinline{Eta}, and \lstinline{Iota}),
which appear in the proof term transformation as metavariables.

The goal of the proof term transformation is to preserve that equivalence in some way, while no longer referring to the old specification.
That is, for equivalent types \A and \B, the transformation takes as input functions and proofs
that refer to \A and returns functions and proofs that refer to \B.
Furthermore, the transformed functions behave the same way as the input functions,
and the transformed proofs talk about the same things as the input proofs.

\begin{figure}
\begin{minipage}{0.48\textwidth}
\begin{lstlisting}
$\lambda$ (T : Type) (l m : list T) .
 Elim (l, $\lambda$(l: list T).list T $\rightarrow$ list T))
 {
   (@\codediff{($\lambda$ m . m)}@),
   ($\lambda$ t _ IHl m.
      Constr((@\codediff{1}@), list T) t (IHl m))
 } m.
\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}{0.48\textwidth}
\begin{lstlisting}
$\lambda$ (T : Type) (l m : list T) .
 Elim (l, $\lambda$(l: list T).list T $\rightarrow$ list T))
 {
   ($\lambda$ t _ IHl m.
      Constr((@\codediff{0}@), list T) t (IHl m)),
   (@\codediff{($\lambda$ m . m)}@)
 } m.
\end{lstlisting}
\end{minipage}
\caption{The list append function before (left) and after (right) repair.}
\label{fig:appswap1}
\end{figure}

\begin{figure}
\begin{minipage}{0.48\textwidth}
\begin{lstlisting}
$\lambda$ (T : Type) (l m : list T) .
 Elim
   (l, $\lambda$(l: list T).list T $\rightarrow$ list T))
 {
   ($\lambda$ m . m)
   ($\lambda$ t _ IHl m.
      Constr(1, list T) t (IHl m))
 } m.
\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}{0.48\textwidth}
\begin{lstlisting}
$\lambda$ (T : Type) (l m : list T) .
 (@\codediff{DepElim}@)
   (l, $\lambda$(l: list T).list T $\rightarrow$ list T))
 {
   ($\lambda$ m . m)
   ($\lambda$ t _ IHl m.
      (@\codediff{DepConstr}@)(1, list T) t (IHl m))
 } m.
\end{lstlisting}
\end{minipage}
\caption{The original list append function (left) and the same function rewritten to use \lstinline{DepConstr} (right).}
\label{fig:appswap2}
\end{figure}

To update the append function \lstinline{++} from the left of Figure~\ref{fig:appswap1}, \toolname
identifies implicit applications of \lstinline{DepConstr} and \lstinline{DepElim} and expands them (Figure~\ref{fig:appswap2}).
The transformation then just recursively substitutes in the updated \lstinline{list} type
for the original \lstinline{list} type, which moves \lstinline{DepConstr} and \lstinline{DepElim}
to construct and eliminate over the updated type.
Finally, this reduces to the term on the right of Figure~\ref{fig:appswap1}.
Transforming proofs works the same way.

Both versions of append behave identically up to the equivalence from Figure~\ref{fig:equivalence}, since:

\begin{lstlisting}
$\forall$ T (l1 l2 : Old.list T), f T (l1 ++ l2) = (f T l1) ++ (f T l2).
\end{lstlisting}
by induction and rewriting, and similarly in the opposite direction.
Our transformed proof \lstinline{rev_app_distr} then proves the same thing the same way
as the original proof up to the same equivalence---and up to the corresponding changes in \lstinline{++}
and \lstinline{rev}.

More formally, the output of the proof term transformation ought to be equal to the input of the program transformation
\textit{up to transport} along the equivalence between \A and \B that the configuration instantiates it to.
This is the same as the correctness criterion for the program transformation from \textsc{Devoid} that this is based on,
with the transformation generalized to handle other equivalences beyond the class that \textsc{Devoid} supports.
The key steps in this transformation that make this possible are porting functions and proofs along the configuration corresponding
to a particular equivalence ((\textsc{Dep-Constr}, \textsc{Dep-Elim}), (\textsc{Eta}, and \textsc{Iota})).
From there, rest of the transformation is straightforward.

Note that this correctness criterion is metatheoretical:
stating and proving that two terms are in equal up to transport is in general not possible in a language like Coq
without additional axioms, though it is in some cases realizable with an external tool~\cite{tabareau2017equivalences}.
\toolname does not yet generate these proofs as we were focused on building a usable tool with axiomatic freedom and few dependencies.
Coq ensures that all terms that plugins produce are well-typed; for now, as with \textsc{Devoid}, the proof engineer must vet the transformed
specifications herself.

\subsection{The Tool}
\label{sec:implementation}

The configurable proof term transformation helped us build a flexible proof repair and reuse tool.
However, it alone was not enough to build a tool that reaches real users.
This section describes a sample of the implementation challenges that we encountered and how we solved them.
Section~\ref{sec:discussion} elaborates on the remaining challenges and our plans to address them in the future.

\paragraph{From CIC$_{\omega}$ to Coq}

Like \textsc{Devoid}, we also had to handle language differences to scale from CIC$_{\omega}$ to Coq.
We use the same \lstinline{Preprocess} command that \textsc{Devoid} uses to turn pattern matching and fixpoints into applications of eliminators.
We generalize the work from \textsc{Devoid} to handle Coq's non-primitive projections into our \lstinline{Eta} rule.
We move the work of refolding constants into the configuration for each search procedure, so that it does not
cloud the proof term transformation itself.

\paragraph{Matching Against Preconditions}

It is easy to \textit{describe} the proof term transformation, but it is much more difficult to implement it.
This is because the proof term transformation only describes what transformation rules are applicable when,
but it does not describe how to actually check that the precondition holds.
In many cases, this check is not purely syntactic---we really want to know if a term \textit{unifies}
with an application of \lstinline{DepConstr}, for example, not whether it applies the term exactly.
This is especially pronounced with \lstinline{Eta} and \lstinline{Iota},
which typically show up contracted in real code.
This problem is exactly why \citet{tabareau2019marriage} speculated that converting definitional to propositional equalities
like we do with \lstinline{Iota} may, in general, be intractable.

In practice, we find that unification is often not enough to identify an implicit application of one of the configuration terms.
Each of our search procedures for automatic configuration in turn implements special rewrite rules that tell \toolname
how to identify and expand these implicit applications before applying the transformation.
There is not yet a way for proof engineers themselves to supply these custom rewrite rules,
so sometimes in order to use \toolname with manual configuration, proof engineers must manually expand
input terms to explicitly apply parts of the configuration like \lstinline{Iota}.
This can be challenging, so we plan to give proof engineers the opportunity to write
these custom rewrite rules themselves in the future.

\paragraph{Termination \& Intent}

Another challenge with implementing the proof term transformation is deciding whether to run a rule that matches at all.
That is, when the correctness criteria for a configuration hold and a subterm matches a rule, this suggests that \toolname \textit{can}
run the transformation rule, but it does not necessarily mean that it \textit{should}.
In some cases, repeatedly running a matching transformation rule would result in nontermination.
For example, if our type \B is a refinement of our type \A, then we can always run \textsc{Equivalence}
over and over again, forever.
\textsc{Devoid} ruled out this case by simply prohibiting the case where \B refers to \A, but we found it sometimes
useful in practice to support that case.
To support this, we include some simple termination checks in our code.

More generally, even when termination is guaranteed, whether to run a matching transformation rule
depends on the intent of the user.
For example, our industrial proof engineer sometimes wished to port only some occurrences of \A,
especially when \A was a tuple like \lstinline{(nat * bool)} that could feasibly appear elsewhere in the term
but have a different meaning.
We helped the proof engineer do this by interacting with \toolname using a particular workflow.
We plan to support this automatically using type-directed search in the future.

\paragraph{Reaching Real Users}
Many of our design decisions in implementing \toolname were informed by our partnership with
an industrial user.
For example, we found that our industrial user rarely had the patience to wait more than ten seconds
for \toolname to port a function or proof.
In response, we implemented very aggressive caching (with an option to disable the cache), even caching intermediate subterms that
we encounter in the course of running our program transformation.
We also added the option to set certain terms or even entire modules as opaque to \toolname, to prevent
unecessary $\delta$-reduction of constants.
We included many other optimizations, including lazy $\eta$-expansion of terms like \textsc{Devoid}.

User experiences also informed features that we exposed to users.
For example, all of our search procedures for configurations generate proofs that the discovered
equivalence actually is an equivalence, using functionality that expands on the same functionality from \textsc{Devoid}.
We also implemented special search procedures to generate custom eliminators to make it easier to reason about
types that we found common for certain search procedures.
For example, \toolname generates a custom eliminator automatically to reason about \{\lstinline{l : list T & length l = n}\}
and other similar types by breaking it into parts and reasoning seperately about the two projections.
These features along with our tactic decompiler helped with integration into proof engineering workflows.

%First we need that \lstinline{DepElim} over $A$ into \lstinline{DepConstr} over $B$ and \lstinline{DepElim} over $B$ into
%\lstinline{DepConstr} over $A$ form an equivalence between $A$ and $B$. When that's true, I think it should hold that \lstinline{DepElim} over $A$
%and \lstinline{DepElim} over $B$ are in univalent relation with one another. If not, then that's an extra condition.
%Finally, we need the transformation to preserve definitional equalities. Not sure about the general case, but for vectors and lists,
%we need:

%\begin{lstlisting}
%  $\forall$ A l (f : $\forall$ (l : sigT (Vector.t A)), l = l),
%    vect_dep_elim A (fun l => l = l) (f nil) (fun t s _ => f (cons t s)) l = f (id_eta l).
%\end{lstlisting}
%and:

%\begin{lstlisting}
%Definition elim_id (A : Type) (s : {H : nat & t A H}) :=
%  vect_dep_elim
%    A
%    (fun _ => {H : nat & t A H})
%    nil
%    (fun (h : A) _ IH =>
%      cons h IH)
%    s.

% $\forall$ A h s,
%    exists (H : cons h (elim_id A s) = elim_id A (cons h s)),
%      H = eq_refl.
%\end{lstlisting}
%More generally, for each constructor index $j$, define:

%\begin{lstlisting}
%  eqc (j, B) (f : $\forall$ b : B, b = b) :=
%    fun ... (* TODO get the hypos from the type of the eliminator *) =>
%      f (DepConstr (j, B)) (* TODO args *)%%

  %elim_id := (* TODO *)
%\end{lstlisting}
%Then we need:

%\begin{enumerate}
%\item $\forall b f, \mathrm{DepElim}(b,\ p_{b}) \{\mathrm{eqc} (1, B) f, \ldots, \mathrm{eqc} (n, B) f\} = f (\mathrm{Eta}(A) a) $
%\item Something relating the constructors and \lstinline{elim_id} to reflexivity
%\end{enumerate}
%and similarly for $A$.

%Really the point of these conditions is that from them, with some restrictions on input terms, we can get
%that lifting terms gives us the same type that we'd get from lifting the type. But there are still
%some restrictions (see the few that fail).

%It's probably not always possible to define these three things for every equivalence.
%Could generalize by rewriting. But this lets us avoid the rewriting problem from Nicolas' paper.

% TODO how does this get us something like primitive projections? Just makes Eta definitionally equal to regular Id?

% TODO so we can probably just frame search in terms of DepConstr and DepElim and then generate proofs about this on an ad-hoc basis
% and get away with not including the specific details of our instantiations. We can give examples instead, give intuition, and say we generate
% the proofs in Coq

%For the second one we need not just an eliminator rule but also an identity rule.
%DEVOID assumed primitive projections which let them get away without thinking of this,
%but then had this weirdly ad-hoc ``repacking'' thing in their implementation.
%It turns out this is just a more general identity rule, which basically says what
%the identity function should lift to so that the transformation preserves definitional equalities.
%Actually deciding when to run this rule is one of the biggest challenges in practice,
%so we'll talk about that more in the implementation section.


\section{A Configurable Proof Term Transformation}
\label{sec:key2}

At the heart of \toolname is a configurable proof term transformation for transporting
proofs across equivalences. This is based on the proof term transformation from 
\textsc{Devoid}~\cite{Ringer2019}, which solved this problem for a particular class of equivalences.
The goal of \toolname is to do the same thing over a much broader set of changes, and with better workflow integration.
We were able to generalize the \textsc{Devoid} algorithm to do this.

\begin{quote}
\textbf{Insight 2}:
The proof term transformation from an existing proof reuse tool can be generalized
to build such a proof repair tool that can handle 
many different kinds of changes.
\end{quote}

This section starts by introducing the configuration (Section~\ref{sec:configurable}),
then introduces the proof term transformation that builds on that (Section~\ref{sec:generic}).
It then gives intuition for what it means for a configuration to be correct (Section~\ref{sec:art}),
and finally describes the additional work needed to go from this transformation to the implementation (Section~\ref{sec:implementation}). 

\paragraph{Conventions}
All terms that we introduce in this section are in CIC$_{\omega}$ with primitive eliminators,
the syntax for which is in Figure~\ref{fig:syntax}.
The typing rules are standard.
Throughout, we use $\vec{i}$ and $\{t_1, \ldots, t_n\}$ to denote lists of terms.

\begin{figure}
\small
\begin{grammar}
<i> $\in \mathbbm{N}$, <v> $\in$ Vars, <s> $\in$ \{ Prop, Set, Type<i> \}

<t> ::= <v> | <s> | $\Pi$ (<v> : <t>) . <t> | $\lambda$ (<v> : <t>) . <t> | <t> <t> | \\ 
Ind (<v> : <t>)\{<t>,\ldots,<t>\} | Constr (<i>, <t>) | Elim(<t>, <t>)\{<t>,\ldots,<t>\}
\end{grammar}
\vspace{-0.3cm}
\caption{Syntax for CIC$_\omega$, from \citet{Timany2015FirstST}.}
\label{fig:syntax}
\end{figure}

\subsection{The Configuration}
\label{sec:configurable}

The configuration is the key to building a proof term transformation that can support many different classes of changes.
%Before introducing the proof term transformation, we will describe the configuration, which in effect specifies the behavior
%of the transformation.
It instantiates the proof term transformation to two equivalent types \A and \B, so that the proof term transformation
can transform terms defined over \A to terms defined over \B instead.
%The behavior of the proof term transformation at a particular equivalence hinges on correct configuration.
At a high level, the configuration helps the transformation achieve two goals:

\begin{enumerate}
\item preserve equality up to transport along the equivalence between \A and \B, and
\item produce well-typed terms.
\end{enumerate}
This configuration is a pair of pairs:

\begin{lstlisting}
((DepConstr, DepElim), (Eta, Iota))
\end{lstlisting}
each of which corresponds to one of the two goals, namely:

\begin{enumerate}
\item \lstinline{DepConstr} and \lstinline{DepElim} define how to transform constructors and eliminators, thereby preserving the equivalence (Section~\ref{sec:equivalence}), and 
\item \lstinline{Eta} and \lstinline{Iota} define how to transform $\eta$-expansion and $\iota$-reduction of these constructors and eliminators, thereby producing well-typed terms (Section~\ref{sec:equality}).
\end{enumerate}
Each of these is defined in CIC$_{\omega}$ for any given equivalence.
\textbf{Configure} passes this configuration to \textbf{Transform}.
The four parts of this configuration must be in relation to one another in a certain way in order for the proof
term transformation to work correctly (Section~\ref{sec:art}).

\subsubsection{Preserving the Equivalence}
\label{sec:equivalence}

The two configuration parts responsible for preserving the
equivalence are \lstinline{DepConstr}
and \lstinline{DepElim} (\textit{dependent constructors and eliminators}).
These describe how to construct and eliminate \A and \B, wrapping the types with a common inductive structure.
There must be the same number of dependent constructors and inductive hypotheses in dependent eliminators for \A and \B,
even if \A and \B are types with different numbers of constructors.
The idea is to port terms \A to terms over \B by viewing \B as if it is an \A.
This way, the rest of the transformation can replace values of \A with values of \B and
inductive proofs about \A with inductive proofs about \B, then recursively transform
subterms without changing the order or number of arguments.

\begin{figure}
\begin{minipage}{0.48\textwidth}
\begin{lstlisting}
DepConstr(0, list T) : list T :=(@\vspace{-0.04cm}@)
  Constr((@\codediff{0}@), list T).(@\vspace{-0.04cm}@)
DepConstr(1, list T) t l : list T :=(@\vspace{-0.04cm}@)
  Constr ((@\codediff{1}@), list T) t l.(@\vspace{-0.04cm}@)
(@\vspace{-0.14cm}@)
DepElim(l, P) { p$_{\mathtt{nil}}$, p$_{\mathtt{cons}}$ } : P l :=(@\vspace{-0.04cm}@)
  Elim(l, P) { (@\codediff{p$_{\mathtt{nil}}$}@), (@\codediff{p$_{\mathtt{cons}}$}@) }.
\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}{0.48\textwidth}
\begin{lstlisting}
DepConstr(0, list T) : list T :=(@\vspace{-0.04cm}@)
  Constr((@\codediff{1}@), list T).(@\vspace{-0.04cm}@)
DepConstr(1, list T) t l : list T :=(@\vspace{-0.04cm}@)
  Constr((@\codediff{0}@), list T) t l.(@\vspace{-0.04cm}@)
(@\vspace{-0.14cm}@)
DepElim(l, P) { p$_{\mathtt{nil}}$, p$_{\mathtt{cons}}$ } : P l :=(@\vspace{-0.04cm}@)
  Elim(l, P) { (@\codediff{p$_{\mathtt{cons}}$}@), (@\codediff{p$_{\mathtt{nil}}$}@) }.
\end{lstlisting}
\end{minipage}
\vspace{-0.3cm}
\caption{The dependent constructors and eliminators for old (left) and new (right) \lstinline{list}.}
\label{fig:listconfig}
\end{figure}

For the \lstinline{list} change from Section~\ref{sec:overview},
the configuration that \toolname discovers uses the dependent constructors
and eliminators in Figure~\ref{fig:listconfig}. The dependent constructors for \lstinline{Old.list}
are the normal constructors \lstinline{nil} and \lstinline{cons} with the order unchanged,
while the dependent constructors for \lstinline{New.list} swap \lstinline{nil} and \lstinline{cons}
back to the original order.
Similarly, the dependent eliminator for \lstinline{Old.list} is the normal eliminator for \lstinline{Old.list},
while the dependent eliminator for \lstinline{New.list} swaps 	cases.

These constructors and eliminators can be \textit{dependent}.
One example of this arises from integrating the change from lists and $\Sigma$\lstinline{(n : nat).vector T n} that
\textsc{Devoid} supports into the \toolname framework.
\toolname includes a search procedure that automatically configures the \toolname  
transformation to perform this same repair.
It does this by configuring the dependent constructors to pack the index into an existential, for example (letting $\exists$ denote the constructor for $\Sigma$ types):

\begin{lstlisting}
DepConstr(0, $\Sigma$(n : nat).vector T n) : $\Sigma$(n : nat).vector T n :=(@\vspace{-0.04cm}@)
  $\exists$ (Constr(0, nat)) (Constr(0, vector T)).
\end{lstlisting}
and by configuring the eliminator to eliminate over the projections:

\begin{lstlisting}
DepElim(s, P) { f$_0$ f$_1$ } : P ($\exists$ ($\pi_l$ s) ($\pi_r$ s)) :=(@\vspace{-0.04cm}@)
  Elim($\pi_r$ s, $\lambda$ (n : nat) (v : vector T n) . P ($\exists$ n v)) {(@\vspace{-0.04cm}@)
    f$_0$,(@\vspace{-0.04cm}@)
    ($\lambda$ (t : T) (n : nat) (v : vector T n) . f$_1$ t ($\exists$ n v))(@\vspace{-0.04cm}@)
  }. 
\end{lstlisting}

In both of these examples, the only interesting work moves into the configuration:
the configuration for the swap example swaps constructors and cases,
and the configuration for the \textsc{Devoid} example implements the constructor and eliminator rules from the \textsc{Devoid} transformation.
That way, the rest of the \toolname transformation does not need to add, drop, or reorder arguments.
In essence, all of the difficult work moves into the configuration.
Furthermore, both examples use automatic configuration, which means that the \textsc{Configure} component of \toolname is able to 
discover \lstinline{DepConstr} and \lstinline{DepElim} from just the types \A and \B, taking care of even the difficult work.

\subsubsection{Producing Well-Typed Terms}
\label{sec:equality}

The other configuration parts \lstinline{Eta} and \lstinline{Iota} deal with producing well-typed terms,
in particular by transporting equalities.
A naive proof term transformation in a non-univalent language, as noted in \citet{tabareau2019marriage},
may fail to generate well-typed terms if it does not consider the problem of transporting equalities.
Otherwise, if the transformation transforms a term \lstinline{t : T} to some \lstinline{t' : T'}, it does not necessarily
hold that it transforms \lstinline{T} to \lstinline{T'}.

\lstinline{Eta} and \lstinline{Iota} describe how to transport equalities.
More formally, they define $\eta$-expansion and $\iota$-reduction of \A and \B,
which may be propositional rather than definitional, and so must be explicit in the transformation.
$\eta$-expansion describes how to expand a term to apply a constructor to an eliminator in a way that preserves propositional equality,
and is important for defining dependent eliminators~\cite{nlab:eta-conversion}.
$\iota$-reduction ($\beta$-reduction for inductive types) describes how to reduce an elimination of a constructor~\cite{nlab:beta-reduction}.

\begin{figure}
\begin{minipage}{0.48\textwidth}
   \lstinputlisting[firstline=1, lastline=8]{nattobin.tex}
\end{minipage}
\hfill
\begin{minipage}{0.48\textwidth}
   \lstinputlisting[firstline=10, lastline=17]{nattobin.tex}
\end{minipage}
\vspace{-0.3cm}
\caption{Unary (left) and binary (right) natural numbers.}
\label{fig:nattobin}
\end{figure}

The configuration (see Section~\ref{sec:dep}) for to the change from \lstinline{list} to \lstinline{$\Sigma$(n : nat).vector T n} has propositional \lstinline{Eta}.
To describe \lstinline{Eta}, it is enough to use the standard definition of $\eta$-expansion for $\Sigma$:

\begin{lstlisting}
Eta ($\Sigma$(n : nat).vector T n) := $\lambda$ (s : $\Sigma$(n : nat).vector T n).$\exists$ ($\pi_l$ s) ($\pi_r$ s).
\end{lstlisting}
which is propositional and not definitional in Coq.
Thanks to this, we can forego the assumption from the \textsc{Devoid} transformation
that our language has primitive projections (definitional $\eta$ for $\Sigma$).

Each \lstinline{Iota}---one per constructor---describes and proves the $\iota$-reduction behavior
of \lstinline{DepElim} on the corresponding case.
This is needed, for example, to port proofs about unary numbers \lstinline{nat} to
proofs about binary numbers \lstinline{N} (Figure~\ref{fig:nattobin}).
While we can in fact define \lstinline{DepConstr} and \lstinline{DepElim} to induce an equivalence
between them (see Section~\ref{sec:bin}), we run into trouble reasoning about applications of \lstinline{DepElim},
since proofs about \lstinline{nat} that hold by reflexivity do not necessarily hold by reflexivity over \lstinline{N}. 
For example, in Coq, while \lstinline{S (n + m)  = S n + m} holds by reflexivity over \lstinline{nat},
when we define \lstinline{+} with \lstinline{DepElim} over \lstinline{N},
the corresponding theorem over \lstinline{N} does not hold by reflexivity.

To transform proofs about \lstinline{nat} to proofs about \lstinline{N}, we must transform \textit{definitional} $\iota$-reduction over \lstinline{nat} to explicit \textit{propositional} $\iota$-reduction over \lstinline{N}.
For our choice of configuration in Section~\ref{sec:bin},
$\iota$-reduction is definitional over \lstinline{nat}, since a proof of:

\begin{lstlisting}
$\forall$ P p$_\texttt{0}$ p$_\texttt{S}$ n, DepElim((@\codediff{DepConstr(1, nat) n}@), P) { p$_\texttt{0}$ p$_\texttt{S}$ } = (@\codediff{p$_\texttt{S}$}@) n (DepElim(n, P) { p$_\texttt{0}$ p$_\texttt{S}$ }).
\end{lstlisting}
goes through by reflexivity.
However, the corresponding $\iota$ rule for \lstinline{N} is propositional, since:

\begin{lstlisting}
$\forall$ P p$_\texttt{0}$ p$_\texttt{S}$ n, DepElim((@\codediff{DepConstr(1, N) n}@), P) { p$_\texttt{0}$ p$_\texttt{S}$ } = (@\codediff{p$_\texttt{S}$}@) n (DepElim(n, P) { p$_\texttt{0}$ p$_\texttt{S}$ }).
\end{lstlisting}
no longer holds by reflexivity.
Thus, the \lstinline{Iota} rules are trivial
for the base case and are exactly rewrites along the proofs of theorems above for the successor case.
The transformation replaces rewrites by reflexivity over \lstinline{nat} to rewrites by propositional equalities over \lstinline{N},
that way the dependent eliminators behave the same way over \lstinline{nat} and \lstinline{N}.

Taken together over both \A and \B, \lstinline{Iota} describes how the inductive structures of \A and \B differ from each other.
The structures of \lstinline{DepElim} over \A and \B are always the same, so if \A and \B have the same 
inductive structure (if they are \textit{ornaments}~\cite{mcbride}),
then if $\iota$-reduction is definitional over \lstinline{DepElim} on \A, it will also be definitional on \B.
Otherwise, if \A and \B have different inductive structures, as with \lstinline{nat} and \lstinline{N},
then definitional $\iota$ over one would become propositional $\iota$ over the other.
For the case of \lstinline{nat} and \lstinline{N},
the need for explicit $\iota$ was noted as far back as \citet{magaud2000changing}.
What \lstinline{Iota} does in the configuration is encode this more generally.

\subsection{The Proof Term Transformation}
\label{sec:generic}

\begin{figure}
\begin{mathpar}
\mprset{flushleft}
\small
\hfill\fbox{$\Gamma$ $\vdash$ $t$ $\Uparrow$ $t'$}\vspace{-0.4cm}\\

\inferrule[Dep-Elim]
  { \Gamma \vdash a \Uparrow b \\ \Gamma \vdash p_{a} \Uparrow p_b \\ \Gamma \vdash \vec{f_{a}}\phantom{l} \Uparrow \vec{f_{b}} }
  { \Gamma \vdash \mathrm{DepElim}(a,\ p_{a}) \vec{f_{a}} \Uparrow \mathrm{DepElim}(b,\ p_b) \vec{f_{b}} }

\inferrule[Dep-Constr]
{ \Gamma \vdash \vec{t}_{a} \Uparrow \vec{t}_{b} } %\\ TODO must we explicitly lift A to B if we want to handle parameters/indices?
{ \Gamma \vdash \mathrm{DepConstr}(j,\ A)\ \vec{t}_{a} \Uparrow \mathrm{DepConstr}(j,\ B)\ \vec{t}_{b}  }

\inferrule[Eta]
  { \\ }
  { \Gamma \vdash \mathrm{Eta}(A) \Uparrow \mathrm{Eta}(B) }

\inferrule[Iota]
  { \Gamma \vdash q_A \Uparrow q_B \\ \Gamma \vdash t_A \Uparrow t_B }
  { \Gamma \vdash \mathrm{Iota}(j,\ A,\ q_A,\ t_A) \Uparrow \mathrm{Iota}(j,\ B,\ q_B,\ t_B) }

\inferrule[Equivalence]
  { \\ }
  { \Gamma \vdash A\ \Uparrow B }

\inferrule[Constr]
{ \Gamma \vdash T \Uparrow T' \\ \Gamma \vdash \vec{t} \Uparrow \vec{t'} }
{ \Gamma \vdash \mathrm{Constr}(j,\ T)\ \vec{t} \Uparrow \mathrm{Constr}(j,\ T')\ \vec{t'} }

\inferrule[Ind]
  { \Gamma \vdash T \Uparrow T' \\ \Gamma \vdash \vec{C} \Uparrow \vec{C'}  }
  { \Gamma \vdash \mathrm{Ind} (\mathit{Ty} : T) \vec{C} \Uparrow \mathrm{Ind} (\mathit{Ty} : T') \vec{C'} }

%% Application
\inferrule[App]
 { \Gamma \vdash f \Uparrow f' \\ \Gamma \vdash t \Uparrow t'}
 { \Gamma \vdash f t \Uparrow f' t' }

\inferrule[Elim] % TODO wait why do we have c here when it clearly refers to the term we eliminate over? um
  { \Gamma \vdash c \Uparrow c' \\ \Gamma \vdash Q \Uparrow Q' \\ \Gamma \vdash \vec{f} \Uparrow \vec{f'}}
  { \Gamma \vdash \mathrm{Elim}(c, Q) \vec{f} \Uparrow \mathrm{Elim}(c', Q') \vec{f'}  }

% Lamda
\inferrule[Lam]
  { \Gamma \vdash T \Uparrow T' \\\\ \Gamma,\ t : T \vdash b \Uparrow b' }
  {\Gamma \vdash \lambda (t : T).b \Uparrow \lambda (t : T').b'}

% Product
\inferrule[Prod]
  { \Gamma \vdash T \Uparrow T' \\\\ \Gamma,\ t : T \vdash b \Uparrow b' }
  {\Gamma \vdash \Pi (t : T).b \Uparrow \Pi (t : T').b'}
\end{mathpar}
\vspace{-0.3cm}
\caption{Proof term transformation for transporting terms across an equivalence $A \simeq B$ described by configuration \lstinline{((DepConstr, DepElim), (Eta, Iota))}.}
\label{fig:final}
\end{figure}

Figure~\ref{fig:final} shows the proof term transformation $\Gamma \vdash t \Uparrow t'$ that forms the core of \toolname.
Like the transformation from \textsc{Devoid},
this transformation is parameterized over two equivalent types \A and \B (\textsc{Equivalence}) and assumes fully expanded terms.
It is also parameterized over the configuration \lstinline{((DepConstr, DepElim), (Eta, Iota))},
which each appear in the transformation as a metavariable.

The goal of the proof term transformation is to preserve equality up to transport along that equivalence,
while no longer referring to the old specification.
That is, we need that $\Gamma \vdash t \Uparrow t' \rightarrow t \equiv_{A \simeq B} t'$, and that $t'$ refers to \B in place of \A.
This is the same as the correctness criterion for the program transformation from \textsc{Devoid} that this is based on,
with the transformation generalized to handle other equivalences beyond the class that \textsc{Devoid} supports.
The key steps in this transformation that make this possible are porting functions and proofs along the configuration corresponding
to a particular equivalence (\textsc{Dep-Constr}, \textsc{Dep-Elim}, \textsc{Eta}, and \textsc{Iota}).
The rest is straightforward.

\begin{figure}
\begin{minipage}{0.49\textwidth}
\begin{lstlisting}
(* 1: original term *)(@\vspace{-0.04cm}@)
$\lambda$ (T : Type) (l m : list T) .(@\vspace{-0.04cm}@)
 (@\codediff{Elim}@)(@\vspace{-0.04cm}@)
   (l, $\lambda$(l: Old.list T).list T $\rightarrow$ list T))(@\vspace{-0.04cm}@)
 {(@\vspace{-0.04cm}@)
   ($\lambda$ m . m),(@\vspace{-0.04cm}@)
   ($\lambda$ t _ IHl m.(@\vspace{-0.04cm}@)
      (@\codediff{Constr}@)(1, Old.list T) t (IHl m))(@\vspace{-0.04cm}@)
 } m.(@\vspace{-0.04cm}@)
(@\vspace{-0.14cm}@)
(* 2: after unifying (@\texttt{with}@) configuration *)(@\vspace{-0.04cm}@)
$\lambda$ (T : Type) (l m : list T) .(@\vspace{-0.04cm}@)
 (@\codediff{DepElim}@)(@\vspace{-0.04cm}@)
   (l, $\lambda$(l: Old.list T).list T $\rightarrow$ list T))(@\vspace{-0.04cm}@)
 {(@\vspace{-0.04cm}@)
   ($\lambda$ m . m)(@\vspace{-0.04cm}@)
   ($\lambda$ t _ IHl m.(@\vspace{-0.04cm}@)
      (@\codediff{DepConstr}@)(1, Old.list T) t (IHl m))(@\vspace{-0.04cm}@)
 } m.
\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}{0.49\textwidth}
\begin{lstlisting}
(* 4: reduced to final term *)(@\vspace{-0.04cm}@)
$\lambda$ (T : Type) (l m : list T) .(@\vspace{-0.04cm}@)
 (@\codediff{Elim}@)(@\vspace{-0.04cm}@)
   (l, $\lambda$(l: New.list T).list T $\rightarrow$ list T))(@\vspace{-0.04cm}@)
 {(@\vspace{-0.04cm}@)
   ($\lambda$ t _ IHl m.(@\vspace{-0.04cm}@)
      (@\codediff{Constr}@)(0, New.list T) t (IHl m)),(@\vspace{-0.04cm}@)
   ($\lambda$ m . m)(@\vspace{-0.04cm}@)
 } m.(@\vspace{-0.04cm}@)
(@\vspace{-0.14cm}@)
(* 3: ported to New.list *)(@\vspace{-0.04cm}@)
$\lambda$ (T : Type) (l m : list T) .(@\vspace{-0.04cm}@)
 DepElim(@\vspace{-0.04cm}@)
   (l, $\lambda$(l: (@\codediff{New.list T}@)).list T $\rightarrow$ list T))(@\vspace{-0.04cm}@)
 {(@\vspace{-0.04cm}@)
   ($\lambda$ m . m)(@\vspace{-0.04cm}@)
   ($\lambda$ t _ IHl m.(@\vspace{-0.04cm}@)
      DepConstr(1, (@\codediff{New.list T}@)) t (IHl m))(@\vspace{-0.04cm}@)
 } m.
\end{lstlisting}
\end{minipage}
\vspace{-0.3cm}
\caption{Swapping cases of the append function, with names fully qualified only when needed for clarity, counterclockwise: 1) the input, 2) the term unified with the configuration, 3) the term ported to the updated type, and 4) the term reduced to the final output.}
\label{fig:appswap1}
\end{figure}

The transformation is simple because it moves the bulk of the work into the configuration,
and because it represents the configuration explicitly.
Before running the transformation, \toolname unifies the input proof term with applications of the 
terms in the configuration for \A. The transformation then transforms the applications of the terms in the configuration of \A
to applications of the terms in the configuration for \B.
Reducing the result produces the output term defined over \B.

For example, to update the append function \lstinline{++} from the left of Figure~\ref{fig:appswap1}, \toolname
identifies implicit applications of \lstinline{DepConstr} and \lstinline{DepElim} and expands them (in this case,
just by matching against \lstinline{Constr} and \lstinline{Elim}, though this can be more difficult).
The transformation then recursively substitutes in \lstinline{New.list}
for \lstinline{Old.list}, which moves \lstinline{DepConstr} and \lstinline{DepElim}
to construct and eliminate over the updated type.
Finally, this reduces to the term on the right of Figure~\ref{fig:appswap1}.
Both versions of append behave equally up to transport along the equivalence from Figure~\ref{fig:equivalence}, since:

\begin{lstlisting}
$\forall$ T (l1 l2 : Old.list T), swap T (l1 ++ l2) = (swap T l1) ++ (swap T l2).
\end{lstlisting}
by induction and rewriting, and similarly in the opposite direction.
Our transformed proof \lstinline{rev_app_distr} then proves the same thing the same way
as the original proof up to the same equivalence---and up to the corresponding changes in \lstinline{++}
and \lstinline{rev}.

Note that this goal for correctness is metatheoretical:
stating and proving that two terms are equal up to transport is in general not possible in a language like Coq
without additional axioms, though it is in some cases realizable with an external tool~\cite{tabareau2017equivalences}.
\toolname does not yet generate these proofs as we were focused on building a usable tool with axiomatic freedom and few dependencies.
Coq ensures that all terms that plugins produce are well-typed; for now, as with \textsc{Devoid}, the proof engineer must vet the transformed
specifications herself to ensure that they specify the expected behavior.

\subsection{Specifying Correct Configuration}
\label{sec:art}

Of course, both when designing a search procedure for an automatic configuration and when
configuring \toolname manually, choosing correct and useful configuration is important,
and it is not always straightforward. This section specifies what it means for these
to be correct and gives some intuition to why.
Section~\ref{sec:search} shows some useful example configurations.

The configuration \lstinline{((DepConstr, DepElim), (Eta, Iota))} instantiates
the proof term transformation to a particular equivalence between \A and \B.
Choosing an equivalence is a bit of an art:
there can be infinitely many equivalences that correspond to a 
given change in specification, only some of which are useful.
Beyond that, even once we have chosen an equivalence, we could define many possible configurations that correspond
to the equivalence, some of which will produce functions and proofs that are more useful or efficient than others.

Thankfully, once the art is done, we at least understand what it means for it to be \textit{correct art}.
The correctness criteria for the configuration relate \lstinline{DepConstr}, \lstinline{DepElim}, \lstinline{Eta}, and \lstinline{Iota}
in a way that preserves equivalence (Section~\ref{sec:equivalence}) coherently with equality (Section~\ref{sec:equality}).

To preserve equivalence, we need that \lstinline{DepElim} and \lstinline{DepConstr} together induce an equivalence between \A and \B,
formed by one function that eliminates \A and constructs \B, and another function that eliminates \B and constructs \A:

\begin{lstlisting}
f : A $\rightarrow$ B := DepElim(a, $\lambda$(a : A).B){ $\lambda$ ... DepConstr(0, B) ..., ... }(@\vspace{-0.04cm}@)
g : B $\rightarrow$ A := DepElim(b, $\lambda$(b : B).A){ $\lambda$ ... DepConstr(0, A) ..., ... }
\end{lstlisting}
In addition, we need that:

\begin{enumerate}
\item $\forall$ \lstinline{j}, \lstinline{DepConstr(j, A)} $\equiv_{A \simeq B}$ \lstinline{DepConstr(j, B)}, and
\item $\forall$ \lstinline{(a : A) (b : B) (P : A $\rightarrow$ Type) (Q : B $\rightarrow$ Type)},\\ \lstinline{a} $\equiv_{A \simeq B}$ \lstinline{b} $\rightarrow$ \lstinline{P} $\equiv_{A \simeq B}$ \lstinline{Q} $\rightarrow$ \lstinline{DepElim(a, P)} $\equiv_{A \simeq B}$ \lstinline{DepElim(b, Q)}.
\end{enumerate}
The intuition for this is based on insights from \textsc{Devoid},
and is proven on an example from \textsc{Devoid} in the univalent parametricity framework.\footnote{\url{https://github.com/CoqHott/univalent_parametricity/commit/7dc14e69942e6b3302fadaf5356f9a7e724b0f3c}}
That these are equal up to transport along the equivalence means that replacing dependent constructors (respectively eliminators) of \A
with dependent constructors (respectively eliminators) of \B will preserve equality up to transport for those subterms.
Furthermore, since CIC$_{\omega}$ constructive, the \textit{only} way to construct an \A (respectively \B) is to use its constructors,
and the \textit{only} way to match over an \A (respectively \B) is to apply its eliminator.
Finally, since these form an equivalence, all ways of constructing or eliminating \A and \B are covered by these dependent constructors and eliminators.
So, as long as we are able to identify and expand all implicit applications of \lstinline{DepConstr} and \lstinline{DepElim},
\textsc{Dep-Constr} and \textsc{Dep-Elim} preserve correctness of the transformation and cover all values and eliminations of \A and \B.

To ensure coherence with equality, we need \lstinline{Eta} and \lstinline{Iota} to correctly prove the $\eta$ and $\iota$ rules
over \lstinline{DepElim}.
For \lstinline{Eta}, we need it to have the same definitional behavior as the dependent eliminator:

\begin{lstlisting}
DepElim(a, P) { f$_0$, ..., f$_n$ } : P (Eta(A) a)
\end{lstlisting}
and similarly for \B.

Each \lstinline{Iota} needs to prove and rewrite along the simplification or refolding behavior that corresponds to a case of the dependent eliminator, in other words: % TODO do we need eta here?

\begin{lstlisting}
Iota(A) :(@\vspace{-0.04cm}@)
  $\forall$ P $\vec{f}$ $\vec{x}$ (Q : P (DepConstr(j, A) $\vec{x}$) $\rightarrow$ Type),(@\vspace{-0.04cm}@)
    Q (DepElim((@\codediff{DepConstr(j, A) $\vec{x}$}@), P) $\vec{f}$ $\rightarrow$ (@\vspace{-0.04cm}@)
    Q ((@\codediff{$\vec{f}$[j]}@) ... (DepElim(IH$_0$, P) $\vec{f}$) ... (DepElim(IH$_n$, P) $\vec{f}$) ...)
\end{lstlisting}
where each \lstinline{IH}$_i$ is each recursive occurrence of \A in the eliminator case,
and similarly for \B.
Together, these induce proofs of \lstinline{section} and \lstinline{retraction} (by induction).
The intuition here is that preserving the reduction behavior
of the eliminators and constructors should be sufficient, since again those are the only ways we can construct or eliminate our types.

\textbf{Configure} implements search procedures that discover functions \lstinline{f} and \lstinline{g} for certain classes of
equivalences, and also
generate proofs \lstinline{section} and \lstinline{retraction} that these functions form an equivalence.
It can be difficult to prove the entire correctness criteria for the configuration---proving equality of the eliminators
up to transport, for example, requires a special framework~\cite{tabareau2017equivalences}
or a univalent type theory~\cite{univalent2013homotopy}.
Thankfully, the proof engineer does not need to prove the correctness criteria for a configuration in order to use \toolname.
Rather, the correctness criteria simply need to hold in order for the transformation to work.

\subsection{The Tool}
\label{sec:implementation}

The configurable proof term transformation helped us build a flexible proof repair and reuse tool.
However, it alone was not enough to build a tool that reaches real proof engineers.
This section describes a sample of the implementation challenges that we encountered and how we solved them.
Section~\ref{sec:discussion} elaborates on the remaining challenges and our plans to address them in the future.

\paragraph{From CIC$_{\omega}$ to Coq}

Like \textsc{Devoid}, we also had to handle language differences to scale from CIC$_{\omega}$ to Coq.
We use the same \lstinline{Preprocess} command that \textsc{Devoid} uses to turn pattern matching and fixpoints into applications of eliminators.
We handle non-primitive projections using \lstinline{Eta}, and we handle refolding of constants in constructors
using \lstinline{DepConstr}.

\paragraph{Matching Against Preconditions}

It is easy to \textit{describe} the proof term transformation, but it is much more difficult to implement it.
This is because the proof term transformation only describes what transformation rules are applicable when,
but it does not describe how to actually check that the precondition holds.
In many cases, this check is not purely syntactic---we really want to know if a term \textit{unifies}
with an application of \lstinline{DepConstr}, for example, not whether it applies the term exactly.
This is especially pronounced with \lstinline{Eta} and \lstinline{Iota},
which typically show up contracted in real code.
This problem is exactly why \citet{tabareau2019marriage} speculated that converting definitional to propositional equalities
like we do with \lstinline{Iota} may, in general, be intractable.

In practice, we find that unification is sometimes not enough to identify an implicit application of one of the configuration terms.
Each of our search procedures for automatic configuration in turn implements rewrite rules that tell \toolname
how to identify and expand these implicit applications before applying the transformation.
In the worst case, proof engineers can provide hints to \toolname in the form of explicit annotations.

\paragraph{Termination \& Intent}

Another challenge with implementing the proof term transformation is deciding whether to run a rule that matches at all.
That is, when the correctness criteria for a configuration hold and a subterm matches a rule, this suggests that \toolname \textit{can}
run the transformation rule, but it does not necessarily mean that it \textit{should}.
In some cases, repeatedly running a matching transformation rule would result in nontermination.
For example, if our type \B is a refinement of our type \A, then we can always run \textsc{Equivalence}
over and over again, forever.
\textsc{Devoid} ruled out this case by simply prohibiting the case where \B refers to \A, but we found it sometimes
useful to support this case.
To support this, we include some simple termination checks in our code.

Even when termination is guaranteed, whether to run a matching transformation rule
depends on intent.
For example, our industrial proof engineer sometimes wished to port only some occurrences of \A,
especially when \A was a tuple like \lstinline{(nat * bool)} that could appear elsewhere
with a different meaning.
We helped the proof engineer do this by interacting with \toolname using a particular workflow.
We plan to support this automatically using type-directed search in the future.

\paragraph{Reaching Real Proof Engineers}
Many of our design decisions in implementing \toolname were informed by our partnership with
an industrial proof engineer.
For example, we found that the proof engineer rarely had the patience to wait more than ten seconds
for \toolname to port a function or proof.
In response, we implemented very aggressive caching (with an option to disable the cache), even caching intermediate subterms that
we encounter in the course of running our proof term transformation.
We also added the option to set certain terms or modules as opaque to \toolname, to prevent
unnecessary $\delta$-reduction.
We also implemented many optimizations from \textsc{Devoid}.

The experiences of proof engineers also informed features that we exposed.
We implemented special search procedures to generate custom eliminators to make it easier to reason about
types that we found common for certain search procedures.
For example, \toolname generates a custom eliminator to reason about types refined by equalities like $\Sigma$\lstinline{(l : list T).length l = n}
by breaking them into parts and reasoning separately about the projections.
These features along with our tactic decompiler helped with integration into proof engineering workflows.

%First we need that \lstinline{DepElim} over $A$ into \lstinline{DepConstr} over $B$ and \lstinline{DepElim} over $B$ into
%\lstinline{DepConstr} over $A$ form an equivalence between $A$ and $B$. When that's true, I think it should hold that \lstinline{DepElim} over $A$
%and \lstinline{DepElim} over $B$ are in univalent relation with one another. If not, then that's an extra condition.
%Finally, we need the transformation to preserve definitional equalities. Not sure about the general case, but for vectors and lists,
%we need:

%\begin{lstlisting}
%  $\forall$ A l (f : $\forall$ (l : sigT (Vector.t A)), l = l),
%    vect_dep_elim A (fun l => l = l) (f nil) (fun t s _ => f (cons t s)) l = f (id_eta l).
%\end{lstlisting}
%and:

%\begin{lstlisting}
%Definition elim_id (A : Type) (s : {H : nat & t A H}) :=
%  vect_dep_elim
%    A
%    (fun _ => {H : nat & t A H})
%    nil
%    (fun (h : A) _ IH =>
%      cons h IH)
%    s.

% $\forall$ A h s,
%    exists (H : cons h (elim_id A s) = elim_id A (cons h s)),
%      H = eq_refl.
%\end{lstlisting}
%More generally, for each constructor index $j$, define:

%\begin{lstlisting}
%  eqc (j, B) (f : $\forall$ b : B, b = b) :=
%    fun ... (* TODO get the hypos from the type of the eliminator *) =>
%      f (DepConstr (j, B)) (* TODO args *)%%

  %elim_id := (* TODO *)
%\end{lstlisting}
%Then we need:

%\begin{enumerate}
%\item $\forall b f, \mathrm{DepElim}(b,\ p_{b}) \{\mathrm{eqc} (1, B) f, \ldots, \mathrm{eqc} (n, B) f\} = f (\mathrm{Eta}(A) a) $
%\item Something relating the constructors and \lstinline{elim_id} to reflexivity
%\end{enumerate}
%and similarly for $A$.

%Really the point of these conditions is that from them, with some restrictions on input terms, we can get
%that lifting terms gives us the same type that we'd get from lifting the type. But there are still
%some restrictions (see the few that fail).

%It's probably not always possible to define these three things for every equivalence.
%Could generalize by rewriting. But this lets us avoid the rewriting problem from Nicolas' paper.

% TODO how does this get us something like primitive projections? Just makes Eta definitionally equal to regular Id?

% TODO so we can probably just frame search in terms of DepConstr and DepElim and then generate proofs about this on an ad-hoc basis
% and get away with not including the specific details of our instantiations. We can give examples instead, give intuition, and say we generate
% the proofs in Coq

%For the second one we need not just an eliminator rule but also an identity rule.
%DEVOID assumed primitive projections which let them get away without thinking of this,
%but then had this weirdly ad-hoc ``repacking'' thing in their implementation.
%It turns out this is just a more general identity rule, which basically says what
%the identity function should lift to so that the transformation preserves definitional equalities.
%Actually deciding when to run this rule is one of the biggest challenges in practice,
%so we'll talk about that more in the implementation section.


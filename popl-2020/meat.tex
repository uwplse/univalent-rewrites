\section{Correct Art}

It's true that you can squint and view non-semantics-preserving changes as equivalence-preserving changes,
but you need to pick the right equivalence, then instantiate the algorithm to that equivalence.
You want this equivalence and the transformation you choose for eliminators and consructors to be both correct and useful.
Making it useful is an art, but we can at least make sure your art is correct.

We define correctness criteria for the transformation: needs to preserve equality up to univalent transport, and also needs to
preserve definitional equalities.
We then define a set of transformation rules that are generic across equivalences so long as the correctness criteria hold.
We prove this.

Next, for the four classes of equivalences we support (maybe more if we have time), we define the constructor, eliminator, and identity rules.
We prove that each of these satisfies the correctness criteria.
Our implementation also (or alternatively, depending on how much time we have) generates these proofs on an ad-hoc basis because
the general proof isn't possible within Coq.

Note about decidability of matching: when all of this is correct, what this means is that you \textit{can} always
run one of the transformation rules. But that doesn't mean you \textit{should}. Depends what the user wants,
and in some cases, would not terminate (refinement types, unpacking indexed types). Implementation section will
discuss how we actually decide which ones to run so user doesn't need to apply transport by hand over and over again,
and discussion section describes some cool ideas for doing this nicely with type-based search in the future.

\subsection{Correctness Criteria}

I suspect the eliminator transformations are correct when:

\begin{enumerate}
\item they preserve the univalent relation
\item they preserve definitional equalities
\end{enumerate}

Nicolas proved the first of these a while ago
for the equivalence in the DEVOID ITP paper.\footnote{\url{https://github.com/CoqHott/univalent_parametricity/commit/7dc14e69942e6b3302fadaf5356f9a7e724b0f3c}}
The statement is that the old and new eliminator variants are related along the univalent parametric relation.
Here are some examples.
We (hopefully) extend DEVOID to generate this proof automatically for each pair of types.
We (maybe) prove the more general versions below. 
We (hopefully) show that the transformation rules actually are correct when these two criteria hold.

For the second one we need not just an eliminator rule but also an identity rule.
DEVOID assumed primitive projections which let them get away without thinking of this,
but then had this weirdly ad-hoc ``repacking'' thing in their implementation.
It turns out this is just a more general identity rule, which basically says what
the identity function should lift to so that the transformation preserves definitional equalities.
Actually deciding when to run this rule is one of the biggest challenges in practice,
so we'll talk about that more in the implementation section.

\subsection{Four Transformations}

Here are the constructor, eliminator, and identity rules for our four implemented transformations.
The equivalence between $A$ and $B$ can be constructed in terms of these.
This shows just one direction---the opposite is similar.

\subsubsection{Swap}

Let $A$ and $B$ be inductive types:

\begin{lstlisting}
$A$ := $\mathrm{Ind} (\mathit{Ty}_A : \Pi (\vec{i_A} : \vec{\mathrm{X}_A}) . \mathrm{s}_A)\{\mathrm{C}_{A_1}, \ldots, \mathrm{C}_{A_n}\}$
$B$ := $\mathrm{Ind} (\mathit{Ty}_B : \Pi (\vec{i_B} : \vec{\mathrm{X}_B}) . \mathrm{s}_B)\{\mathrm{C}_{B_1}, \ldots, \mathrm{C}_{B_n}\}$
\end{lstlisting}
Assume there is some invertible swap map $m$ such that for any index $j$,
\lstinline{C}$_{B_{m(j)}}$ is exactly \lstinline{C}$_{A_j}[B / A]$.
Then:

\begin{lstlisting}
DepConstr(j, A) : C$_{A_{j}}$ := Constr(j, A) 
DepConstr(j, B) : C$_{A_{j}}$[B / A] := Constr(m(j), B)

DepElim(a, p){f$_{1}$, $\ldots$, f$_{n}$} : p a := Elim(a, p){f$_{1}$, $\ldots$, f$_{n}$}
DepElim(b, p){f$_{1}$, $\ldots$, f$_{n}$} : p b := Elim(b, p){f$_{m(1)}$, $\ldots$, f$_{m(n)}$}

IdEta(A) := $\lambda$ ($\vec{t}$ : $\vec{T}$) (a : A $\vec{t}$).a
IdEta(B) := $\lambda$ ($\vec{t}$ : $\vec{T}$) (b : B $\vec{t}$).b
\end{lstlisting}

\subsubsection{Algebraic}

It is straightforward to fit the search algorithm from DEVOID into this framework.
Let $A$ be $A$ from DEVOID, let $B_{ind}$ be $B$ from DEVOID, let $I_B$ be $I_B$ from DEVOID,
and let \lstinline{index} be \lstinline{index} from DEVOID.
Let $B$ wrap $B_{ind}$ packed into a sigma type:

\begin{lstlisting}
B := $\lambda$ ($\vec{t}$ : $\vec{T}$) . ($\Sigma$ (i : I$_B$ $\vec{t}$) . B$_{ind}$ (index i $\vec{t}$))
\end{lstlisting}
%Using the functions \lstinline{promote} (denoted $\uparrow$) and \lstinline{forget} (denoted $\downarrow$) determined by the search
%algorithm from DEVOID, 
%and defining $\vec{\downarrow}$ to forget all arguments of type $B$ to an argument of type $A$ (fuzzy for now), and
%defining $\vec{\mathrm{retract}}$ to retract all subterms $\uparrow (\downarrow s))$ to $s$ (fuzzy for now), we have:
% $\lambda$ ($\vec{t}$ : $\vec{T_{A_j}}$[B / A]) . $\vec{\mathrm{retract}}$ (($\uparrow$ (Constr(j, A) ($\vec{\downarrow}$ $\vec{t}$))$_{\beta\delta\iota}$)
Letting $\vec{T_{A_j}}$ be the types of the arguments to C$_{A_{j}}$, we have:

\begin{lstlisting}
DepConstr(j, A) : C$_{A_{j}}$ := Constr(j, A)
DepConstr(j, B) : C$_{A_{j}}$[B / A] := $\lambda$ ($\vec{t}$ : $\vec{T_{A_j}}$[B / A]) . $\exists$ ... ...

DepElim(a, p){f$_{1}$, $\ldots$, f$_{n}$} : p a := Elim(a, p){f$_{1}$, $\ldots$, f$_{n}$}
DepElim(b, p){f$_{1}$, $\ldots$, f$_{n}$} : p b := Elim($\pi_r$ b, ($\lambda$ p ...){...}

IdEta(A) := $\lambda$(a : A).a
IdEta(B) := $\lambda$(b : B).$\exists$ ($\pi_l$ b) ($\pi_r$ b)
\end{lstlisting}

% TODO investigate below projection thing, and write in when you finish
%For now assume we have some \lstinline{pack} function to pack into an existential;
%this is just for convenience.
%The indexer is just the first projection of this lifted across the eliminator rule, AFAIK---note this isn't exactly $\Pi_{l}$ like we use
%in the tool, but is really an eliminated $\Pi_{l}$? I will need to check on this, it's the only weird part.
%Also assume some \lstinline{index_args} function to add the new index to the appropriate arguments---I'll
%elaborate on this later but it's also something search needs to find and it's determined in terms of the \lstinline{indexer} that search finds.
%Also now, we no longer assume primitive projections.

\subsubsection{Unpack sigma}

This one is kind of weird but it gets us user-friendly types. I'll explain later.

\begin{lstlisting}
DepConstr(j, A) $\vec{t}_{a}$ := (* TODO pack into existential, deal with equality *)
DepConstr(j, B) $\vec{t}_{b}$ := Constr(j, B) $\vec{t}_{b}$

DepElim(a, p$_a$){f$_{a_{1}}$, $\ldots$, f$_{a_{n}}$} := (* TODO *)
DepElim(b, p$_b$){f$_{b_{1}}$, $\ldots$, f$_{b_{n}}$} := Elim(b, p$_b$){f$_{b_{1}}$, $\ldots$, f$_{b_{n}}$}

IdEta(A) := $\lambda$(a : A).$\exists$ ($\exists$ ($\pi_l$ ($\pi_l$ a)) ($\pi_r$ ($\pi_l$ a))) ($\pi_r$ a)
IdEta(B) := $\lambda$(b : B).b
\end{lstlisting}

\subsubsection{Records and tuples}

This one should be easier. (TODO)

\subsection{Transformation Rules}

Here are the general rules, adapted from DEVOID.
I'll explain later and add back the common definition and define the custom eliminators ``DepElim'' and so on.

Note that now we define the types $A$ and $B$ to take all of the same arguments, so for example for the algebraic
example with \lstinline{list} and \lstinline{vector}, $A$ is \lstinline{fun (T : Type) => list T} while $B$
is \lstinline{fun (T : Type) => sigT (fun (n : nat) => vector T n)}. When we lift terms $a$ and $b$ of that type
we implicitly lift their types $A$ and $B$ and so their parameters. The eliminator, identity, and constructor rules
depend on this since they are different by type.

Given what it means to be correct, I'm not sure if small-step will make more sense here.
Also some of the rules are preliminary and will need tweaking.
The definition of the constructor rules will just apply and normalize the equivalence in one direction.
Especially coherence and its relation to identity and how to capture things like \lstinline{eq_refl n}.
Right now I omit coherence because in theory it should be handled by the eliminator rule.
But really need to consider cases like \lstinline{eq_refl n}.
May have something to do with parameterized inductive types.
I'm also removing internalize and retraction because I think they should be handled
by the eliminator rule, the identity rule, and the application rule.
For eliminators, I think the definition of the lifted dependent eliminator itself should handle the initial transformation
of the motive and the cases, but we might need to weak when we reverse the direction.
In equivalence rule, we lift $A$ to $B$, but implicitly this is lifting the functions that take parameters and return $A$ or $B$,
and the arguments are lifted by the application rule.
Also this is only one direction but just flip for the other direction.

\begin{figure}
\begin{mathpar}
\mprset{flushleft}
\small
\hfill\fbox{$\Gamma$ $\vdash$ $t$ $\Uparrow$ $t'$}\\

\inferrule[Lift-Elim]
  { \Gamma \vdash p_{a} \Uparrow p_b \\ \Gamma \vdash \vec{f_{a}}\phantom{l} \Uparrow \vec{f_{b}} }
  { \Gamma \vdash \mathrm{DepElim}(a,\ p_{a}) \vec{f_{a}} \Uparrow \mathrm{DepElim}(b,\ p_b) \vec{f_{b}} }

\inferrule[Lift-Constr]
{ \vec{t}_{a} \Uparrow \vec{t}_{b} } %\\ TODO must we explicitly lift A to B if we want to handle parameters/indices?
{ \Gamma \vdash \mathrm{DepConstr}(j,\ A)\ \vec{t}_{a} \Uparrow \mathrm{DepConstr}(j,\ B)\ \vec{t}_{b}  }

\inferrule[Lift-Identity]
  { \\ }
  { \Gamma \vdash \mathrm{IdEta}(A) \Uparrow \mathrm{IdEta}(B) }

\inferrule[Equivalence]
  { \\ }
  { \Gamma \vdash A\ \Uparrow B }

\inferrule[Constr]
{ \Gamma \vdash T \Uparrow T' \\ \Gamma \vdash \vec{t} \Uparrow \vec{t'} }
{ \Gamma \vdash \mathrm{Constr}(j,\ T)\ \vec{t} \Uparrow \mathrm{Constr}(j,\ T')\ \vec{t'} }

\inferrule[Ind]
  { \Gamma \vdash T \Uparrow T' \\ \Gamma \vdash \vec{C} \Uparrow \vec{C'}  }
  { \Gamma \vdash \mathrm{Ind} (\mathit{Ty} : T) \vec{C} \Uparrow \mathrm{Ind} (\mathit{Ty} : T') \vec{C'} }

\inferrule[Elim]
  { \Gamma \vdash c \Uparrow c' \\ \Gamma \vdash Q \Uparrow Q' \\ \Gamma \vdash \vec{f} \Uparrow \vec{f'}}
  { \Gamma \vdash \mathrm{Elim}(c, Q) \vec{f} \Uparrow \mathrm{Elim}(c', Q') \vec{f'}  }

%% Application
\inferrule[App]
 { \Gamma \vdash f \Uparrow f' \\ \Gamma \vdash t \Uparrow t'}
 { \Gamma \vdash f t \Uparrow f' t' }

% Lamda
\inferrule[Lam]
  { \Gamma \vdash T \Uparrow T' \\ \Gamma,\ t : T \vdash b \Uparrow b' }
  {\Gamma \vdash \lambda (t : T).b \Uparrow \lambda (t : T').b'}

% Product
\inferrule[Prod]
  { \Gamma \vdash T \Uparrow T' \\ \Gamma,\ t : T \vdash b \Uparrow b' }
  {\Gamma \vdash \Pi (t : T).b \Uparrow \Pi (t : T').b'}
\end{mathpar}
\caption{Generic lifting algorithm.}
\label{fig:final}
\end{figure}


\subsection{Correctness}

Here's the proof that as long as the correctness criteria hold, it's OK to take any of those steps.
Same definition as DEVOID paper for correctness but note we just consider one step at a time since
it's very undecidable to decide which ones to run. The implementation section talks about how we
decide this in practice.




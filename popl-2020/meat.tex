\section{Correct Art}

It's true that you can squint and view non-semantics-preserving changes as equivalence-preserving changes,
but you need to pick the right equivalence, then instantiate the algorithm to that equivalence.
You want this equivalence and the transformation you choose for eliminators and consructors to be both correct and useful.
Making it useful is an art, but we can at least make sure your art is correct.

We define correctness criteria for the transformation: needs to preserve equality up to univalent transport, and also needs to
preserve definitional equalities.
We then define a set of transformation rules that are generic across equivalences so long as the correctness criteria hold.
We prove this.

Next, for the four classes of equivalences we support (maybe more if we have time), we define the constructor, eliminator, and identity rules.
We prove that each of these satisfies the correctness criteria.
Our implementation also (or alternatively, depending on how much time we have) generates these proofs on an ad-hoc basis because
the general proof isn't possible within Coq.

Note about decidability of matching: when all of this is correct, what this means is that you \textit{can} always
run one of the transformation rules. But that doesn't mean you \textit{should}. Depends what the user wants,
and in some cases, would not terminate (refinement types, unpacking indexed types). Implementation section will
discuss how we actually decide which ones to run so user doesn't need to apply transport by hand over and over again,
and discussion section describes some cool ideas for doing this nicely with type-based search in the future.

\subsection{Correctness Criteria}

First we need that \lstinline{DepElim} over $A$ into \lstinline{DepConstr} over $B$ and \lstinline{DepElim} over $B$ into
\lstinline{DepConstr} over $A$ form an equivalence between $A$ and $B$. When that's true, I think it should hold that \lstinline{DepElim} over $A$
and \lstinline{DepElim} over $B$ are in univalent relation with one another. If not, then that's an extra condition.
Finally, we need the eliminator transformation to preserve definitional equalities (need more details here).

% TODO so we can probably just frame search in terms of DepConstr and DepElim and then generate proofs about this on an ad-hoc basis
% and get away with not including the specific details of our instantiations. We can give examples instead, give intuition, and say we generate
% the proofs in Coq

Nicolas proved the first of these a while ago
for the equivalence in the DEVOID ITP paper.\footnote{\url{https://github.com/CoqHott/univalent_parametricity/commit/7dc14e69942e6b3302fadaf5356f9a7e724b0f3c}}
The statement is that the old and new eliminator variants are related along the univalent parametric relation.
Here are some examples.
We (hopefully) extend DEVOID to generate this proof automatically for each pair of types.
We (maybe) prove the more general versions below. 
We (hopefully) show that the transformation rules actually are correct when these two criteria hold.

For the second one we need not just an eliminator rule but also an identity rule.
DEVOID assumed primitive projections which let them get away without thinking of this,
but then had this weirdly ad-hoc ``repacking'' thing in their implementation.
It turns out this is just a more general identity rule, which basically says what
the identity function should lift to so that the transformation preserves definitional equalities.
Actually deciding when to run this rule is one of the biggest challenges in practice,
so we'll talk about that more in the implementation section.

\subsection{Four Transformations}

% TODO oracles, naming, consider just doing code and generating proofs in Coq

Here are the constructor, eliminator, and identity rules for our four implemented transformations (very informal WIP).
The equivalence between $A$ and $B$ can be constructed in terms of these.
This shows just one direction---the opposite is similar.

\subsubsection{Swap}

Let $A$ and $B$ be inductive types:

\begin{lstlisting}
$A$ := $\mathrm{Ind} (\mathit{Ty}_A : \Pi (\vec{i_A} : \vec{\mathrm{X}_A}) . \mathrm{s}_A)\{\mathrm{C}_{A_1}, \ldots, \mathrm{C}_{A_n}\}$
$B$ := $\mathrm{Ind} (\mathit{Ty}_B : \Pi (\vec{i_B} : \vec{\mathrm{X}_B}) . \mathrm{s}_B)\{\mathrm{C}_{B_1}, \ldots, \mathrm{C}_{B_n}\}$
\end{lstlisting}
Assume there is some invertible swap map $m$ such that for any index $j$,
\lstinline{C}$_{B_{m(j)}}$ is exactly \lstinline{C}$_{A_j}[B / A]$.
Then:

\begin{lstlisting}
DepConstr(j, A) : C$_{A_{j}}$ := Constr(j, A) 
DepConstr(j, B) : C$_{A_{j}}$[B / A] := Constr(m(j), B)

DepElim(a, p){f$_{1}$, $\ldots$, f$_{n}$} : p a := Elim(a, p){f$_{1}$, $\ldots$, f$_{n}$}
DepElim(b, p){f$_{1}$, $\ldots$, f$_{n}$} : p b := Elim(b, p){f$_{m(1)}$, $\ldots$, f$_{m(n)}$}

IdEta(A) := $\lambda$ ($\vec{t}$ : $\vec{T}$) (a : A $\vec{t}$).a
IdEta(B) := $\lambda$ ($\vec{t}$ : $\vec{T}$) (b : B $\vec{t}$).b
\end{lstlisting}

\subsubsection{Algebraic}

It is straightforward to fit the search algorithm from DEVOID into this framework, and in fact
we can loosen the restriction that the language has primitive projections.
Let $A$ be $A$ from DEVOID, let $B_{ind}$ be $B$ from DEVOID, let $I_B$ be $I_B$ from DEVOID,
and let \lstinline{index} be \lstinline{index} from DEVOID.
Let $B$ wrap $B_{ind}$ packed into a sigma type:

\begin{lstlisting}
B := $\lambda$ ($\vec{t}$ : $\vec{T}$) . ($\Sigma$ (i : I$_B$ $\vec{t}$) . B$_{ind}$ (index i $\vec{t}$))
\end{lstlisting}
Let $\vec{T_{B_j}}$ be the arguments of constructor type $C_{B_j}$ (type of constructor of $B_{\mathrm{ind}}$).
Define \lstinline{DepConstr(j, B)} recursively using the following derivation (based on and same fall-through convention as the DEVOID paper for now,
and I'd prefer to move this away from a derivation but not sure how to do so and maintain formality): % TODO check

\begin{mathpar}
\mprset{flushleft}
\small
\hfill\fbox{$\Gamma$ $\vdash$ $(T_A, T_B)$ $\Downarrow_{C}$ $t$}\\

\inferrule[Dep-Constr-Conclusion]
  { \Gamma \vdash \vec{t_{B_j}} : \vec{T_{B_j}} \\ \Gamma \vdash Constr(j, B)\ \vec{t_{B_j}} : B_{\mathrm{ind}} \vec{i_B}  }
  { \Gamma \vdash (A\ \vec{i_A},\ B_{\mathrm{ind}}\ \vec{i_B}) \Downarrow_{p_{c}} \exists\ (\vec{i_B}[\mathrm{off}\ A\ B]) (Constr(j, B)\ \vec{t_{B_j}}) }

\inferrule[Dep-Constr-Index] % new hypothesis for index
  { \mathrm{new}\ n_B\ b_B \\ \Gamma,\ n_B : t_B \vdash (\Pi (n_A : t_A) . b_A,\ b_B) \Downarrow_{i_{c}} t }
  {  \Gamma \vdash (\Pi (n_A : t_A) . b_A,\ \Pi (n_B : t_B) . b_B) \Downarrow_{C} t}

\inferrule[Dep-Constr-IH] % inductive hypothesis
  { \Gamma,\ n_B : B\ \vec{i_B} \vdash (b_A [n_B / n_A], b_B [\pi_l\ n_B / \vec{i_B}[\mathrm{off}\ A\ B]]) \Downarrow_{C} t }
  { \Gamma \vdash (\Pi (n_A : A\ \vec{i_A}) . b_A, \Pi (n_B : B\ \vec{i_B}) \Downarrow_{C} \lambda (n_B : B\ \vec{i_B}) . t }

\inferrule[Dep-Constr-Prod] % otherwise, unchanged (when we get rid of the gross fall-through thing, needs not new, and needs to check t_A and t_B not IHs)
  { \Gamma,\ n_B : t_B \vdash (b_A [n_B / n_A], b_B) \Downarrow_{C} t }
  { \Gamma \vdash (\Pi (n_A : t_A) . b_A, \Pi (n_B, t_B) . b_B) \Downarrow_{C} \lambda (n_B : t_B) . t }\\

\inferrule[Dep-Constr]
{ \Gamma \vdash Constr(j, A) : C_{A_j} \\ \Gamma \vdash (C_{A_j}, C_{B_j}) \Downarrow_{C} t }
{ \Gamma \vdash (Constr(j, A), Constr(j, B_{\mathrm{ind}}) \Downarrow_{C} t }
\end{mathpar}
and \lstinline{DepElim(b, p)} similarly:

\begin{mathpar}
TODO
\end{mathpar}

Then:

\begin{lstlisting}
DepConstr(j, A) : C$_{A_{j}}$ := Constr(j, A)
DepConstr(j, B) : C$_{A_{j}}$[B / A] := DepConstr(j, B)

DepElim(a, p){f$_{1}$, $\ldots$, f$_{n}$} : p a := Elim(a, p){f$_{1}$, $\ldots$, f$_{n}$}
DepElim(b, p){f$_{1}$, $\ldots$, f$_{n}$} : p b := DepElim(b, p)

IdEta(A) := $\lambda$(a : A).a
IdEta(B) := $\lambda$(b : B).$\exists$ ($\pi_l$ b) ($\pi_r$ b)
\end{lstlisting}

% TODO investigate below projection thing, and write in when you finish
%For now assume we have some \lstinline{pack} function to pack into an existential;
%this is just for convenience.
%The indexer is just the first projection of this lifted across the eliminator rule, AFAIK---note this isn't exactly $\Pi_{l}$ like we use
%in the tool, but is really an eliminated $\Pi_{l}$? I will need to check on this, it's the only weird part.
%Also assume some \lstinline{index_args} function to add the new index to the appropriate arguments---I'll
%elaborate on this later but it's also something search needs to find and it's determined in terms of the \lstinline{indexer} that search finds.
%Also now, we no longer assume primitive projections.

\subsubsection{Unpack sigma}

This one is kind of weird but it gets us user-friendly types. I'll explain later.

\begin{lstlisting}
DepConstr(j, A) := (* TODO pack into existential, deal with equality *)
DepConstr(j, B) : C$_{B_{j}}$ := Constr(j, B)

DepElim(a, p){f$_{1}$, $\ldots$, f$_{n}$} : p a := (* TODO *)
DepElim(b, p){f$_{1}$, $\ldots$, f$_{n}$} : p b := Elim(b, p){f$_{1}$, $\ldots$, f$_{n}$}

IdEta(A) := $\lambda$(a : A).$\exists$ ($\exists$ ($\pi_l$ ($\pi_l$ a)) ($\pi_r$ ($\pi_l$ a))) ($\pi_r$ a)
IdEta(B) := $\lambda$(b : B).b
\end{lstlisting}

\subsubsection{Records and tuples}

This one should be easier. We'll play a similar trick with $B$ and $B_{ind}$ like we do for algebraic,
and give things similar names.
Then:

\begin{lstlisting}
DepConstr(j, A) : C$_{A_{j}}$ := Constr(j, A)
DepConstr(j, B) : C$_{A_{j}}$[B / A] := $\lambda$ ($\vec{t_{A_j}}$ : $\vec{T_{A_j}}$) . (* TODO recursively pack into pair *)

DepElim(a, p){f$_{1}$, $\ldots$, f$_{n}$} : p a := Elim(a, p){f$_{1}$, $\ldots$, f$_{n}$}
DepElim(b, p){f$_{1}$, $\ldots$, f$_{n}$} : p b := (* TODO recursively eliminate product *)

IdEta(A) := $\lambda$(a : A).a
IdEta(B) := (* TODO recursive eta *)
\end{lstlisting}

\subsection{Transformation Rules}

Here are the general rules, adapted from DEVOID.
I'll explain later and add back the common definition and define the custom eliminators ``DepElim'' and so on.

Note that now we define the types $A$ and $B$ to take all of the same arguments, so for example for the algebraic
example with \lstinline{list} and \lstinline{vector}, $A$ is \lstinline{fun (T : Type) => list T} while $B$
is \lstinline{fun (T : Type) => sigT (fun (n : nat) => vector T n)}. When we lift terms $a$ and $b$ of that type
we implicitly lift their types $A$ and $B$ and so their parameters. The eliminator, identity, and constructor rules
depend on this since they are different by type.

Given what it means to be correct, I'm not sure if small-step will make more sense here.
Also some of the rules are preliminary and will need tweaking.
The definition of the constructor rules will just apply and normalize the equivalence in one direction.
Especially coherence and its relation to identity and how to capture things like \lstinline{eq_refl n}.
Right now I omit coherence because in theory it should be handled by the eliminator rule.
But really need to consider cases like \lstinline{eq_refl n}.
May have something to do with parameterized inductive types.
I'm also removing internalize and retraction because I think they should be handled
by the eliminator rule, the identity rule, and the application rule.
For eliminators, I think the definition of the lifted dependent eliminator itself should handle the initial transformation
of the motive and the cases, but we might need to weak when we reverse the direction.
In equivalence rule, we lift $A$ to $B$, but implicitly this is lifting the functions that take parameters and return $A$ or $B$,
and the arguments are lifted by the application rule.
Also this is only one direction but just flip for the other direction.

\begin{figure}
\begin{mathpar}
\mprset{flushleft}
\small
\hfill\fbox{$\Gamma$ $\vdash$ $t$ $\Uparrow$ $t'$}\\

\inferrule[Lift-Elim]
  { \Gamma \vdash p_{a} \Uparrow p_b \\ \Gamma \vdash \vec{f_{a}}\phantom{l} \Uparrow \vec{f_{b}} }
  { \Gamma \vdash \mathrm{DepElim}(a,\ p_{a}) \vec{f_{a}} \Uparrow \mathrm{DepElim}(b,\ p_b) \vec{f_{b}} }

\inferrule[Lift-Constr]
{ \vec{t}_{a} \Uparrow \vec{t}_{b} } %\\ TODO must we explicitly lift A to B if we want to handle parameters/indices?
{ \Gamma \vdash \mathrm{DepConstr}(j,\ A)\ \vec{t}_{a} \Uparrow \mathrm{DepConstr}(j,\ B)\ \vec{t}_{b}  }

\inferrule[Lift-Identity]
  { \\ }
  { \Gamma \vdash \mathrm{IdEta}(A) \Uparrow \mathrm{IdEta}(B) }

\inferrule[Equivalence]
  { \\ }
  { \Gamma \vdash A\ \Uparrow B }

\inferrule[Constr]
{ \Gamma \vdash T \Uparrow T' \\ \Gamma \vdash \vec{t} \Uparrow \vec{t'} }
{ \Gamma \vdash \mathrm{Constr}(j,\ T)\ \vec{t} \Uparrow \mathrm{Constr}(j,\ T')\ \vec{t'} }

\inferrule[Ind]
  { \Gamma \vdash T \Uparrow T' \\ \Gamma \vdash \vec{C} \Uparrow \vec{C'}  }
  { \Gamma \vdash \mathrm{Ind} (\mathit{Ty} : T) \vec{C} \Uparrow \mathrm{Ind} (\mathit{Ty} : T') \vec{C'} }

\inferrule[Elim]
  { \Gamma \vdash c \Uparrow c' \\ \Gamma \vdash Q \Uparrow Q' \\ \Gamma \vdash \vec{f} \Uparrow \vec{f'}}
  { \Gamma \vdash \mathrm{Elim}(c, Q) \vec{f} \Uparrow \mathrm{Elim}(c', Q') \vec{f'}  }

%% Application
\inferrule[App]
 { \Gamma \vdash f \Uparrow f' \\ \Gamma \vdash t \Uparrow t'}
 { \Gamma \vdash f t \Uparrow f' t' }

% Lamda
\inferrule[Lam]
  { \Gamma \vdash T \Uparrow T' \\ \Gamma,\ t : T \vdash b \Uparrow b' }
  {\Gamma \vdash \lambda (t : T).b \Uparrow \lambda (t : T').b'}

% Product
\inferrule[Prod]
  { \Gamma \vdash T \Uparrow T' \\ \Gamma,\ t : T \vdash b \Uparrow b' }
  {\Gamma \vdash \Pi (t : T).b \Uparrow \Pi (t : T').b'}
\end{mathpar}
\caption{Generic lifting algorithm.}
\label{fig:final}
\end{figure}


\subsection{Correctness}

Here's the proof that as long as the correctness criteria hold, it's OK to take any of those steps.
Same definition as DEVOID paper for correctness but note we just consider one step at a time since
it's very undecidable to decide which ones to run. The implementation section talks about how we
decide this in practice.




\section{Proof Term Transformation}
\label{sec:meat}

At the core of \toolname is a configurable program transformation for transporting proof terms across equivalences.
There are two key insights beneath \toolname that inform this design:

\begin{enumerate}
\item Proof refactoring and proof repair are just proof reuse over time. That is, refactoring or repairing
a proof that is broken due to a change in specification amounts to reusing the proof about the old specification
in the proof about the new specification.
\item We can view any change in specification as inducing at least one type equivalence,
possibly with additional information (for non-semantics-preserving changes).
Reusing a proof about the old specification then amounts to transporting the proof across the equivalence.
\end{enumerate}
(2) alone makes it tempting to use univalent transport like in HoTT or in the univalent parametricity framework.
This is nice, but as DEVOID notes, means referring back to the old specification, which we can't do because of (1),
and gets really slow over time. % TODO will need to cite current UP work, maybe when we get to equality
DEVOID addresses this by implementing a program transformation for transport across a particular class of equivalences,
but this is pretty narrow.

We generalize the transformation from DEVOID to handle other equivalences.
The result is a configurable (Section~\ref{sec:art}) proof term transformation (Section~\ref{sec:transform}).
The configuration can be supplied either by search procedure to support an entire class of equivalences,
or can be provided by the user of \toolname directly;
we discuss some examples of both in Section~\ref{sec:search}.

\subsection{Transformation}
\label{sec:transform}

Figure~\ref{fig:final} shows the configurable proof term transformation,
which is parameterized over two equivalent types (rule \lstinline{Equivalence}).
Most of it is standard with the exception of the four rules that correspond to the configuration:

\begin{enumerate}
\item Rules \lstinline{Dep-Constr} and \lstinline{Dep-Elim} for transforming constructors and eliminators 
\item Rules \lstinline{Id-Eta} and \lstinline{Rew-Eta} for transforming identity and equalities
\end{enumerate}
These transformations rules, taken together, both induce a particular equivalence and ensure that the transformation
preserves it and produces well-typed terms.
In short, (1) ensures the transformation preserves the \textit{equivalence} between our old and new specifications,
while (2) ensures that the transformation respects \textit{equalities} in the original proof.
The former of these just means that it implements transport, while the latter deals specifically
with the fact that we do not have univalence (which would state that equivalence is equivalent to equality),
so for the transformation to produce terms that type-check, we must transform equalities too.
This is a problem the marriage of univalence and parametricity notes as intractable in general---it turns out
to be easily describable, but there are many challenges to implemention which we will note in Section~\ref{sec:implementation}.

\paragraph{Constructors and Eliminators} Explanation, intuition, simple example.

\paragraph{Identity and Rewrites} Explanation, intuition, simple example.

\begin{figure}
\begin{mathpar}
\mprset{flushleft}
\small
\hfill\fbox{$\Gamma$ $\vdash$ $t$ $\Uparrow$ $t'$}\\

\inferrule[Dep-Elim]
  { \Gamma \vdash p_{a} \Uparrow p_b \\ \Gamma \vdash \vec{f_{a}}\phantom{l} \Uparrow \vec{f_{b}} }
  { \Gamma \vdash \mathrm{DepElim}(a,\ p_{a}) \vec{f_{a}} \Uparrow \mathrm{DepElim}(b,\ p_b) \vec{f_{b}} }

\inferrule[Dep-Constr]
{ \Gamma \vdash \vec{t}_{a} \Uparrow \vec{t}_{b} } %\\ TODO must we explicitly lift A to B if we want to handle parameters/indices?
{ \Gamma \vdash \mathrm{DepConstr}(j,\ A)\ \vec{t}_{a} \Uparrow \mathrm{DepConstr}(j,\ B)\ \vec{t}_{b}  }

\inferrule[Id-Eta]
  { \\ }
  { \Gamma \vdash \mathrm{IdEta}(A) \Uparrow \mathrm{IdEta}(B) }

\inferrule[Rew-Eta]
  { \Gamma \vdash c_A \Uparrow c_B \\ \Gamma \vdash q_A \Uparrow q_B \\ \Gamma \vdash e_A \Uparrow e_B }
  { \Gamma \vdash \mathrm{RewEta}(j, A, q_A, t_A) \Uparrow \mathrm{RewEta}(j, B, q_B, t_B) }

\inferrule[Equivalence]
  { \\ }
  { \Gamma \vdash A\ \Uparrow B }

\inferrule[Constr]
{ \Gamma \vdash T \Uparrow T' \\ \Gamma \vdash \vec{t} \Uparrow \vec{t'} }
{ \Gamma \vdash \mathrm{Constr}(j,\ T)\ \vec{t} \Uparrow \mathrm{Constr}(j,\ T')\ \vec{t'} }

\inferrule[Ind]
  { \Gamma \vdash T \Uparrow T' \\ \Gamma \vdash \vec{C} \Uparrow \vec{C'}  }
  { \Gamma \vdash \mathrm{Ind} (\mathit{Ty} : T) \vec{C} \Uparrow \mathrm{Ind} (\mathit{Ty} : T') \vec{C'} }

\inferrule[Elim] % TODO wait why do we have c here when it clearly refers to the term we eliminate over? um
  { \Gamma \vdash c \Uparrow c' \\ \Gamma \vdash Q \Uparrow Q' \\ \Gamma \vdash \vec{f} \Uparrow \vec{f'}}
  { \Gamma \vdash \mathrm{Elim}(c, Q) \vec{f} \Uparrow \mathrm{Elim}(c', Q') \vec{f'}  }

%% Application
\inferrule[App]
 { \Gamma \vdash f \Uparrow f' \\ \Gamma \vdash t \Uparrow t'}
 { \Gamma \vdash f t \Uparrow f' t' }

% Lamda
\inferrule[Lam]
  { \Gamma \vdash T \Uparrow T' \\ \Gamma,\ t : T \vdash b \Uparrow b' }
  {\Gamma \vdash \lambda (t : T).b \Uparrow \lambda (t : T').b'}

% Product
\inferrule[Prod]
  { \Gamma \vdash T \Uparrow T' \\ \Gamma,\ t : T \vdash b \Uparrow b' }
  {\Gamma \vdash \Pi (t : T).b \Uparrow \Pi (t : T').b'}
\end{mathpar}
\caption{Proof term transformation.}
\label{fig:final}
\end{figure}

\subsection{Configuration}
\label{sec:art}

The transformation is configurable by equivalence, but choosing the configuration (either by providing direct input or writing a 
search procedure for an entire class of equivalences) is a bit of an art: There can be infinitely many equivalences that correpond to a 
given change in specification, only some of which are useful. Furthermore, different configurations based on those equivalences
can be more or less useful than others. Finally, certain proof obligations for configuring the transformation can be tricky.
Thankfully, once that art is done, we know what it means for it to be correct.

The correctness criteria for the configuration relate \lstinline{DepConstr}, \lstinline{DepElim}, \lstinline{IdEta}, and \lstinline{RewEta}
in a particular way.
This goes back to the equivalence and equality thing from the previous section.
Formal thing here, intuition for what it means for the whole thing, explanation, and example.
Section~\ref{sec:search} shows some particular instantions of this and their applicability to real programs and proofs.

%Nicolas proved the first of these a while ago
%for the equivalence in the DEVOID ITP paper.\footnote{\url{https://github.com/CoqHott/univalent_parametricity/commit/7dc14e69942e6b3302fadaf5356f9a7e724b0f3c}}

Note about decidability of matching: when all of this is correct, what this means is that you \textit{can} always
run one of the transformation rules. But that doesn't mean you \textit{should}. Depends what the user wants,
and in some cases, would not terminate (refinement types, unpacking indexed types). Implementation section will
discuss how we actually decide which ones to run so user doesn't need to apply transport by hand over and over again,
and discussion section describes some cool ideas for doing this nicely with type-based search in the future.

\paragraph{Preserving Equivalence} Explanation and example.

\paragraph{Preserving Equality} Explanation and example.

%First we need that \lstinline{DepElim} over $A$ into \lstinline{DepConstr} over $B$ and \lstinline{DepElim} over $B$ into
%\lstinline{DepConstr} over $A$ form an equivalence between $A$ and $B$. When that's true, I think it should hold that \lstinline{DepElim} over $A$
%and \lstinline{DepElim} over $B$ are in univalent relation with one another. If not, then that's an extra condition.
%Finally, we need the transformation to preserve definitional equalities. Not sure about the general case, but for vectors and lists,
%we need:

%\begin{lstlisting}
%  $\forall$ A l (f : $\forall$ (l : sigT (Vector.t A)), l = l),
%    vect_dep_elim A (fun l => l = l) (f nil) (fun t s _ => f (cons t s)) l = f (id_eta l).
%\end{lstlisting}
%and:

%\begin{lstlisting}
%Definition elim_id (A : Type) (s : {H : nat & t A H}) :=
%  vect_dep_elim
%    A
%    (fun _ => {H : nat & t A H})
%    nil
%    (fun (h : A) _ IH =>
%      cons h IH)
%    s.

% $\forall$ A h s,
%    exists (H : cons h (elim_id A s) = elim_id A (cons h s)),
%      H = eq_refl.
%\end{lstlisting}
%More generally, for each constructor index $j$, define:

%\begin{lstlisting}
%  eqc (j, B) (f : $\forall$ b : B, b = b) :=
%    fun ... (* TODO get the hypos from the type of the eliminator *) =>
%      f (DepConstr (j, B)) (* TODO args *)%%

  %elim_id := (* TODO *)
%\end{lstlisting}
%Then we need:

%\begin{enumerate}
%\item $\forall b f, \mathrm{DepElim}(b,\ p_{b}) \{\mathrm{eqc} (1, B) f, \ldots, \mathrm{eqc} (n, B) f\} = f (\mathrm{IdEta}(A) a) $
%\item Something relating the constructors and \lstinline{elim_id} to reflexivity
%\end{enumerate}
%and similarly for $A$.

%Really the point of these conditions is that from them, with some restrictions on input terms, we can get
%that lifting terms gives us the same type that we'd get from lifting the type. But there are still
%some restrictions (see the few that fail).

%It's probably not always possible to define these three things for every equivalence.
%Could generalize by rewriting. But this lets us avoid the rewriting problem from Nicolas' paper.

% TODO how does this get us something like primitive projections? Just makes IdEta definitionally equal to regular Id?

% TODO so we can probably just frame search in terms of DepConstr and DepElim and then generate proofs about this on an ad-hoc basis
% and get away with not including the specific details of our instantiations. We can give examples instead, give intuition, and say we generate
% the proofs in Coq

%For the second one we need not just an eliminator rule but also an identity rule.
%DEVOID assumed primitive projections which let them get away without thinking of this,
%but then had this weirdly ad-hoc ``repacking'' thing in their implementation.
%It turns out this is just a more general identity rule, which basically says what
%the identity function should lift to so that the transformation preserves definitional equalities.
%Actually deciding when to run this rule is one of the biggest challenges in practice,
%so we'll talk about that more in the implementation section.



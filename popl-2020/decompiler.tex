\section{Decompiling Proof Terms to Tactics}
\label{sec:decompiler}

\textbf{Transform} produces a proof term,
while the proof engineer typically writes and maintains proof scripts made up of tactics.
We improve user experience thanks the realization that, since Coq's proof term language Gallina is very structured,
we can decompile these Gallina terms to Ltac proof scripts for the proof engineer to maintain. In other words:

\begin{quote}
\textbf{Insight 3}: The transformed proof terms can then be translated back to tactics.
\end{quote}

The \textbf{Decompile} component implements a prototype of this translation.
This decompiler prototype has shown early promising results.
For example, it produced the automatically generated tactic proof for \lstinline{rev_app_distr} 
in Section~\ref{sec:overview}, as well as the tactic proofs of \lstinline{section}
and \lstinline{retraction} in Section~\ref{fig:equivalence}.

The output language for the implementation of \textbf{Decompile} is Ltac, the proof script language for Coq.
Ltac can be confusing to reason about, since Ltac tactics can refer to Gallina terms, and the semantics of Ltac depends both on the
semantics of Gallina and on the implementation of proof search procedures written in OCaml.
To give a sense of how the decompiler works without the clutter of these proof search details, we start by defining a toy
decompiler from CIC$_{\omega}$ to a simple subset of Ltac containing just a few predefined tactics (Section~\ref{sec:first}).
We then explain how we scale that up to the actual implementation (Section~\ref{sec:second}).

\subsection{A Toy Decompiler}
\label{sec:first}

\begin{figure}
\small
\begin{grammar}
<v> $\in$ Vars, <t> $\in$ CIC$_{\omega}$

<p> ::= intro <v> |  rewrite <t> <t> | symmetry | apply <t> | induction <t> <t> \{ <p>, \ldots, <p> \} | split \{ <p>, <p> \} | left | right | <p> . <p>
\end{grammar}
\caption{Qtac syntax.}
\label{fig:ltacsyntax1}
\end{figure}

The toy decompiler takes CIC$_{\omega}$ terms and produces tactics in a toy version of Ltac which we call Qtac.\footnote{Pronounced \textit{cute-tac}}.
The syntax for Qtac is in Figure~\ref{fig:ltacsyntax1}.
Qtac includes hypothesis introduction (\lstinline{intro},
rewriting by equalities (\lstinline{rewrite}), symmetry (\lstinline{symmetry}) of equality,
application of a term to prove the goal (\lstinline{apply}), induction over terms (\lstinline{induction}),
case splitting of conjunctions (\lstinline{split}),
constructors of disjunctions (\lstinline{left} and \lstinline{right}), and
composition (\lstinline{.}).

Unlike in Ltac, in Qtac, \lstinline{induction} and \lstinline{rewrite} always take a motive explicitly, rather than relying on a unification engine.
Smilarly, \lstinline{apply} applies only the function without inferring any arguments, and leaves those arguments to proof obligations.
The implementation reasons about Ltac and so does not make these assumptions.

\begin{figure}
\begin{mathpar}
\mprset{flushleft}
\small
\hfill\fbox{$\Gamma$ $\vdash$ $t$ $\Rightarrow$ $p$}\\

\inferrule[Intro]
  { \Gamma,\ n : T \vdash b \Rightarrow p }
  { \Gamma \vdash \lambda (n : T) . b \Rightarrow \mathrm{intro}\ n.\ p }

\inferrule[Symmetry]
  { \Gamma \vdash H \Rightarrow p }
  { \Gamma \vdash \mathtt{eq\_sym}\ H \Rightarrow \mathrm{symmetry}.\ p }

\inferrule[Split]
  { \Gamma \vdash l \Rightarrow p \\ \Gamma \vdash r \Rightarrow q }
  { \Gamma \vdash \mathrm{Constr}(0,\ \wedge)\ l r \Rightarrow \mathrm{split} \{ p, q \}.\ }

\inferrule[Rewrite]
  { \Gamma \vdash H_1 : x = y \\ \Gamma \vdash H_2 \Rightarrow p }
  { \Gamma \vdash \mathrm{Elim}(H_1,\ P) \{ x,\ H_2,\ y \} \Rightarrow \mathrm{symmetry}.\ \mathrm{rewrite}\ P\ H_1.\ p }

\inferrule[Induction]
  { \Gamma \vdash \vec{f} \Rightarrow \vec{p} }
  { \Gamma \vdash \mathrm{Elim}(t,\ P)\ \vec{f} \Rightarrow \mathrm{induction}\ P\ t\ \vec{p} }

\inferrule[Left]
  { \Gamma \vdash H \Rightarrow p }
  { \Gamma \vdash \mathrm{Constr}(0,\ \vee)\ H \Rightarrow \mathrm{left}.\ p }

\inferrule[Right]
  { \Gamma \vdash H \Rightarrow p }
  { \Gamma \vdash \mathrm{Constr}(1,\ \vee)\ H \Rightarrow \mathrm{right}.\ p }

\inferrule[Apply]
  { \Gamma \vdash t \Rightarrow p }
  { \Gamma \vdash f t \Rightarrow \mathrm{apply}\ f.\ p }

\inferrule[Base]
  { \\ }
  { \Gamma \vdash t \Rightarrow \mathrm{apply}\ t }
\end{mathpar}
\caption{Toy decompiler semantics.}
\label{fig:someantics}
\end{figure}

The semantics for the toy decompiler are in Figure~\ref{fig:someantics} (assuming $=$, \lstinline{eq_sym}, $\wedge$, and $\vee$ are defined as in Coq).
This decompiler works like the real decompiler: it accepts a proof term and generates a candidate proof script that attempts to prove the same theorem.
As with the real decompiler, the baseline for success of the toy decompiler is the naive proof script
that applies the entire proof term with the \lstinline{apply} tactic.
Such a proof script will always work, but will often be unreadable.
The decompiler defaults to this baseline behavior (\textsc{Base}).

Otherwise, the goal of the decompiler is to improve on that baseline as much as possible,
or else produce a candidate proof script that is close enough that the proof engineer can manually massage it into something that
both works and is maintainable.
It does this by recursing over the proof term and constructing a proof script using a predefined set of tactics.

For the toy decompiler, this is fairly straightforward: Lambda terms become introduction of hypotheses (\textsc{Intro}), since they introduce new bindings
in the environment of the body. Applications of \lstinline{eq_sym} become symmetry of equality (\textsc{Symmetry}).
Constructors of conjunction and disjunction become map to the respective tactics (\textsc{Split}, \textsc{Left}, and \textsc{Right}).
Applications of equality eliminators compose symmetry (to orient the rewrite direction with the goal) with rewrites (\textsc{Rewrite}),
and all other applications of eliminators become induction (\textsc{Induction}).
The remaining applications become apply tactics (\textsc{Apply}).
In all cases, the decompiler recurses on the remaining body, breaking into cases when relevant, until no other preconditions match.
At that point the \textsc{Base} case holds, and we are done.

% TODO example

\subsection{Scaling Up}

The prototype decompiler works by decompiling proof terms to candidate proof scripts that 
use a predefined set of Ltac tactics.
It then pretty-prints and helps clean up that proof script for the proof engineer.
The proof engineer can massage the final result as desired into a proof script that both works and is maintainable.

Coq instead of CIC$_{\omega}$.
extend with let expressions. pose. rewrite-in. apply-in. subgoals for those.
checking if let binding is actually in the conclusion.
skipping if it is not.

matching/non-primitive eliminatorss

simplifying rewrites

rewrite direction

inductive motives, revert, generalize

\begin{figure}
\small
\begin{grammar}
<d> $\in$ \{ $\leftarrow$, $\rightarrow$ \}, <v> $\in$ Vars, <t> $\in$ Gallina

<p> ::= Intro <v> | Intros \{<v>,\ldots,<v>\} | Revert \{<v>, \ldots, <v>\} | Pose <t> <v> | \\
Apply <t> | Rewrite <d> <t> | Induction <t> \{ <p>, \ldots, <p> \} | Split \{ <p>, <p> \} | \\
ApplyIn <t> <t> \{ <p>, \ldots, <p> \} | RewriteIn <d> <t> <t> \{ <p>, \ldots, <p> \} | \\
Reflexivity | Simpl | Left | Right | Symmetry | <p> . <p>
\end{grammar}
\caption{Syntax for a predefined set of Ltac tactics.}
\label{fig:ltacsyntax2}
\end{figure}

\paragraph{Rewrite In}
Rewrite-in transforms an existing hypothesis by binding a new hypothesis to replace all occurrences of the original in the remainder of the proof.
\lstinline{let _ : _ := eq_ind _ _ _ H2 _ H1 in _} where
		H2 is a hypothesis in context,
		H2 doesn’t occur in the body.
		Generate \lstinline{rewrite H1 in H2}. Recurse on body.

\paragraph{Apply In}
Apply-in transforms a hypothesis by applying a function to it, rebinding its type to the result of the function.
		In general,
		\lstinline{let _ : _ := f H in _} where
		H is a hypothesis in context,
		H doesn’t occur in the body.
		Generate  \lstinline{apply f in H}. Recurse on body.
		Unless we have,
		\lstinline{let H2 : _ := f H1 in H2 _} where
function \lstinline{f} expects additional arguments after \lstinline{H1}.
Performing \lstinline{apply f in H1}, Coq transforms the goal to be the result type of \lstinline{f}, and creates additional goals for arguments required after H1. Thus, we recurse on H2 and all following arguments it’s applied to.


\paragraph{Introduction}
Lambda abstractions correspond to assumptions of hypotheses. Thus, each abstraction generates an “intro” tactic, adding a new hypothesis into the environment. The algorithm recurses on the body of the abstraction.

\paragraph{Rewriting}
Applications of the equality eliminators (eq_ind, eq_rec, eq_rect, eq_ind_r, eq_rec_r, eq_rect_r) generate a single “rewrite” tactic. In an Ltac proof, rewrite accepts a proof of equality between two terms and transforms the goal. The following tactics must prove the new goal. The decompiler generates a rewrite of the equality (the sixth argument of the eliminator) and recurses on the new goal (the fourth argument). If the eliminator is without the “_r”, then it is written “rewrite <-“ indicating the direction of the equality. (???)

\paragraph{Induction}
Applications of induction eliminators are deconstructed into a proof of each case, arguments to the motive, and the value we perform induction on.
The position of the inducted value (hard time explaining this): Pos = \# of arguments … – pms + 1 (???)
Following the inducted value are additional arguments to the motive. A “revert” tactic is inserted for each such hypothesis before induction. This forgets the hypotheses by adding them as arguments to the goal, producing a motive requiring these arguments exactly, and so they must be re-introduced in each case.

\paragraph{Left}
Application of \lstinline{or_introl}, constructing a logical or. A \lstinline{left} tactic is generated, transforming the goal to be the left side of the disjunction, and we recurse on the given proof.
Vs. (template-y description)
\lstinline{@or_introl A B H : A \/ B}
Generate \lstinline{left.}
Recurse on \lstinline{H.}

\paragraph{Right}
Application of \lstinline{or_intror}, constructing a logical or. A \lstinline{right} tactic is generated, transforming the goal to be the left side of the disjunction, and we recurse on the given proof.

\paragraph{Split}
Application of \lstinline{conj} constructing a logical and. A \lstinline{split} tactic is generated, creating a goal for each side of the conjunction, and we recurse on both proofs, generating the left side first.

\paragraph{Symmetry}

\paragraph{Pose}
Pose is a catch-all for let-expressions. It explicitly binds a new name to a value.
\lstinline{let A : B := C in D} generates \lstinline{pose C as A}, recurse on the body.

\subsection{Cleanup \& Printing}
\label{sec:second}

Pretty printing at the very end.
Collapse multiple \lstinline{intro}s of several assumptions into a single \lstinline{intros} tactic assuming multiple hypotheses.
Replace all \lstinline{apply eq_refl} with the \lstinline{reflexivity} tactic.
\lstinline{simpl} before \lstinline{rewrite} (for now just always when we do induction, but eventually can be smarter based on motive) (technically not
in second pass yet, but easier conceptually).
Cool things we could do with this: use original tactics, semicolons. Apply just the function name instead of the whole application (need to try it out, this pass is a good place to try it out). Morphisms. Decision procedures.

take user input here,

not same tactics as original

not perfect





\section{Discussion: Univalent Constraint Solvers}
\label{sec:discussion}

The program transformation from Section~\ref{sec:meat} implements transport between equivalent types \A and \B.
However, it alone does not help the user in any way decide when to \textit{apply} transport.
This is a problem independent from whether transport is implemented as a function in the type theory itself
or as a program transformation.
Many implementations of transport, like those in CoqHoTT and Cubical Agda, % TODO check
do not include any automation to help the user with this decision.

\toolname automates the most basic case of this when possible: changing \textit{every} occurrence of \A to \B.
However, even for repair, this is not always what the user wants, and this can lead to confusing behavior (Section~\ref{sec:ideal}).
The ideal would be a type-directed search procedure that decides when to apply transport,
whether that transport is implemented as a function or a program transformation.
The only solution we are aware of so far for this is that of the univalent parametricity framework,
which as the authors note can sometimes be slow or unpredictable without user-supplied hints.

The key to implementing efficient type-directed automatic transport both for \toolname
and for other systems may be to adapt special data structures from the constraint solver world to use a
notion of equivalence that corresponds to equality up to transport (Section~\ref{sec:key}).
This may help not only build better proof refactoring and repair tools, but also build better proof reuse tools,
implement better congruence tactics in univalent type theories, and better automate transport in HoTT.

\subsection{Type-Directed Search is Ideal}
\label{sec:ideal}

\toolname replaces every occurrence of \A with an occurrence of \B.
Because of this, users sometimes encounter confusing behavior.
Consider an example from the industrial user from Section~\ref{sec:industry}.
That user's compiler had at one point generated the following specifications and function:

\begin{lstlisting}
Module Generated.

  Definition input := (bool * (nat * bool)).

  Definition output := (nat * bool).

  Definition op (r : (bool * (nat * bool))) : (nat * bool) :=
    pair (fst (snd r)) (andb (fst r) (snd (snd r))).

Emd Generated.
\end{lstlisting}
He wished to port those tuple specifications to records:

\begin{lstlisting}
Record input :=
  MkInput { firstBool : bool; numberI : nat; secondBool : bool }.

Record output :=
  MkOutput { numberO : nat; andBools : bool }.
\end{lstlisting}
Whether or not this succeeded with \toolname depended on the order that the user
called the \lstinline{Repair} command.
If the user called \lstinline{Repair} in this order:

\begin{lstlisting}
Repair Generated.input input in Generated.op as op_1.
Repair Generated.output output in op_1 as op.
\end{lstlisting}
then \toolname managed to define the correct lifted \lstinline{op}:

\begin{lstlisting}
Definition op (r : input) : output :=
  {|
      numberO := numberI r;
      andBools := andb (firstBool r) (secondBool r)
  |}.
\end{lstlisting}
The user could then write his proofs over these records,
then lift those proofs back to get analogous proofs over the original specification.

This failed, however, if the user instead chose to call \lstinline{Repair} in the opposite order:

\begin{lstlisting}
Repair Generated.output output in Generated.op as op_1.
Repair Generated.input input in op_1 as op.
\end{lstlisting}
This generated this function instead:

\begin{lstlisting}
Definition op (r : bool * output) : output := 
  {|
    numberO := numberO (snd r);
    andBools := andb (fst r) (andBools (snd r))
  |}.
\end{lstlisting}
While this function behaves the same way as \lstinline{Generated.op}, it is not the one that the user wanted.

The problem that the user encountered here was that the argument \lstinline{r : (bool * (nat * bool))} to
\lstinline{Generated.op} could be thought of as having type \lstinline{Generated.input}, or as having type
\lstinline{bool * Generated.output}.
There are thus multiple correct implementations of \lstinline{op} to choose from,
and which one \toolname chooses depends on the order of calls to \lstinline{Repair}.

The user found this confusing and limiting.
He agreed that the better solution would be implementing automatic transport as type-directed search.
That way, the user could just say:

\begin{lstlisting}
Repair Generated.op as op : input -> output.
\end{lstlisting}
and \toolname would apply the program transformation along the correct equivalences
to produce \lstinline{op} with the correct type.

We are aware of exactly one implementation of type-directed automatic transport:
the univalent parametricity framework uses type classes coupled with user-defined hints to implement type-based search.
However, the authors note that this approach scales poorly, and that without the right user-defined
hints, it can be slow or diverge.
This is a step in the right direction, but it is not enough.

\subsection{Enter Univalent E-Graphs}
\label{sec:key}

Automatic transport is really nothing but a rewrite system.
Equality up to transport is just an equivalence relation, and automatic transport just searches for proofs of that relation and rewrites along those proofs, either by directly applying transport (in homotopy type theory and univalent parametricity) or by transforming the term in a metalanguage (in \toolname).

When thinking about how to build clean and efficient type-directed transport, then, we find it natural to look
at how other programming languages communities have already implemented clean and efficient rewrite systems.
Modern rewrite systems often use special data structures called e-graphs that are built specifically
for clean and efficient rewriting across equivalences.
They are used, for example, inside of SMT solvers like Z3.
They are basically designed to help deal with the problem like the one we saw with op earlier, when there were multiple equivalences to 
choose from.

Recent work extended these data structures to handle dependent types. The result was wonderful automation of equality proofs in the Lean theorem prover. The cost was introducing an axiom called UIP to Lean that is not in Coq and is incompatible with homotopy type theory (without any axioms, the notion of equality between dependent types is just not very useful for automation like this).

What if we were to implement this data structure for equality up to transport rather than heterogenous equality as in Lean? In univalent type theories like homotopy type theory, I bet we could implement automatic transport this way, using what would essentially be an extremely powerful congruence tactic coupled with the transport function. In the univalent parametricity framework, I imagine we could get much more predictable and efficient type-directed transport when managing a lot of equivalences. And in \toolname, I bet we could also get efficient type-directed search.

I think this also hides the key to better proof repair. Proof repair is really nothing but proof reuse over time. And I bet that, in a dependently-typed language, you can think of any change as an equivalence between sigma types. The problem just becomes exposing a good interface around searching for and transporting along this equivalence (maybe using example-based search like the original PUMPKIN PATCH, maybe doing something different), getting rid of all references to the old type (which \toolname can do), and then hopefully at some point converting everything back to a reasonable, maintainable set of tactics (which our decompiler does). This is the future, guys.

% TODO e-matching---matching RewEta is just letting the user add additional rewrite rules (or call out to custom code).
% see chandra conversation.
% cite szalinski to note how to not be just syntactic/how to call out to something else

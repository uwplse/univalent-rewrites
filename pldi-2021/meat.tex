\section{A Configurable Proof Term Transformation}
\label{sec:key2}

At the heart of \toolname is a configurable proof term transformation for transporting
proofs across equivalences (\href{https://github.com/uwplse/pumpkin-pi/blob/master/plugin/src/automation/lift/lift.ml}{lift.ml}). 
This proof term transformation is a generalization of the transformation from 
\textsc{Devoid}~\cite{Ringer2019}, which solved this problem for a particular class of equivalences.
\toolname moves the reasoning specific to that class of equivalences into the configuration. 

\begin{quote}
\textbf{Insight 2}:
A configurable proof term transformation can be used to build such a proof repair tool,
and the result can handle many different kinds of changes.
\end{quote}

This section starts by introducing the configuration (Section~\ref{sec:configurable}),
then introduces the proof term transformation that builds on that (Section~\ref{sec:generic}).
It then gives intuition for what it means for a configuration to be correct (Section~\ref{sec:art}),
and finally describes the additional work needed to go from this transformation to the implementation (Section~\ref{sec:implementation}). 

\paragraph{Conventions}
All terms that we introduce in this section are in CIC$_{\omega}$ (the core calculus of Coq) with primitive eliminators,
the syntax for which is in Figure~\ref{fig:syntax}.
The typing rules are standard.
We assume the existence of an inductive type $\Sigma$ with constructor $\exists$ and projections $\pi_l$ and $\pi_r$.
Throughout, we use $\vec{t}$ and $\{t_1, \ldots, t_n\}$ to denote lists of terms.

\begin{figure}
\small
\begin{grammar}
<i> $\in \mathbbm{N}$, <v> $\in$ Vars, <s> $\in$ \{ Prop, Set, Type<i> \}

<t> ::= <v> | <s> | $\Pi$ (<v> : <t>) . <t> | $\lambda$ (<v> : <t>) . <t> | <t> <t> | \\ 
Ind (<v> : <t>)\{<t>,\ldots,<t>\} | Constr (<i>, <t>) | Elim(<t>, <t>)\{<t>,\ldots,<t>\}
\end{grammar}
\vspace{-0.3cm}
\caption{Syntax for CIC$_\omega$ from \citet{Timany2015FirstST} with (from left to right) variables, sorts, dependent types, functions, application, inductive types, inductive constructors, and primitive eliminators.}
\label{fig:syntax}
\end{figure}

\subsection{The Configuration}
\label{sec:configurable}

The configuration is the key to building a proof term transformation that implements transport in a way that is suitable for repair.
%Before introducing the proof term transformation, we will describe the configuration, which in effect specifies the behavior
%of the transformation.
%It instantiates the proof term transformation to two equivalent types \A and \B, so that the proof term transformation
%can transform terms defined over \A to terms defined over \B instead.
%The behavior of the proof term transformation at a particular equivalence hinges on correct configuration.
Each configuration corresponds to an equivalence \A $\simeq$ \B.
It deconstructs that equivalence into things that talk about \A, and things that talk about \B.
Furthermore, it does so in a way that allows the transformation to abstract away details
specific to the given equivalence, like the order or number of arguments to an induction principle or type.

At a high level, the configuration helps the transformation achieve two goals:

\begin{enumerate}
\item preserve equality up to transport along the equivalence between \A and \B, and
\item produce well-typed terms.
\end{enumerate}
This configuration is a pair of pairs:

\begin{lstlisting}
((DepConstr, DepElim), (Eta, Iota))
\end{lstlisting}
each of which corresponds to one of the two goals, namely:

\begin{enumerate}
\item \lstinline{DepConstr} and \lstinline{DepElim} define how to transform constructors and eliminators, thereby preserving the equivalence (Section~\ref{sec:equivalence}), and 
\item \lstinline{Eta} and \lstinline{Iota} define how to transform $\eta$-expansion and $\iota$-reduction of constructors and eliminators, thereby producing well-typed terms (Section~\ref{sec:equality}).
\end{enumerate}
Each of these is defined in CIC$_{\omega}$ for any given equivalence.
%\textbf{Configure} passes this configuration to \textbf{Transform}.
The four parts of this configuration must relate to one another in a particular way in order for the proof
term transformation to work correctly (Section~\ref{sec:art}).

\subsubsection{Preserving the Equivalence}
\label{sec:equivalence}

To preserve the equivalence, the configuration ports terms over \A to terms over \B by viewing each
term of type \B as if it is an \A.
This way, the rest of the transformation can replace values of \A with values of \B and
inductive proofs about \A with inductive proofs about \B, then recursively transform
subterms without changing the order or number of arguments.

The two configuration parts responsible for preserving this are \lstinline{DepConstr}
and \lstinline{DepElim} (\textit{dependent constructors} and \textit{eliminators}).
These describe how to construct and eliminate \A and \B, wrapping the types with a common inductive structure.
There must be the same number of dependent constructors and cases in dependent eliminators for \A and \B,
even if \A and \B are types with different numbers of constructors.

\begin{figure*}
\begin{minipage}{0.48\textwidth}
\begin{lstlisting}
DepConstr(0, list T) : list T := Constr((@\codediff{0}@), list T).(@\vspace{-0.04cm}@)
DepConstr(1, list T) t l : list T :=(@\vspace{-0.04cm}@)
  Constr ((@\codediff{1}@), list T) t l.(@\vspace{-0.04cm}@)
(@\vspace{-0.14cm}@)
DepElim(l, P) { p$_{\mathtt{nil}}$, p$_{\mathtt{cons}}$ } : P l :=(@\vspace{-0.04cm}@)
  Elim(l, P) { (@\codediff{p$_{\mathtt{nil}}$}@), (@\codediff{p$_{\mathtt{cons}}$}@) }.
\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}{0.48\textwidth}
\begin{lstlisting}
DepConstr(0, list T) : list T := Constr((@\codediff{1}@), list T).(@\vspace{-0.04cm}@)
DepConstr(1, list T) t l : list T :=(@\vspace{-0.04cm}@)
  Constr((@\codediff{0}@), list T) t l.(@\vspace{-0.04cm}@)
(@\vspace{-0.14cm}@)
DepElim(l, P) { p$_{\mathtt{nil}}$, p$_{\mathtt{cons}}$ } : P l :=(@\vspace{-0.04cm}@)
  Elim(l, P) { (@\codediff{p$_{\mathtt{cons}}$}@), (@\codediff{p$_{\mathtt{nil}}$}@) }.
\end{lstlisting}
\end{minipage}
\vspace{-0.3cm}
\caption{The dependent constructors and eliminators for old (left) and new (right) \lstinline{list}.}
\label{fig:listconfig}
\end{figure*}

For the \lstinline{list} change from Section~\ref{sec:overview},
the configuration that \toolname discovers uses the dependent constructors
and eliminators in Figure~\ref{fig:listconfig}. The dependent constructors for \lstinline{Old.list}
are the normal constructors with the order unchanged,
while the dependent constructors for \lstinline{New.list} swap constructors
back to the original order.
Similarly, the dependent eliminator for \lstinline{Old.list} is the normal eliminator for \lstinline{Old.list},
while the dependent eliminator for \lstinline{New.list} swaps cases.

These constructors and eliminators can be \textit{dependent}.
One example of this arises from implementing the change from \lstinline{list T} to \lstinline{packed_vect T}.
The configuration \toolname discovers for this configures the dependent constructors to pack the index into an existential, for example:

\begin{lstlisting}
DepConstr(0, packed_vect) : packed_vect T :=(@\vspace{-0.04cm}@)
  $\exists$ (Constr(0, nat)) (Constr(0, vector T)).
\end{lstlisting}
and the eliminator it discovers eliminates the projections:

\begin{lstlisting}
DepElim(s, P) { f$_0$ f$_1$ } : P ($\exists$ ($\pi_l$ s) ($\pi_r$ s)) :=(@\vspace{-0.04cm}@)
  Elim($\pi_r$ s, $\lambda$(n : nat)(v : vector T n).P ($\exists$ n v)) {(@\vspace{-0.04cm}@)
    f$_0$,(@\vspace{-0.04cm}@)
    ($\lambda$(t : T)(n : nat)(v : vector T n).f$_1$ t ($\exists$ n v))(@\vspace{-0.04cm}@)
  }. 
\end{lstlisting}

In both of these examples, the only interesting work moves into the configuration:
the configuration for the first example swaps constructors and cases,
and the configuration for the second example implements the constructor and eliminator rules from the \textsc{Devoid} transformation.
That way, the rest of the \toolname transformation does not need to add, drop, or reorder arguments.
%In essence, all of the difficult work moves into the configuration.
Furthermore, both examples use automatic configuration, which means that the \textbf{Configure} component of \toolname is able to 
discover \lstinline{DepConstr} and \lstinline{DepElim} from just the types \A and \B, taking care of even the difficult work.

\subsubsection{Producing Well-Typed Terms}
\label{sec:equality}

The other configuration parts \lstinline{Eta} and \lstinline{Iota} deal with producing well-typed terms,
in particular by transporting equalities.
A naive proof term transformation, as noted in \citet{tabareau2019marriage},
may fail to generate well-typed terms if it does not consider the problem of transporting equalities.
Otherwise, if the transformation transforms a term \lstinline{t : T} to some \lstinline{t' : T'}, it does not necessarily
hold that it transforms \lstinline{T} to \lstinline{T'}.

\lstinline{Eta} and \lstinline{Iota} describe how to transport equalities.
More formally, they define $\eta$-expansion and $\iota$-reduction of \A and \B,
which may be propositional rather than definitional, and so must be explicit in the transformation.
$\eta$-expansion describes how to expand a term to apply a constructor to an eliminator in a way that preserves propositional equality,
and is important for defining dependent eliminators~\cite{nlab:eta-conversion}.
$\iota$-reduction ($\beta$-reduction for inductive types) describes how to reduce an elimination of a constructor~\cite{nlab:beta-reduction}.

\begin{figure}
\begin{minipage}{0.44\columnwidth}
   \lstinputlisting[firstline=1, lastline=8]{nattobin.tex}
\end{minipage}
\hfill
\begin{minipage}{0.54\columnwidth}
   \lstinputlisting[firstline=10, lastline=17]{nattobin.tex}
\end{minipage}
\vspace{-0.3cm}
\caption{Unary (left) and binary (right) natural numbers.}
\label{fig:nattobin}
\end{figure}

The configuration for the change from \lstinline{list} to \lstinline{packed\_vect} has propositional \lstinline{Eta}.
To describe \lstinline{Eta}, it is enough to use the standard definition of $\eta$-expansion for $\Sigma$:

\begin{lstlisting}
Eta (packed_vect) :=
  $\lambda$(s : packed_vect).$\exists$ ($\pi_l$ s) ($\pi_r$ s).
\end{lstlisting}
which is propositional and not definitional in Coq.
Thanks to this, we can forego the assumption that our language has primitive projections (definitional $\eta$ for $\Sigma$).

Each \lstinline{Iota}---one per constructor---describes and proves the $\iota$-reduction behavior
of \lstinline{DepElim} on the corresponding case.
This is needed, for example, to port proofs about unary numbers \lstinline{nat} to
proofs about binary numbers \lstinline{N} (Figure~\ref{fig:nattobin}).
While we can in fact define \lstinline{DepConstr} and \lstinline{DepElim} to induce an equivalence
between them (see Section~\ref{sec:bin}), we run into trouble reasoning about applications of \lstinline{DepElim},
since proofs about \lstinline{nat} that hold by reflexivity do not necessarily hold by reflexivity over \lstinline{N}. 
For example, in Coq, while \lstinline{S (n + m)  = S n + m} holds by reflexivity over \lstinline{nat},
when we define \lstinline{+} with \lstinline{DepElim} over \lstinline{N},
the corresponding theorem over \lstinline{N} does not hold by reflexivity.

To transform proofs about \lstinline{nat} to proofs about \lstinline{N}, we must transform \textit{definitional} $\iota$-reduction over \lstinline{nat} to \textit{propositional} $\iota$-reduction over \lstinline{N}.
For our configuration in Section~\ref{sec:bin},
$\iota$-reduction is definitional over \lstinline{nat}, since a proof of:

\begin{lstlisting}
$\forall$ P p$_\texttt{0}$ p$_\texttt{S}$ n,
  DepElim((@\codediff{DepConstr(1, nat) n}@), P) { p$_\texttt{0}$ p$_\texttt{S}$ } =
  (@\codediff{p$_\texttt{S}$}@) n (DepElim(n, P) { p$_\texttt{0}$ p$_\texttt{S}$ }).
\end{lstlisting}
goes through by reflexivity.
However, the corresponding $\iota$ rule for \lstinline{N} is propositional, since:

\begin{lstlisting}
$\forall$ P p$_\texttt{0}$ p$_\texttt{S}$ n,
  DepElim((@\codediff{DepConstr(1, N) n}@), P) { p$_\texttt{0}$ p$_\texttt{S}$ } =
  (@\codediff{p$_\texttt{S}$}@) n (DepElim(n, P) { p$_\texttt{0}$ p$_\texttt{S}$ }).
\end{lstlisting}
no longer holds by reflexivity.
The \lstinline{Iota} rules are exactly rewrites along proofs of the theorems above for the successor case.
The transformation replaces rewrites by reflexivity over \lstinline{nat} to rewrites by propositional equalities over \lstinline{N}.
That way, \lstinline{DepElim} behaves the same over \lstinline{nat} and \lstinline{N}.

Taken together over both \A and \B, \lstinline{Iota} describes how the inductive structures of \A and \B differ from each other.
The transformation requires that \lstinline{DepElim} over \A and over \B always have the same inductive structure
as each other, so if \A and \B themselves have the same 
inductive structure (if they are \textit{ornaments}~\cite{mcbride}),
then if $\iota$-reduction is definitional over \lstinline{DepElim} on \A, it will be possible to choose
\lstinline{DepElim} with definitional $\iota$ on \B.
Otherwise, if \A and \B have different inductive structures, as with \lstinline{nat} and \lstinline{N},
then definitional $\iota$ over one would become propositional $\iota$ over the other.
For the case of \lstinline{nat} and \lstinline{N},
the need for propositional $\iota$ was noted as far back as \citet{magaud2000changing}.
\lstinline{Iota} in the configuration encodes this more generally.

\subsection{The Proof Term Transformation}
\label{sec:generic}

\begin{figure*}
\begin{mathpar}
\mprset{flushleft}
\small
\hfill\fbox{$\Gamma$ $\vdash$ $t$ $\Uparrow$ $t'$}\vspace{-0.4cm}\\

\inferrule[Dep-Elim]
  { \Gamma \vdash a \Uparrow b \\ \Gamma \vdash p_{a} \Uparrow p_b \\ \Gamma \vdash \vec{f_{a}}\phantom{l} \Uparrow \vec{f_{b}} }
  { \Gamma \vdash \mathrm{DepElim}(a,\ p_{a}) \vec{f_{a}} \Uparrow \mathrm{DepElim}(b,\ p_b) \vec{f_{b}} }

\inferrule[Dep-Constr]
{ \Gamma \vdash \vec{t}_{a} \Uparrow \vec{t}_{b} } %\\ TODO must we explicitly lift A to B if we want to handle parameters/indices?
{ \Gamma \vdash \mathrm{DepConstr}(j,\ A)\ \vec{t}_{a} \Uparrow \mathrm{DepConstr}(j,\ B)\ \vec{t}_{b}  }

\inferrule[Eta]
  { \\ }
  { \Gamma \vdash \mathrm{Eta}(A) \Uparrow \mathrm{Eta}(B) }

\inferrule[Iota]
  { \Gamma \vdash q_A \Uparrow q_B \\ \Gamma \vdash \vec{t_A} \Uparrow \vec{t_B} }
  { \Gamma \vdash \mathrm{Iota}(j,\ A,\ q_A)\ \vec{t_A} \Uparrow \mathrm{Iota}(j,\ B,\ q_B)\ \vec{t_B} }

\inferrule[Equivalence]
  { \\ }
  { \Gamma \vdash A\ \Uparrow B }

\inferrule[Constr]
{ \Gamma \vdash T \Uparrow T' \\ \Gamma \vdash \vec{t} \Uparrow \vec{t'} }
{ \Gamma \vdash \mathrm{Constr}(j,\ T)\ \vec{t} \Uparrow \mathrm{Constr}(j,\ T')\ \vec{t'} }

\inferrule[Ind]
  { \Gamma \vdash T \Uparrow T' \\ \Gamma \vdash \vec{C} \Uparrow \vec{C'}  }
  { \Gamma \vdash \mathrm{Ind} (\mathit{Ty} : T) \vec{C} \Uparrow \mathrm{Ind} (\mathit{Ty} : T') \vec{C'} }

%% Application
\inferrule[App]
 { \Gamma \vdash f \Uparrow f' \\ \Gamma \vdash t \Uparrow t'}
 { \Gamma \vdash f t \Uparrow f' t' }

\inferrule[Elim] % TODO wait why do we have c here when it clearly refers to the term we eliminate over? um
  { \Gamma \vdash c \Uparrow c' \\ \Gamma \vdash Q \Uparrow Q' \\ \Gamma \vdash \vec{f} \Uparrow \vec{f'}}
  { \Gamma \vdash \mathrm{Elim}(c, Q) \vec{f} \Uparrow \mathrm{Elim}(c', Q') \vec{f'}  }

% Lamda
\inferrule[Lam]
  { \Gamma \vdash T \Uparrow T' \\ \Gamma,\ t : T \vdash b \Uparrow b' }
  {\Gamma \vdash \lambda (t : T).b \Uparrow \lambda (t : T').b'}

% Product
\inferrule[Prod]
  { \Gamma \vdash T \Uparrow T' \\ \Gamma,\ t : T \vdash b \Uparrow b' }
  {\Gamma \vdash \Pi (t : T).b \Uparrow \Pi (t : T').b'}
\end{mathpar}
\vspace{-0.3cm}
\caption{Proof term transformation for transporting terms across an equivalence $A \simeq B$ described by configuration \lstinline{((DepConstr, DepElim), (Eta, Iota))}.}
\label{fig:final}
\end{figure*}

Figure~\ref{fig:final} shows the proof term transformation $\Gamma \vdash t \Uparrow t'$ that forms the core of \toolname.
%Like the transformation from \textsc{Devoid},
The transformation is parameterized over two equivalent types \A and \B (\textsc{Equivalence})
as well as the configuration terms, which appear in the transformation explicitly.
It assumes fully $\eta$-expanded functions.

The proof term transformation is (perhaps deceptively) simple because it moves the bulk of the work into the configuration,
and because it represents the configuration explicitly.
Of course, real proof terms that correspond to proofs that typical proof engineers write in Coq do not apply these configuration
terms explicitly.
\toolname does some additional work to get real proof terms into this format before running the transformation (Section~\ref{sec:unif}).
It then runs the proof term transformation, which transports proofs across the equivalence that corresponds to the configuration 
(Section~\ref{sec:transfspecif}).

\subsubsection{Unification Heuristics}
\label{sec:unif}

The transformation does not fully describe the search procedure for transforming terms that \toolname implements.
Before running the transformation, \toolname \textit{unifies} the 
input proof term with applications of the terms in the configuration for \A. 
The transformation then transforms the applications of the terms in the configuration of \A
to applications of the terms in the configuration for \B.
Reducing the result produces the output term defined over \B.

\begin{figure*}
\begin{minipage}{0.49\textwidth}
\begin{lstlisting}
(* 1: original term *)(@\vspace{-0.04cm}@)
$\lambda$ (T : Type) (l m : list T) .(@\vspace{-0.04cm}@)
 (@\codediff{Elim}@) (l, $\lambda$(l: Old.list T).list T $\rightarrow$ list T)) {(@\vspace{-0.04cm}@)
   ($\lambda$ m . m),(@\vspace{-0.04cm}@)
   ($\lambda$ t _ IHl m . (@\codediff{Constr}@)(1, Old.list T) t (IHl m))(@\vspace{-0.04cm}@)
 } m.(@\vspace{-0.04cm}@)
(@\vspace{-0.14cm}@)
(* 2: after unifying (@\texttt{with}@) configuration *)(@\vspace{-0.04cm}@)
$\lambda$ (T : Type) (l m : list T) .(@\vspace{-0.04cm}@)
 (@\codediff{DepElim}@) (l, $\lambda$(l: Old.list T).list T $\rightarrow$ list T)) {(@\vspace{-0.04cm}@)
   ($\lambda$ m . m)(@\vspace{-0.04cm}@)
   ($\lambda$ t _ IHl m . (@\codediff{DepConstr}@)(1, Old.list T) t (IHl m))(@\vspace{-0.04cm}@)
 } m.
\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}{0.49\textwidth}
\begin{lstlisting}
(* 4: reduced to final term *)(@\vspace{-0.04cm}@)
$\lambda$ (T : Type) (l m : list T) .(@\vspace{-0.04cm}@)
 (@\codediff{Elim}@) (l, $\lambda$(l: New.list T).list T $\rightarrow$ list T)) {(@\vspace{-0.04cm}@)
   ($\lambda$ t _ IHl m . (@\codediff{Constr}@)(0, New.list T) t (IHl m)),(@\vspace{-0.04cm}@)
   ($\lambda$ m . m)(@\vspace{-0.04cm}@)
 } m.(@\vspace{-0.04cm}@)
(@\vspace{-0.14cm}@)
(* 3: ported to New.list *)(@\vspace{-0.04cm}@)
$\lambda$ (T : Type) (l m : list T) .(@\vspace{-0.04cm}@)
 DepElim (l, $\lambda$(l: (@\codediff{New.list T}@)).list T $\rightarrow$ list T)) {(@\vspace{-0.04cm}@)
   ($\lambda$ m . m)(@\vspace{-0.04cm}@)
   ($\lambda$ t _ IHl m . DepConstr(1, (@\codediff{New.list T}@)) t (IHl m))(@\vspace{-0.04cm}@)
 } m.
\end{lstlisting}
\end{minipage}
\vspace{-0.3cm}
\caption{Swapping cases of the append function, with names fully qualified only when needed for clarity, counterclockwise: 1) the input, 2) the term unified with the configuration, 3) the term ported to the updated type, and 4) the term reduced to the final output.}
\label{fig:appswap1}
\end{figure*}

Figure~\ref{fig:appswap1} shows this with the list append function \lstinline{++} from Section~\ref{sec:overview}.
To update the append function (top left), \toolname
unifies subterms of the input term with implicit applications of \lstinline{DepConstr} and \lstinline{DepElim} and substitutes
in the configuration terms (bottom left).
After expansion, the transformation then recursively substitutes in \lstinline{New.list}
for \lstinline{Old.list}, which moves \lstinline{DepConstr} and \lstinline{DepElim}
to construct and eliminate over the updated type (bottom right).
Finally, this reduces to a term with swapped constructors and cases (top right).

In this case, unification is straightforward, since \lstinline{DepConstr} and \lstinline{DepElim} correspond to
\lstinline{Constr} and \lstinline{Elim} directly.
This can be more challenging when configuration terms are dependent or have uninstantiated parameters.
This is especially pronounced with definitional \lstinline{Eta} and \lstinline{Iota},
which typically show up contracted in real code.
This problem is exactly why \citet{tabareau2019marriage} speculated that converting definitional to propositional equalities
like we do with \lstinline{Iota} may, in general, be intractable.

To handle this, \toolname relies on \textit{unification heuristics} that tell \toolname how to unify subterms with applications of configuration terms, and how to instantiate parameters and dependent indices in those configuration subterms.
The transformation in turn assumes that all parameters and indices are fixed.

\toolname implements custom unification heuristics for each search procedure (\href{https://github.com/uwplse/pumpkin-pi/blob/master/plugin/src/automation/lift/liftconfig.ml}{liftconfig.ml}) as functions in OCaml that interact with type checking and equality in Coq.
These unification heuristics are incomplete.
\toolname falls back to Coq's unification for manual configuration and when these custom heuristics fail.
When even Coq's unification is not enough, \toolname relies on proof engineers to provide hints
in the form of explicit annotations.

\subsubsection{Specifying Correct Transformation}
\label{sec:transfspecif}

The goal of the proof term transformation is to preserve equality up to transport along the equivalence $A \simeq B$,
while no longer referring to the old specification.
That is, we need that $\Gamma \vdash t \Uparrow t' \rightarrow t \equiv_{A \simeq B} t'$, and that $t'$ refers to \B in place of \A.
%This is the same as the correctness criterion for the program transformation from \textsc{Devoid} that this is based on,
%with the transformation generalized to handle other equivalences beyond the class that \textsc{Devoid} supports.
The key steps in this transformation that make this possible are porting functions and proofs along the configuration corresponding
to a particular equivalence (\textsc{Dep-Constr}, \textsc{Dep-Elim}, \textsc{Eta}, and \textsc{Iota}).
The rest is straightforward.

Note that this goal for correctness is metatheoretical:
stating and proving that two terms are equal up to transport is in general not possible in a language like Coq
without additional axioms, though it is in some cases realizable with an external tool like the
univalent parametricity framework~\cite{tabareau2017equivalences}.
\toolname does not yet generate these proofs as we were focused on building a usable tool with axiomatic freedom and few dependencies.
Coq ensures that all terms that plugins produce are well-typed; for now, %as with \textsc{Devoid},
the proof engineer must vet the transformed specifications herself to ensure that they specify the expected behavior.

\subsection{Specifying Correct Configurations}
\label{sec:art}

Both when designing a search procedure for an automatic configuration and when
configuring \toolname manually, choosing a correct and useful configuration is important,
and it is not always straightforward. This section specifies what it means for these
to be correct and gives some intuition as to why.
Section~\ref{sec:search} shows some useful example configurations.

The configuration instantiates the proof term transformation to a particular equivalence between \A and \B.
Choosing an equivalence is a bit of an art:
there can be infinitely many equivalences that correspond to a 
given change in specification, only some of which are useful (for example, \href{https://github.com/uwplse/ornamental-search/blob/master/plugin/coq/playground/refine_unit.v}{refine_unit.v} proves that any \A is equivalent to \lstinline{unit} refined by \A).
Beyond that, even once we have chosen an equivalence, we could define many possible configurations that correspond
to the equivalence, some of which will produce functions and proofs that are more useful or efficient than others
(consider \lstinline{DepElim} converting through several intermediate types).

\begin{figure*}
\begin{lstlisting}
(* --- Equivalence --- *)(@\vspace{-0.04cm}@)
f : A $\rightarrow$ B := DepElim(a, $\lambda$(a : A).B){ $\lambda$ ... DepConstr(0, B) ..., ... }(@\vspace{-0.04cm}@)
g : B $\rightarrow$ A := DepElim(b, $\lambda$(b : B).A){ $\lambda$ ... DepConstr(0, A) ..., ... }(@\vspace{-0.04cm}@)
section : $\forall$ (a : A), g (f a) = a.(@\vspace{-0.04cm}@)
retraction : $\forall$ (b : B), f (g b) = b.(@\vspace{-0.04cm}@)
(@\vspace{-0.04cm}@)
dep_constr_ok : $\forall$ j, DepConstr(j, A) $\equiv_{A \simeq B}$ DepConstr(j, B).(@\vspace{-0.04cm}@)
dep_elim_ok : $\forall$ (a : A) (b : B) (P : A $\rightarrow$ Type) (Q : B $\rightarrow$ Type),(@\vspace{-0.04cm}@)
  a $\equiv_{A \simeq B}$ b $\rightarrow$ P $\equiv_{A \simeq B}$ Q $\rightarrow$ DepElim(a, P) $\equiv_{A \simeq B}$ DepElim(b, Q).(@\vspace{-0.04cm}@)
(@\vspace{-0.04cm}@)
(* --- Equality --- *)(@\vspace{-0.04cm}@)
eta_ok (A) : $\forall$ (a : A) (P : A $\rightarrow$ Type) $\vec{f}$, DepElim(a, P) $\vec{f}$ : P (Eta(A) a).(@\vspace{-0.04cm}@)
eta_ok (B) : $\forall$ (b : B) (P : B $\rightarrow$ Type) $\vec{f}$, DepElim(b, P) $\vec{f}$ : P (Eta(B) b).(@\vspace{-0.04cm}@)
(@\vspace{-0.04cm}@)
iota_ok (j, A) : $\forall$ (P : A $\rightarrow$ Type) $\vec{f}$ $\vec{x}$ (Q : P (DepConstr(j, A) $\vec{x}$) $\rightarrow$ Type),(@\vspace{-0.04cm}@)
  Q (DepElim(DepConstr(j, A) $\vec{x}$, P) $\vec{f}$) $\rightarrow$ (@\vspace{-0.04cm}@)
  Q ($\vec{f}$[j] ... (DepElim(IH$_0$, P) $\vec{f}$) ... (DepElim(IH$_n$, P) $\vec{f}$) ...)(@\vspace{-0.04cm}@)
:= Iota(A, j, Q).(@\vspace{-0.04cm}@)
iota_ok (j, B) : $\forall$ (P : B $\rightarrow$ Type) $\vec{f}$ $\vec{x}$ (Q : P (DepConstr(j, B) $\vec{x}$) $\rightarrow$ Type),(@\vspace{-0.04cm}@)
  Q (DepElim(DepConstr(j, B) $\vec{x}$, P) $\vec{f}$) $\rightarrow$ (@\vspace{-0.04cm}@)
  Q ($\vec{f}$[j] ... (DepElim(IH$_0$, P) $\vec{f}$) ... (DepElim(IH$_n$, P) $\vec{f}$) ...)(@\vspace{-0.04cm}@)
:= Iota(B, j, Q).
\end{lstlisting}
\vspace{-0.3cm}
\caption{Correctness criteria for a configuration \lstinline{(DepConstr, DepElim), (Eta, Iota)} to ensure that the transformation
preserves equivalence (top) coherently with equality (bottom). Throughout, $\vec{f}$, $\vec{x}$, and $\vec{\mathtt{IH}}$ represent
eliminator cases, constructor arguments, and inductive hypotheses, respectively.}
\label{fig:spec}
\end{figure*} % TODO sigs for Iota here are not quite correct---Q is not bound

Thankfully, once the art is done, we can specify what it means for it to be \textit{correct art}.
Figure~\ref{fig:spec} specifies the correctness criteria for any given configuration (assuming a univalent metatheory in which equality up
to transport is defined).
These correctness criteria relate \lstinline{DepConstr}, \lstinline{DepElim}, \lstinline{Eta}, and \lstinline{Iota}
in a way that preserves equivalence (Section~\ref{sec:equivalence}) coherently with equality (Section~\ref{sec:equality}).

\paragraph{Equivalence}
To preserve equivalence (Figure~\ref{fig:spec}, top), \lstinline{DepConstr} and \lstinline{DepElim} must together induce an equivalence between \A and \B.
That is, \lstinline{section} and \lstinline{retraction} must hold for two functions \lstinline{f} and \lstinline{g},
where \lstinline{f} uses \lstinline{DepElim} to eliminate \A and \lstinline{DepConstr} to construct \B, and \lstinline{g} uses 
\lstinline{DepElim} to eliminate \B and \lstinline{DepConstr} to construct \A.
\lstinline{DepConstr} over \B must be equal to \lstinline{DepConstr} over \A up to transport along the induced equivalence (\lstinline{dep_constr_ok}), 
and similarly for \lstinline{DepElim} (\lstinline{dep_elim_ok}).
This had previously been proven on the change from \lstinline{list T} to \lstinline{packed_vect T} in the 
univalent parametricity framework\footnote{\url{https://github.com/CoqHott/univalent_parametricity/commit/7dc14e69942e6b3302fadaf5356f9a7e724b0f3c}}---we build on that intuition.

\paragraph{Equality}
To ensure coherence with equality (Figure~\ref{fig:spec}, bottom),
\lstinline{Eta} and \lstinline{Iota} must correctly prove the $\eta$ and $\iota$ rules.
That is, \lstinline{Eta} must have the same definitional behavior as the dependent eliminator (\lstinline{eta_ok}).
Each \lstinline{Iota} must prove and rewrite along the simplification (formally, \textit{refolding}~\cite{boutillier:tel-01054723}) behavior that corresponds to a case of the dependent eliminator (\lstinline{iota_ok}).

\paragraph{Intuition for Correctness}
The correctness criteria for equivalence make it possible for the transformation
to avoid applying \lstinline{f} and \lstinline{g} explicitly---instead porting terms from \A directly to \B.
Intuitively, \lstinline{dep_constr_ok} and \lstinline{dep_elim_ok} guarantee that the transformation
correctly transports dependent constructors and dependent eliminators,
as doing so will preserve equality up to transport for those subterms.
Furthermore, since CIC$_{\omega}$ is constructive, the \textit{only} way to construct an \A (respectively \B) is to use its constructors,
and the \textit{only} way to eliminate an \A (respectively \B) is to apply its eliminator.
Finally, since these form an equivalence, all ways of constructing or eliminating \A and \B are covered by these dependent constructors and eliminators.
So, as long as we are able to unify subterms with applications of \lstinline{DepConstr} and \lstinline{DepElim},
\textsc{Dep-Constr} and \textsc{Dep-Elim} should preserve correctness of the transformation and cover all values and eliminations of \A and \B.

The correctness criteria for equality then make it possible for the transformation to
avoid applying \lstinline{section} and \lstinline{retraction} explicitly.
Intuitively, this is because the configuration terms together induce proofs of \lstinline{section}
and \lstinline{retraction}.
A sketch of the proof of \lstinline{section} is as follows (\lstinline{retraction} is similar):
Induct using \lstinline{DepElim} over \A.
For each case $i$, the proof obligation is to show that \lstinline{g b} is equal to \lstinline{g} at \lstinline{DepConstr(b, i)} applied to the non-inductive arguments (by definition of \lstinline{f}).
Define this as a motive \lstinline{Q}.
Refold to rewrite along each inductive hypothesis (\lstinline{iota_ok}) using \lstinline{Iota(A, i, Q)} applied to each \lstinline{DepConstr} over \B (the cases of the definition of \lstinline{f}), with reflexivity as the base case. % TODO check this

\paragraph{Generating Proofs of Correctness}
The intuition above is what
\textbf{Configure} uses to implement search procedures that generate functions \lstinline{f} and \lstinline{g} for the classes of equivalences
that correspond to automatic configuration (\href{https://github.com/uwplse/pumpkin-pi/blob/master/plugin/src/automation/search/search.ml}{search.ml}), and also
generate proofs \lstinline{section} and \lstinline{retraction} that these functions form an equivalence (\href{https://github.com/uwplse/pumpkin-pi/blob/master/plugin/src/automation/search/equivalence.ml}{equivalence.ml}).
To minimize dependencies, \toolname does not produce proofs of \lstinline{dep_constr_ok} and \lstinline{dep_elim_ok} directly,
as doing so would require either a special framework~\cite{tabareau2017equivalences}
or a univalent type theory~\cite{univalent2013homotopy}.
Thankfully, the proof engineer does not need to prove these in order to use \toolname.
Rather, the correctness criteria simply need to hold in order for the transformation to work.

\subsection{The Tool}
\label{sec:implementation}

The configurable proof term transformation helped us build a flexible proof repair and reuse tool.
However, it alone was not enough to build a tool that reaches real proof engineers.
This section describes a sample of the implementation challenges that we encountered and how we solved them.
Section~\ref{sec:discussion} elaborates on the remaining challenges and our plans to address them in the future.

\paragraph{From CIC$_{\omega}$ to Coq}

We must handle language differences to scale from CIC$_{\omega}$ to Coq.
We use an existing command called \lstinline{Preprocess}~\cite{Ringer2019} to turn pattern matching and fixpoints into 
applications of eliminators.
We handle non-primitive projections using \lstinline{Eta}, and we handle refolding of constants in constructors
using \lstinline{DepConstr}.

\paragraph{Termination \& Intent}

Another challenge with implementing the proof term transformation is deciding whether to run a rule that matches at all.
That is, when the correctness criteria for a configuration hold and a subterm matches a rule, this suggests that \toolname \textit{can}
run the transformation rule, but it does not necessarily mean that it \textit{should}.
In some cases, repeatedly running a matching transformation rule would result in nontermination.
For example, if \B is a refinement of \A, then we can always run \textsc{Equivalence}
over and over again, forever.
%\textsc{Devoid} ruled out this case by simply prohibiting the case where \B refers to \A, but we found it sometimes
%useful to support this case.
We thus include some simple termination checks in our code (\href{https://github.com/uwplse/pumpkin-pi/blob/master/plugin/src/automation/lift/liftrules.ml}{liftrules.ml}).

Even when termination is guaranteed, whether to run a matching transformation rule
depends on intent.
For example, our industrial proof engineer sometimes wished to port only some occurrences of \A,
especially when \A was a tuple that could appear elsewhere
with a different meaning.
\toolname has some support for this using an interactive workflow.
%We helped the proof engineer do this by interacting with \toolname using a particular workflow.
%We plan to support this automatically using type-directed search in the future.

\paragraph{Reaching Real Proof Engineers}
Many of our design decisions in implementing \toolname were informed by our partnership with
an industrial proof engineer (see Section~\ref{sec:industry}).
For example, we found that the proof engineer rarely had the patience to wait more than ten seconds
for \toolname to port a function or proof.
In response, we implemented aggressive caching (with an option to disable the cache), even caching intermediate subterms that
we encounter in the course of running our proof term transformation.
We also added a cache to tell \toolname not to $\delta$-reduce certain terms.
These caches are implemented in \href{https://github.com/uwplse/pumpkin-pi/blob/master/plugin/src/cache/caching.ml}{caching.ml}.
%or recurse into certain modules.
% set certain terms or modules as opaque to \toolname, to prevent unnecessary $\delta$-reduction.

The experiences of proof engineers also informed features that we exposed.
For example, we implemented special search procedures to generate custom eliminators (\href{https://github.com/uwplse/pumpkin-pi/blob/master/plugin/src/automation/search/smartelim.ml}{smartelim.ml}) to make it easier to reason about
types refined by equalities like $\Sigma$\lstinline{(l : list T).length l = n}
by breaking them into parts and reasoning separately about the projections.
These features along with our tactic decompiler helped with integration into proof engineering workflows.

%First we need that \lstinline{DepElim} over $A$ into \lstinline{DepConstr} over $B$ and \lstinline{DepElim} over $B$ into
%\lstinline{DepConstr} over $A$ form an equivalence between $A$ and $B$. When that's true, I think it should hold that \lstinline{DepElim} over $A$
%and \lstinline{DepElim} over $B$ are in univalent relation with one another. If not, then that's an extra condition.
%Finally, we need the transformation to preserve definitional equalities. Not sure about the general case, but for vectors and lists,
%we need:

%\begin{lstlisting}
%  $\forall$ A l (f : $\forall$ (l : sigT (Vector.t A)), l = l),
%    vect_dep_elim A (fun l => l = l) (f nil) (fun t s _ => f (cons t s)) l = f (id_eta l).
%\end{lstlisting}
%and:

%\begin{lstlisting}
%Definition elim_id (A : Type) (s : {H : nat & t A H}) :=
%  vect_dep_elim
%    A
%    (fun _ => {H : nat & t A H})
%    nil
%    (fun (h : A) _ IH =>
%      cons h IH)
%    s.

% $\forall$ A h s,
%    exists (H : cons h (elim_id A s) = elim_id A (cons h s)),
%      H = eq_refl.
%\end{lstlisting}
%More generally, for each constructor index $j$, define:

%\begin{lstlisting}
%  eqc (j, B) (f : $\forall$ b : B, b = b) :=
%    fun ... (* TODO get the hypos from the type of the eliminator *) =>
%      f (DepConstr (j, B)) (* TODO args *)%%

  %elim_id := (* TODO *)
%\end{lstlisting}
%Then we need:

%\begin{enumerate}
%\item $\forall b f, \mathrm{DepElim}(b,\ p_{b}) \{\mathrm{eqc} (1, B) f, \ldots, \mathrm{eqc} (n, B) f\} = f (\mathrm{Eta}(A) a) $
%\item Something relating the constructors and \lstinline{elim_id} to reflexivity
%\end{enumerate}
%and similarly for $A$.

%Really the point of these conditions is that from them, with some restrictions on input terms, we can get
%that lifting terms gives us the same type that we'd get from lifting the type. But there are still
%some restrictions (see the few that fail).

%It's probably not always possible to define these three things for every equivalence.
%Could generalize by rewriting. But this lets us avoid the rewriting problem from Nicolas' paper.

% TODO how does this get us something like primitive projections? Just makes Eta definitionally equal to regular Id?

% TODO so we can probably just frame search in terms of DepConstr and DepElim and then generate proofs about this on an ad-hoc basis
% and get away with not including the specific details of our instantiations. We can give examples instead, give intuition, and say we generate
% the proofs in Coq

%For the second one we need not just an eliminator rule but also an identity rule.
%DEVOID assumed primitive projections which let them get away without thinking of this,
%but then had this weirdly ad-hoc ``repacking'' thing in their implementation.
%It turns out this is just a more general identity rule, which basically says what
%the identity function should lift to so that the transformation preserves definitional equalities.
%Actually deciding when to run this rule is one of the biggest challenges in practice,
%so we'll talk about that more in the implementation section.

